<div class="container">

<table style="width: 100%;"><tr>
<td>blm_star</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>STAR Bayesian Linear Regression</h2>

<h3>Description</h3>

<p>Posterior inference for STAR linear model
</p>


<h3>Usage</h3>

<pre><code class="language-R">blm_star(
  y,
  X,
  X_test = NULL,
  transformation = "np",
  y_max = Inf,
  prior = "gprior",
  use_MCMC = TRUE,
  nsave = 5000,
  nburn = 5000,
  nskip = 0,
  method_sigma = "mle",
  approx_Fz = FALSE,
  approx_Fy = FALSE,
  psi = NULL,
  compute_marg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p><code>n x 1</code> vector of observed counts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code>n x p</code> matrix of predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_test</code></td>
<td>
<p><code>n0 x p</code> matrix of predictors for test data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transformation</code></td>
<td>
<p>transformation to use for the latent process; must be one of
</p>

<ul>
<li>
<p> "identity" (identity transformation)
</p>
</li>
<li>
<p> "log" (log transformation)
</p>
</li>
<li>
<p> "sqrt" (square root transformation)
</p>
</li>
<li>
<p> "np" (nonparametric transformation estimated from empirical CDF)
</p>
</li>
<li>
<p> "pois" (transformation for moment-matched marginal Poisson CDF)
</p>
</li>
<li>
<p> "neg-bin" (transformation for moment-matched marginal Negative Binomial CDF)
</p>
</li>
<li>
<p> "box-cox" (box-cox transformation with learned parameter)
</p>
</li>
<li>
<p> "ispline" (transformation is modeled as unknown, monotone function
using I-splines)
</p>
</li>
<li>
<p> "bnp" (Bayesian nonparametric transformation using the Bayesian bootstrap)
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y_max</code></td>
<td>
<p>a fixed and known upper bound for all observations; default is <code>Inf</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>prior to use for the latent linear regression; currently implemented options
are "gprior", "horseshoe", and "ridge". Not all modeling options and transformations are
available with the latter two priors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_MCMC</code></td>
<td>
<p>= TRUE,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsave</code></td>
<td>
<p>number of MCMC iterations to save (or MC samples to draw if use_MCMC=FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nburn</code></td>
<td>
<p>number of MCMC iterations to discard</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nskip</code></td>
<td>
<p>number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method_sigma</code></td>
<td>
<p>method to estimate the latent data standard deviation in exact sampler;
must be one of
</p>

<ul>
<li>
<p> "mle" use the MLE from the STAR EM algorithm
</p>
</li>
<li>
<p> "mmle" use the marginal MLE (Note: slower!)
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approx_Fz</code></td>
<td>
<p>logical; in BNP transformation, apply a (fast and stable)
normal approximation for the marginal CDF of the latent data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approx_Fy</code></td>
<td>
<p>logical; in BNP transformation, approximate
the marginal CDF of <code>y</code> using the empirical CDF</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psi</code></td>
<td>
<p>prior variance (g-prior)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compute_marg</code></td>
<td>
<p>logical; if TRUE, compute and return the
marginal likelihood (only available when using exact sampler, i.e. use_MCMC=FALSE)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>STAR defines a count-valued probability model by
(1) specifying a Gaussian model for continuous *latent* data and
(2) connecting the latent data to the observed data via a
*transformation and rounding* operation. Here, the continuous
latent data model is a linear regression.
</p>
<p>There are several options for the transformation. First, the transformation
can belong to the *Box-Cox* family, which includes the known transformations
'identity', 'log', and 'sqrt', as well as a version in which the Box-Cox parameter
is inferred within the MCMC sampler ('box-cox'). Second, the transformation
can be estimated (before model fitting) using the empirical distribution of the
data <code>y</code>. Options in this case include the empirical cumulative
distribution function (CDF), which is fully nonparametric ('np'), or the parametric
alternatives based on Poisson ('pois') or Negative-Binomial ('neg-bin')
distributions. For the parametric distributions, the parameters of the distribution
are estimated using moments (means and variances) of <code>y</code>. The distribution-based
transformations approximately preserve the mean and variance of the count data <code>y</code>
on the latent data scale, which lends interpretability to the model parameters.
Lastly, the transformation can be modeled using the Bayesian bootstrap ('bnp'),
which is a Bayesian nonparametric model and incorporates the uncertainty
about the transformation into posterior and predictive inference.
</p>
<p>The Monte Carlo sampler (<code>use_MCMC=FALSE</code>) produces direct, discrete, and joint draws
from the posterior distribution and the posterior predictive distribution
of the linear regression model with a g-prior.
</p>


<h3>Value</h3>

<p>a list with at least the following elements:
</p>

<ul>
<li> <p><code>coefficients</code>: the posterior mean of the regression coefficients
</p>
</li>
<li> <p><code>post.beta</code>: posterior draws of the regression coefficients
</p>
</li>
<li> <p><code>post.pred</code>: draws from the posterior predictive distribution of <code>y</code>
</p>
</li>
<li> <p><code>post.log.like.point</code>: draws of the log-likelihood for each of the <code>n</code> observations
</p>
</li>
<li> <p><code>WAIC</code>: Widely-Applicable/Watanabe-Akaike Information Criterion
</p>
</li>
<li> <p><code>p_waic</code>: Effective number of parameters based on WAIC
</p>
</li>
</ul>
<p>If test points are passed in, then the list will also have <code>post.predtest</code>,
which contains draws from the posterior predictive distribution at test points.
</p>
<p>Other elements may be present depending on the choice of prior, transformation,
and sampling approach.
</p>


<h3>Note</h3>

<p>The 'bnp' transformation (without the <code>Fy</code> approximation) is
slower than the other transformations because of the way
the <code>TruncatedNormal</code> sampler must be updated as the lower and upper
limits change (due to the sampling of <code>g</code>). Thus, computational
improvements are likely available.
</p>


</div>