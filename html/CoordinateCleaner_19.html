<div class="container">

<table style="width: 100%;"><tr>
<td>cd_ddmm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Identify Datasets with a Degree Conversion Error</h2>

<h3>Description</h3>

<p>This test flags datasets where a significant fraction of records has
been subject to a common degree minute to decimal degree conversion error,
where the degree sign is recognized as decimal delimiter.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cd_ddmm(
  x,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
  ds = "dataset",
  pvalue = 0.025,
  diff = 1,
  mat_size = 1000,
  min_span = 2,
  value = "clean",
  verbose = TRUE,
  diagnostic = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data.frame. Containing geographical coordinates and species names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lon</code></td>
<td>
<p>character string. The column with the longitude coordinates.
Default = “decimalLongitude”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lat</code></td>
<td>
<p>character string. The column with the latitude coordinates.
Default = “decimalLatitude”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ds</code></td>
<td>
<p>a character string. The column with the dataset of each record. In
case <code>x</code> should be treated as a single dataset, identical for all
records.  Default = “dataset”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalue</code></td>
<td>
<p>numeric. The p-value for the one-sided t-test to flag the test
as passed or not. Both ddmm.pvalue and diff must be met. Default = 0.025.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diff</code></td>
<td>
<p>numeric. The threshold difference for the ddmm test. Indicates
by which fraction the records with decimals below 0.6 must outnumber the
records with decimals above 0.6. Default = 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mat_size</code></td>
<td>
<p>numeric. The size of the matrix for the binomial test. Must
be changed in decimals (e.g. 100, 1000, 10000). Adapt to dataset size,
generally 100 is better for datasets &lt; 10000 records, 1000 is better for
datasets with 10000 - 1M records. Higher values also work reasonably well
for smaller datasets, therefore, default = 1000. For large datasets try
10000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_span</code></td>
<td>
<p>numeric. The minimum geographic extent of datasets to be
tested. Default = 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value</code></td>
<td>
<p>character string.  Defining the output value. See value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical. If TRUE reports the name of the test and the number
of records flagged.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diagnostic</code></td>
<td>
<p>logical. If TRUE plots the analyses matrix for each
dataset.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If the degree sign is recognized as decimal delimiter during coordinate
conversion, no coordinate decimals above 0.59 (59') are possible. The test
here uses a binomial test to test if a significant proportion of records in
a dataset have been subject to this problem. The test is best adjusted via
the diff argument. The lower <code>diff</code>, the stricter the test. Also scales
with dataset size. Empirically, for datasets with &lt; 5,000 unique coordinate
records <code>diff = 0.1</code> has proven reasonable flagging most datasets with
&gt;25% problematic records and all dataset with &gt;50% problematic records.
For datasets between 5,000 and 100,000 geographic unique records <code>diff
= 0.01</code> is recommended, for datasets between 100,000 and 1 M records diff =
0.001, and so on.
</p>


<h3>Value</h3>

<p>Depending on the ‘value’ argument, either a <code>data.frame</code>
with summary statistics and flags for each dataset (“dataset”) or a
<code>data.frame</code> containing the records considered correct by the test
(“clean”) or a logical vector (“flags”), with TRUE = test passed and FALSE =
test failed/potentially problematic. Default =
“clean”.
</p>


<h3>Note</h3>

<p>See <a href="https://ropensci.github.io/CoordinateCleaner/">https://ropensci.github.io/CoordinateCleaner/</a> for more
details and tutorials.
</p>


<h3>See Also</h3>

<p>Other Datasets: 
<code>cd_round()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
clean &lt;- data.frame(species = letters[1:10], 
                decimalLongitude = runif(100, -180, 180), 
                decimalLatitude = runif(100, -90,90),
                dataset = "FR")
                
cd_ddmm(x = clean, value = "flagged")

#problematic dataset
lon &lt;- sample(0:180, size = 100, replace = TRUE) + runif(100, 0,0.59)
lat &lt;- sample(0:90, size = 100, replace = TRUE) + runif(100, 0,0.59)

prob &lt;-  data.frame(species = letters[1:10], 
                decimalLongitude = lon, 
                decimalLatitude = lat,
                dataset = "FR")
                
cd_ddmm(x = prob, value = "flagged")

</code></pre>


</div>