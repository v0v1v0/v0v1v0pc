<div class="container">

<table style="width: 100%;"><tr>
<td>CNmixt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitting for the Parsimonious Mixtures of Contaminated Normal Distributions</h2>

<h3>Description</h3>

<p>Fits, by using the expectation conditional-maximization (ECM) algorithm, parsimonious mixtures of multivariate contaminated normal distributions (with eigen-decomposed scale matrices) to the given data within a clustering paradigm (default) or classification paradigm. 
Can be run in parallel.
Likelihood-based model selection criteria are used to select the parsimonious model and the number of groups.
</p>


<h3>Usage</h3>

<pre><code class="language-R">CNmixt(X, G, contamination = NULL, model = NULL,
   initialization = "mixt", alphafix = NULL, alphamin = 0.5, 
   seed = NULL, start.z = NULL, start.v = NULL, start = 0,
   label = NULL, AICcond = FALSE, iter.max = 1000, 
   threshold = 1.0e-10, parallel = FALSE, eps = 1e-100,verbose = TRUE)
CNmixtCV(X, G, contamination = NULL, model = NULL,
   initialization = "mixt", k = 10,alphafix = NULL, 
   alphamin = 0.5, seed = NULL, start.z = NULL, start.v = NULL, 
   start = 0, label = NULL, iter.max = 1000, threshold = 1.0e-10, 
   parallel = FALSE, eps = 1e-100, verbose = TRUE)  
</code></pre>


<h3>Arguments</h3>

                      
<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>a <code>dim=c(n,p)</code> matrix such that the <code class="reqn">n</code> rows correspond to observations and the <code class="reqn">p</code> columns correspond to variables. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>

<p>a vector containing the numbers of groups to be tried. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contamination</code></td>
<td>
<p>an optional boolean indicating if the model(s) to be fitted have to be contaminated or not. 
If <code>NULL</code>, then both types of models are fitted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>a vector indicating the model(s) to be fitted.
In the multivariate case (<code class="reqn">p&gt;1</code>), possible values are: <code>"EII"</code>, <code>"VII"</code>, <code>"EEI"</code>, <code>"VEI"</code>, <code>"EVI"</code>, <code>"VVI"</code>, <code>"EEE"</code>, <code>"VEE"</code>, <code>"EVE"</code>, <code>"EEV"</code>, <code>"VVE"</code>, <code>"VEV"</code>, <code>"EVV"</code>, <code>"VVV"</code>.
If <code>NULL</code>, then all 14 models are fitted.
In the univariate case (<code class="reqn">p=1</code>), possible values are <code>"E"</code> and <code>"V"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initialization</code></td>
<td>

<p>initialization strategy for the ECM algorithm. 
It can be:
</p>

<ul>
<li> <p><code>"mixt"</code> (default): the initial (<code class="reqn">n \times G</code>) matrix with posterior probabilities of groups membership arises from a preliminary run of mixtures of multivariate normal distributions as fitted by the <code>gpcm()</code> function of the <span class="pkg">mixture</span> package (see <code>mixture:gpcm</code> for details).
</p>
</li>
<li> <p><code>"kmeans"</code>: the initial (<code class="reqn">n \times G</code>) hard classification matrix arises from a preliminary run of the <code class="reqn">k</code>-means algorithm;
</p>
</li>
<li> <p><code>"random.post"</code>: the initial (<code class="reqn">n \times G</code>) matrix with posterior probabilities of groups membership is randomly generated; 
</p>
</li>
<li> <p><code>"random.clas"</code>: the initial (<code class="reqn">n \times G</code>) classification matrix is randomly generated;
</p>
</li>
<li> <p><code>"manual"</code>: the user must specify either the initial (<code class="reqn">n \times G</code>) classification matrix or the initial (<code class="reqn">n \times G</code>) matrix with posterior probabilities of groups membership, via the argument <code>start.z</code> and, optionally, the initial (<code class="reqn">n \times G</code>) matrix of posterior probabilities to be a good observation in each group, via the argument <code>start.v</code>.    
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphafix</code></td>
<td>

<p>a vector of length <code class="reqn">G</code> with the proportion of good observations in each group. 
If <code>length(alphafix) != G</code>, then the first element is replicated <code class="reqn">G</code> times. 
Default value is <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphamin</code></td>
<td>

<p>a vector of length <code class="reqn">G</code> with the minimum proportion of good observations in each group.  
If <code>length(alphamin) != G</code>, then the first element is replicated <code class="reqn">G</code> times.
Default value is <code>0.5</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>the seed for the random number generator, when random initializations are used; if <code>NULL</code>, current seed is not changed. 
Default value is <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.z</code></td>
<td>

<p>initial <code class="reqn">n \times G</code> matrix of either soft or hard classification. 
Default value is <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start.v</code></td>
<td>

<p>initial <code class="reqn">n \times G</code> matrix of posterior probabilities to be a good observation in each group. 
Default value is a <code class="reqn">n \times G</code> matrix of ones.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>

<p>when <code>initialization = "mixt"</code>, initialization used for the <code>gpcm()</code> function of the <span class="pkg">mixture</span> package (see <code>mixture:gpcm</code> for details). 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>

<p>a vector of integers of length equal to the number of rows of <code>X</code>. 
It indicates the known group of membership of each observation. 
Use <code>0</code> when membership is not known. 
Use <code>NULL</code> when membership is unknown for all observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AICcond</code></td>
<td>
<p>When <code>TRUE</code>, the AICcond criterion, an estimate of the predictive ability of a generative model for classification, is computed (Vandewalle et al., 2013).  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter.max</code></td>
<td>

<p>maximum number of iterations in the ECM algorithm. 
Default value is <code>1000</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>

<p>threshold for Aitken's acceleration procedure. 
Default value is <code>1.0e-03</code>. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>

<p>When <code>TRUE</code>, the package <code>parallel</code> is used for parallel computation. 
When several models are estimated, computational time is reduced. 
The number of cores to use may be set with the global option <code>cl.cores</code>; default value is detected using <code>detectCores()</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>

<p>an optional scalar. 
It sets the smallest value for the eigenvalues of the component scale matrices. 
Default value is <code>1e-100</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of equal sized subsamples used in <code class="reqn">k</code>-fold cross-validation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>write text to the console</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The multivariate data contained in <code>X</code> are either clustered or classified using parsimonious mixtures of multivariate contaminated normal distributions with some or all of the 14 parsimonious models described in Punzo and McNicholas (2016). 
Model specification (via the <code>model</code> argument) follows the nomenclature popularized in other packages such as <span class="pkg">mixture</span> and <span class="pkg">mclust</span>.  
Such a nomenclature refers to the decomposition and constraints on the scale matrix (see Banfield and Raftery, 1993, Celeux and Govaert, 1995 and Punzo and McNicholas, 2016 for details): 
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_g = \lambda_g \Gamma_g \Delta_g \Gamma_g'.</code>
</p>

<p>The nomenclature describes (in order) the volume (<code class="reqn">\lambda_g</code>), shape (<code class="reqn">\Delta_g</code>), and orientation (<code class="reqn">\Gamma_g</code>), in terms of <code>"V"</code>ariable, <code>"E"</code>qual, or the <code>"I"</code>dentity matrix. 
As an example, the string <code>"VEI"</code> would refer to the model where <code class="reqn">\Sigma_g = \lambda_g \Delta</code>.
Note that for <code class="reqn">G=1</code>, several models are equivalent (for example, <code>"EEE"</code> and <code>"VVV"</code>). 
Thus, for <code class="reqn">G=1</code> only one model from each set of equivalent models will be run.
</p>
<p>The algorithms detailed in Celeux and Govaert (1995) are considered in the first CM-step of the ECM algorithm to update <code class="reqn">\Sigma_g</code> for all the models apart from <code>"EVE"</code> and <code>"VVE"</code>.
For <code>"EVE"</code> and <code>"VVE"</code>, majorization-minimization (MM) algorithms (Hunter and Lange, 2000) and accelerated line search algorithms on the Stiefel manifold (Absil, Mahony and Sepulchre, 2009 and Browne and McNicholas, 2014), which are especially preferable in higher dimensions (Browne and McNicholas, 2014), are used to update <code class="reqn">\Sigma_g</code>; the same approach is also adopted in the <span class="pkg">mixture</span> package for those models.
</p>
<p>Starting values are very important to the successful operation of these algorithms and so care must be taken in the interpretation of results.
All the initializations considered here provide initial quantities for the first CM-step of the ECM algorithm.
The predictive ability of a model for classification may be estimated using the cross-validated error rate, returned by <code>CNmixtCV</code> or trough the the AICcond criterion (Vandewalle et al., 2013).
</p>


<h3>Value</h3>

<p><code>CNmixt</code> returns an object of class <code>ContaminatedMixt</code>.
<code>CNmixtCV</code> returns a list with the cross-validated error rate estimated for each model. 
</p>


<h3>Author(s)</h3>

<p>Antonio Punzo, Angelo Mazza, Paul D. McNicholas 
</p>


<h3>References</h3>

<p>Absil P. A., Mahony R. and Sepulchre R. (2009). Optimization Algorithms on Matrix Manifolds. Princeton University Press, Princeton, NJ.
</p>
<p>Banfield J. D. and Raftery A. E. (1993). Model-Based Gaussian and Non-Gaussian Clustering. <em>Biometrics</em>, <b>49</b>(3), 803–821.
</p>
<p>Browne R. P. and McNicholas P. D. (2013). Estimating Common Principal Components in High Dimensions. <em>Advances in Data Analysis and Classification</em>, <b>8</b>(2), 217–226.
</p>
<p>Browne, R. P. and McNicholas P. D. (2014). Orthogonal Stiefel manifold optimization for eigen-decomposed covariance parameter estimation in mixture models. <em>Statistics and Computing</em>, <b>24</b>(2), 203–210.
</p>
<p>Browne R. P. and McNicholas P. D. (2015). <span class="pkg">mixture</span>: Mixture Models for Clustering and Classification. R package version 1.4.
</p>
<p>Celeux G. and Govaert G. (1995). Gaussian Parsimonious Clustering Models. <em>Pattern Recognition</em>. <b>28</b>(5), 781–793.
</p>
<p>Hunter D. R. and Lange K. (2000). Rejoinder to Discussion of “Optimization Transfer Using Surrogate Objective Functions”. <em>Journal of Computational and Graphical Statistics</em>, <b>9</b>(1), 52–59.
</p>
<p>Punzo A., Mazza A. and McNicholas P. D. (2018). <span class="pkg">ContaminatedMixt</span>: An R Package for Fitting Parsimonious Mixtures of Multivariate Contaminated Normal Distributions. <em>Journal of Statistical Software</em>, <b>85</b>(10), 1–25.
</p>
<p>Punzo A. and McNicholas P. D. (2016). Parsimonious mixtures of multivariate contaminated normal distributions. <em>Biometrical Journal</em>, <b>58</b>(6), 1506–1537.
</p>
<p>Vandewalle V., Biernacki C., Celeux G. and Govaert G. (2013). A predictive deviance criterion for selecting a generative
model in semi-supervised classification. <em>Computational Statistics and Data Analysis</em>, <b>64</b>, 220–236.
</p>


<h3>See Also</h3>

                  
<p><code>ContaminatedMixt-package</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Note that the example is extremely simplified 
## in order to reduce computation time

# Artificial data from an EEI Gaussian mixture with G = 2 components

library("mnormt")
p &lt;- 2
set.seed(12345)
X1 &lt;- rmnorm(n = 200, mean = rep(2, p), varcov = diag(c(5, 0.5)))
X2 &lt;- rmnorm(n = 200, mean = rep(-2, p), varcov = diag(c(5, 0.5)))
noise &lt;- matrix(runif(n = 40, min = -20, max = 20), nrow = 20, ncol = 2)
X &lt;- rbind(X1, X2, noise)

group &lt;- rep(c(1, 2, 3), times = c(200, 200, 20))
plot(X, col = group, pch = c(3, 4, 16)[group], asp = 1, xlab = expression(X[1]),
ylab = expression(X[2]))

# ---------------------- #
# Model-based clustering #
# ---------------------- #

res1 &lt;- CNmixt(X, model = c("EEI", "VVV"), G = 2, parallel = FALSE)

summary(res1)

agree(res1, givgroup = group)

plot(res1, contours = TRUE, asp = 1, xlab = expression(X[1]), ylab = expression(X[2]))

# -------------------------- #
# Model-based classification #
# -------------------------- #

indlab &lt;- sample(1:400, 20)
lab &lt;- rep(0,nrow(X))
lab[indlab] &lt;- group[indlab]
res2 &lt;- CNmixt(X, G = 2, model = "EEI", label = lab)


agree(res2, givgroup = group)

</code></pre>


</div>