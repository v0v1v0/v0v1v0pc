<div class="container">

<table style="width: 100%;"><tr>
<td>tokens_context</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get the tokens of contexts sorrounding user defined patterns</h2>

<h3>Description</h3>

<p>This function uses quanteda's <code>kwic()</code> function to find the contexts
around user defined patterns (i.e. target words/phrases) and return a tokens object
with the tokenized contexts and corresponding document variables.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokens_context(
  x,
  pattern,
  window = 6L,
  valuetype = c("glob", "regex", "fixed"),
  case_insensitive = TRUE,
  hard_cut = FALSE,
  rm_keyword = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a (quanteda) <code>tokens-class</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pattern</code></td>
<td>
<p>a character vector, list of character vectors, dictionary,
or collocations object.  See pattern for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>window</code></td>
<td>
<p>the number of context words to be displayed around the keyword</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>valuetype</code></td>
<td>
<p>the type of pattern matching: <code>"glob"</code> for "glob"-style
wildcard expressions; <code>"regex"</code> for regular expressions; or <code>"fixed"</code> for
exact matching. See valuetype for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case_insensitive</code></td>
<td>
<p>logical; if <code>TRUE</code>, ignore case when matching a
<code>pattern</code> or dictionary values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hard_cut</code></td>
<td>
<p>(logical) - if TRUE then a context must have <code>window</code> x 2 tokens,
if FALSE it can have <code>window</code> x 2 or fewer (e.g. if a doc begins with a target word,
then context will have <code>window</code> tokens rather than <code>window</code> x 2)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rm_keyword</code></td>
<td>
<p>(logical) if FALSE, keyword matching pattern is included in the tokenized contexts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>(logical) if TRUE, report the total number of instances per pattern found</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a (quanteda) <code>tokens-class</code>. Each document in the output tokens object
inherits the document variables (<code>docvars</code>) of the document from whence it came,
along with a column registering corresponding the pattern used.
This information can be retrieved using <code>docvars()</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(quanteda)

# tokenize corpus
toks &lt;- tokens(cr_sample_corpus)

# build a tokenized corpus of contexts sorrounding a target term
immig_toks &lt;- tokens_context(x = toks, pattern = "immigr*", window = 6L)
</code></pre>


</div>