<div class="container">

<table style="width: 100%;"><tr>
<td>gs_data_dir</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Google storage bucket path that syncs to local storage when not
running on CloudML.</h2>

<h3>Description</h3>

<p>Refer to data within a Google Storage bucket. When running on CloudML
the bucket will be read from directly. Otherwise, the bucket will be
automatically synchronized to a local directory.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gs_data_dir(url, local_dir = "gs", force_sync = FALSE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>url</code></td>
<td>
<p>Google Storage bucket URL (e.g. <code>gs://&lt;your-bucket&gt;</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>local_dir</code></td>
<td>
<p>Local directory to synchonize Google Storage bucket(s) to.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>force_sync</code></td>
<td>
<p>Force local synchonization even if the data
directory already exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>echo</code></td>
<td>
<p>Echo command output to console.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function is suitable for use in TensorFlow APIs that accept
gs:// URLs (e.g. TensorFlow datasets). However, many package functions
accept only local filesystem paths as input (rather than
gs:// URLs). For these cases you can the <code>gs_data_dir_local()</code> function,
which will always synchronize gs:// buckets to the local filesystem and
provide a local path interface to their contents.
</p>


<h3>Value</h3>

<p>Path to contents of data directory.
</p>


<h3>See Also</h3>

<p><code>gs_data_dir_local()</code>
</p>


</div>