<div class="container">

<table style="width: 100%;"><tr>
<td>cclust</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Convex Clustering </h2>

<h3>Description</h3>

<p>The data given by <code>x</code> is clustered by an algorithm.
</p>
<p>If <code>centers</code> is a matrix, its rows are taken as the initial
cluster centers. If <code>centers</code> is an integer, <code>centers</code> rows
of <code>x</code> are randomly chosen as initial values.
</p>
<p>The algorithm stops, if no cluster center has changed during the last
iteration or the maximum number of iterations (given by
<code>iter.max</code>) is reached.
</p>
<p>If <code>verbose</code> is <code>TRUE</code>, only for <code>"kmeans"</code> method,
displays for each iteration the number of the iteration and the
numbers of cluster indices which have changed since the last iteration
is given.
</p>
<p>If <code>dist</code> is <code>"euclidean"</code>, the distance between the cluster
center and the data points is the Euclidian distance (ordinary kmeans
algorithm). If <code>"manhattan"</code>, the distance between the cluster
center and the data points is the sum of the absolute values of the
distances of the coordinates.
</p>
<p>If <code>method</code> is <code>"kmeans"</code>, then we have the kmeans
clustering method, which works by repeatedly moving all cluster
centers to the mean of their Voronoi sets. If <code>"hardcl"</code> we have
the On-line Update (Hard Competitive learning) method, which works by
performing an update directly after each input signal, and if
<code>"neuralgas"</code> we have the Neural Gas (Soft Competitive learning)
method, that sorts for each input signal the units of the network
according to the distance of their reference vectors to input signal.
</p>
<p>If <code>rate.method</code> is <code>"polynomial"</code>, the polynomial learning
rate is used, that means <code class="reqn">1/t</code>, where <code class="reqn">t</code> stands for the
number of input data for which a particular cluster has been the
winner so far.  If <code>"exponentially decaying"</code>, the exponential
decaying learning rate is used according to
<code class="reqn">par1*{(par2/par1)}^{(iter/itermax)}</code> 
where <code class="reqn">par1</code> and <code class="reqn">par2</code> are the initial and final values of
the learning rate.
</p>
<p>The parameters <code>rate.par</code> of the learning rate, where
if <code>rate.method</code> is <code>"polynomial"</code> then by default
<code>rate.par=1.0</code>, otherwise <code>rate.par=(0.5,1e-5)</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cclust (x, centers, iter.max=100, verbose=FALSE, dist="euclidean",
        method= "kmeans", rate.method="polynomial", rate.par=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Data matrix where columns correspond to variables and rows to
observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>Number of clusters or initial values for cluster
centers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter.max</code></td>
<td>
<p>Maximum number of iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, make some output during learning</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist</code></td>
<td>
<p>If <code>"euclidean"</code>, then mean square error, if
<code>"manhattan "</code>, the mean absolute error is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>If <code>"kmeans"</code>, then we have the kmeans clustering
method, if <code>"hardcl"</code> we have the On-line Update (Hard
Competitive learning) method, and if <code>"neuralgas"</code>, we have the
Neural Gas (Soft Competitive learning) method. Abbreviations of
the method names are accepted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate.method</code></td>
<td>
<p>If <code>"kmeans"</code>, then k-means learning rate,
otherwise exponential decaying learning rate.
It is used only for the Hardcl method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate.par</code></td>
<td>
<p>The parameters of the learning rate.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>cclust</code> returns an object of class <code>"cclust"</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>The final cluster centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initcenters</code></td>
<td>
<p>The initial cluster centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncenters</code></td>
<td>
<p>The number of the centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>Vector containing the indices of the clusters where
the data points are assigned to.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>The number of data points in each cluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>The number of iterations performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>changes</code></td>
<td>
<p>The number of changes performed in each iteration
step with the Kmeans algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist</code></td>
<td>
<p>The distance measure used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The algorithm method being used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate.method</code></td>
<td>
<p>The learning rate being used by the Hardcl clustering
method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate.par</code></td>
<td>
<p>The parameters of the learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>Returns a call in which all of the arguments are
specified by their names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>withinss</code></td>
<td>
<p>Returns the sum of square distances within the clusters.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Evgenia Dimitriadou</p>


<h3>See Also</h3>

<p><code>predict.cclust</code></p>


<h3>Examples</h3>

<pre><code class="language-R">## a 2-dimensional example
x&lt;-rbind(matrix(rnorm(100,sd=0.3),ncol=2),
         matrix(rnorm(100,mean=1,sd=0.3),ncol=2))
cl&lt;-cclust(x,2,20,verbose=TRUE,method="kmeans")
plot(x, col=cl$cluster)   

## a 3-dimensional example 
x&lt;-rbind(matrix(rnorm(150,sd=0.3),ncol=3),
         matrix(rnorm(150,mean=1,sd=0.3),ncol=3),
         matrix(rnorm(150,mean=2,sd=0.3),ncol=3))
cl&lt;-cclust(x,6,20,verbose=TRUE,method="kmeans")
plot(x, col=cl$cluster)

## assign classes to some new data
y&lt;-rbind(matrix(rnorm(33,sd=0.3),ncol=3),
         matrix(rnorm(33,mean=1,sd=0.3),ncol=3),
         matrix(rnorm(3,mean=2,sd=0.3),ncol=3))
         ycl&lt;-predict(cl, y)
         plot(y, col=ycl$cluster)
</code></pre>


</div>