<div class="container">

<table style="width: 100%;"><tr>
<td>LASSO Kullback-Leibler divergence based regression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
LASSO Kullback-Leibler divergence based regression
</h2>

<h3>Description</h3>

<p>LASSO Kullback-Leibler divergence based regression.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lasso.klcompreg(y, x, alpha = 1, lambda = NULL,
nlambda = 100, type = "grouped", xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A numerical matrix with compositional data. Zero values are allowed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A numerical matrix containing the predictor variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>The elastic net mixing parameter, with <code class="reqn">0 \leq \alpha \leq 1</code>. The penalty is defined as a 
weighted combination of the ridge and of the Lasso regression. When <code class="reqn">\alpha=1</code> LASSO is applied, 
while <code class="reqn">\alpha=0</code> yields the ridge regression.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> A user supplied lambda sequence. 
Typical usage is to have the program compute its own lambda sequence based on nlambda and lambda.min.ratio. 
Supplying a value of lambda overrides this. WARNING: use with care. Avoid supplying a single value for 
lambda (for predictions after CV use predict() instead). Supply instead a decreasing sequence of lambda values. 
glmnet relies on its warms starts for speed, and its often faster to fit a whole path than compute a single fit.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> The number of <code class="reqn">lambda</code> values, default is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b>. If "grouped" then a grouped lasso penalty is 
used on the multinomial coefficients for a variable. This ensures they are all in our out together.
The default in our case is "grouped".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function uses the glmnet package to perform LASSO penalised regression. For more details see the 
function in that package.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mod</code></td>
<td>

<p>We decided to keep the same list that is returned by glmnet. So, see the function in that package 
for more information.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est</code></td>
<td>
<p> If you supply a matrix in the "xnew" argument this will return an array of many matrices 
with the fitted values, where each matrix corresponds to each value of <code class="reqn">\lambda</code>.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michail Tsagris and Abdulaziz Alenazi.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and 
Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Alenazi, A. A. (2022). f-divergence regression models for compositional data. 
Pakistan Journal of Statistics and Operation Research, 18(4): 867–882.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear Models 
via Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1–22.
</p>


<h3>See Also</h3>

<p><code>lassocoef.plot, cv.lasso.klcompreg, kl.compreg, lasso.compreg, ols.compreg, alfa.pcr, alfa.knn.reg
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">y &lt;- as.matrix(iris[, 1:4])
y &lt;- y / rowSums(y)
x &lt;- matrix( rnorm(150 * 30), ncol = 30 )
a &lt;- lasso.klcompreg(y, x)
</code></pre>


</div>