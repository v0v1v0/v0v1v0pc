<div class="container">

<table style="width: 100%;"><tr>
<td>slca</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Structured Latent Class Analysis (SLCA)
</h2>

<h3>Description</h3>

<p>This function implements a structured latent class model for
polytomous item responses (Formann, 1985, 1992). Lasso estimation for the
item parameters is included (Chen, Liu, Xu &amp; Ying, 2015;
Chen, Li, Liu &amp; Ying, 2017; Sun, Chen, Liu, Ying &amp; Xin,  2016).
</p>


<h3>Usage</h3>

<pre><code class="language-R">slca(data, group=NULL, weights=rep(1, nrow(data)), Xdes,
  Xlambda.init=NULL, Xlambda.fixed=NULL, Xlambda.constr.V=NULL,
  Xlambda.constr.c=NULL,  delta.designmatrix=NULL,
  delta.init=NULL, delta.fixed=NULL, delta.linkfct="log",
  Xlambda_positive=NULL, regular_type="lasso", regular_lam=0, regular_w=NULL,
  regular_n=nrow(data), maxiter=1000, conv=1e-5, globconv=1e-5, msteps=10,
  convM=5e-04, decrease.increments=FALSE, oldfac=0, dampening_factor=1.01,
  seed=NULL, progress=TRUE, PEM=TRUE, PEM_itermax=maxiter, ...)

## S3 method for class 'slca'
summary(object, file=NULL, ...)

## S3 method for class 'slca'
print(x, ...)

## S3 method for class 'slca'
plot(x, group=1, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>Matrix of polytomous item responses
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group</code></td>
<td>

<p>Optional vector of group identifiers. For <code>plot.slca</code> it is
a single integer group identified.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>

<p>Optional vector of sample weights
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xdes</code></td>
<td>

<p>Design matrix for <code class="reqn">x_{ijh}</code> with <code class="reqn"> q_{ihjv}</code> entries.
Therefore, it must be an array with four dimensions referring to
items (<code class="reqn">i</code>), categories (<code class="reqn">h</code>), latent classes (<code class="reqn">j</code>) and
<code class="reqn">\lambda</code> parameters (<code class="reqn">v</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda.init</code></td>
<td>

<p>Initial <code class="reqn">\lambda_x</code> parameters
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda.fixed</code></td>
<td>

<p>Fixed <code class="reqn">\lambda_x</code> parameters. These must be provided by a matrix
with two columns: 1st column â€“ Parameter index, 2nd column:
Fixed value.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda.constr.V</code></td>
<td>
<p>A design matrix for linear restrictions of the
form <code class="reqn">V_x \lambda_x=c_x</code> for the <code class="reqn">\lambda_x</code> parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda.constr.c</code></td>
<td>
<p>A vector for the linear restriction
<code class="reqn">V_x \lambda_x=c_x</code> of the <code class="reqn">\lambda_x</code> parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta.designmatrix</code></td>
<td>

<p>Design matrix for delta parameters <code class="reqn">\delta</code>
parameterizing the latent class distribution by log-linear smoothing
(Xu &amp; von Davier, 2008)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta.init</code></td>
<td>

<p>Initial <code class="reqn">\delta</code> parameters
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta.fixed</code></td>
<td>

<p>Fixed <code class="reqn">\delta</code> parameters. This must be a matrix with three columns:
1st column: Parameter index, 2nd column: Group index, 3rd column: Fixed value
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta.linkfct</code></td>
<td>
<p>Link function for skill space reduction.
This can be the log-linear link (<code>log</code>) or the
logistic link function (<code>logit</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda_positive</code></td>
<td>
<p>Optional vector of logical indicating which
elements of <code class="reqn">\bold{\lambda}_x</code> should be constrained to be
positive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regular_type</code></td>
<td>
<p>Regularization method which can be <code>lasso</code>,
<code>scad</code> or <code>mcp</code>. See <code>gdina</code> for more
information and references.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regular_lam</code></td>
<td>
<p>Numeric. Regularization parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regular_w</code></td>
<td>
<p>Vector for weighting the regularization penalty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regular_n</code></td>
<td>
<p>Vector of regularization factor. This will be
typically the sample size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>

<p>Maximum number of iterations
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv</code></td>
<td>

<p>Convergence criterion for item parameters and
distribution parameters
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>globconv</code></td>
<td>

<p>Global deviance convergence criterion
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>msteps</code></td>
<td>

<p>Maximum number of M steps in estimating <code class="reqn">b</code> and
<code class="reqn">a</code> item parameters. The default is to use 4 M steps.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convM</code></td>
<td>

<p>Convergence criterion in M step
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decrease.increments</code></td>
<td>
<p>Should in the M step the increments
of <code class="reqn">a</code> and <code class="reqn">b</code> parameters decrease during iterations?
The default is <code>FALSE</code>. If there is an increase in deviance
during estimation, setting <code>decrease.increments</code> to <code>TRUE</code>
is recommended.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>oldfac</code></td>
<td>
<p>Factor <code class="reqn">f</code> between 0 and 1 to control convergence behavior.
If <code class="reqn">x_t</code> denotes the estimated parameter in iteration <code class="reqn">t</code>,
then the regularized estimate <code class="reqn">x_t^{\ast}</code> is obtained by
<code class="reqn">x_t^{\ast}=f x_{t-1} + (1-f) x_t</code>. Therefore, values of
<code>oldfac</code> near to one only allow for small changes in estimated
parameters from in succeeding iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dampening_factor</code></td>
<td>
<p>Factor larger than one defining the specified decrease in
decrements in iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Simulation seed for initial parameters. The default
of <code>NULL</code> corresponds to a random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>
<p>An optional logical indicating whether the function
should print the progress of iteration in the estimation process.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PEM</code></td>
<td>
<p>Logical indicating whether the P-EM acceleration should be
applied (Berlinet &amp; Roland, 2012).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PEM_itermax</code></td>
<td>
<p>Number of iterations in which the P-EM method should be
applied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A required object of class <code>slca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>Optional file name for a file in which <code>summary</code>
should be sinked.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A required object of class <code>slca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional parameters to be passed to or from other
methods will be ignored.  </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The structured latent class model allows for general constraints of items
<code class="reqn">i</code> in categories <code class="reqn">h</code> and classes <code class="reqn">j</code>. The item response model is
</p>
<p style="text-align: center;"><code class="reqn">P( X_{i}=h | j )=\frac{ \exp( x_{ihj} ) }{ \sum_l \exp( x_{ilj} ) }</code>
</p>

<p>with linear constraints on the class specific probabilities
</p>
<p style="text-align: center;"><code class="reqn">  x_{ihj}=\sum_v  q_{ihjv} \lambda_{xv} </code>
</p>

<p>Linear restrictions on the <code class="reqn">\lambda_x</code> parameter can be specified by
a matrix equation <code class="reqn">V_x \lambda_x=c_x</code> (see <code>Xlambda.constr.V</code> and
<code>Xlambda.constr.c</code>; Neuhaus, 1996).
</p>
<p>The latent class distribution can be smoothed by a log-linear
link function (Xu &amp; von Davier, 2008) or a logistic link function
(Formann, 1992). For class <code class="reqn">j</code>
in group <code class="reqn">g</code> employing a link function <code class="reqn">h</code>, it holds that
</p>
<p style="text-align: center;"><code class="reqn"> h [ P( j| g) ] \propto \sum_w   r_{jw}  \delta_{gw} </code>
</p>

<p>where group-specific distributions are allowed. The values
<code class="reqn">r_{jw}</code> are specified in the design matrix <code>delta.designmatrix</code>.
</p>
<p>This model contains classical uni- and multidimensional latent trait models,
latent class analysis, located latent class analysis, cognitive diagnostic
models, the general diagnostic model and mixture item response models as
special cases (see Formann &amp; Kohlmann, 1998; Formann, 2007).
</p>
<p>The function also allows for regularization of <code class="reqn">\lambda_{xv}</code> parameters
using the lasso approach (Sun et al., 2016).
More formally, the penalty function can be written as
</p>
<p style="text-align: center;"><code class="reqn">pen( \bold{\lambda}_x )=p_\lambda \sum_v n_v w_v | \lambda_{xv} | </code>
</p>

<p>where <code class="reqn">p_\lambda</code> can be specified with <code>regular_lam</code>,
<code class="reqn">w_v</code> can be specified with <code>regular_w</code>, and
<code class="reqn">n_v</code> can be specified with <code>regular_n</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>slca</code>. The list contains the
following entries:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>item</code></td>
<td>
<p>Data frame with conditional item probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deviance</code></td>
<td>
<p>Deviance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ic</code></td>
<td>
<p>Information criteria, number of estimated parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda</code></td>
<td>
<p>Estimated <code class="reqn">\lambda_x</code> parameters </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se.Xlambda</code></td>
<td>
<p>Standard error of <code class="reqn">\lambda_x</code> parameters
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi.k</code></td>
<td>
<p>Trait distribution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pjk</code></td>
<td>
<p>Item response probabilities evaluated for all classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.ik</code></td>
<td>
<p>An array of expected counts <code class="reqn">n_{cikg}</code> of ability class <code class="reqn">c</code>
at item <code class="reqn">i</code> at category <code class="reqn">k</code> in group <code class="reqn">g</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>
<p>Number of groups</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>I</code></td>
<td>
<p>Number of items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>Number of persons</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>Parameter estimates for skillspace representation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covdelta</code></td>
<td>
<p>Covariance matrix of parameter estimates for
skillspace representation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MLE.class</code></td>
<td>
<p>Classified skills for each student (MLE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAP.class</code></td>
<td>
<p>Classified skills for each student (MAP)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Original data frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group.stat</code></td>
<td>
<p>Group statistics (sample sizes, group labels)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.xi.aj</code></td>
<td>
<p>Individual likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>
<p>Individual posterior distribution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K.item</code></td>
<td>
<p>Maximal category per item</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time</code></td>
<td>
<p>Info about computation time</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skillspace</code></td>
<td>
<p>Used skillspace parametrization</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>Number of iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed.used</code></td>
<td>
<p>Used simulation seed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xlambda.init</code></td>
<td>
<p>Used initial lambda parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta.init</code></td>
<td>
<p>Used initial delta parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>converged</code></td>
<td>
<p>Logical indicating whether convergence was achieved.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>If some items have differing number of categories, appropriate
class probabilities in non-existing categories per items can be
practically set to zero by loading an item for all skill classes
on a fixed <code class="reqn">\lambda_x</code> parameter of a small number, e.g. <code>-999</code>.
</p>
<p>The implementation of the model builds on pieces work of Anton Formann.
See <a href="http://www.antonformann.at/">http://www.antonformann.at/</a> for more information.
</p>


<h3>References</h3>

<p>Berlinet, A. F., &amp; Roland, C. (2012).
Acceleration of the EM algorithm: P-EM versus epsilon algorithm.
<em>Computational Statistics &amp; Data Analysis, 56</em>(12), 4122-4137.
</p>
<p>Chen, Y., Liu, J., Xu, G., &amp; Ying, Z. (2015).
Statistical analysis of Q-matrix based diagnostic classification models.
<em>Journal of the American Statistical Association, 110</em>, 850-866.
</p>
<p>Chen, Y., Li, X., Liu, J., &amp; Ying, Z. (2017). Regularized latent class analysis
with application in cognitive diagnosis. <em>Psychometrika,
82</em>, 660-692.
</p>
<p>Formann, A. K. (1985). Constrained latent class models: Theory and applications.
<em>British Journal of Mathematical and Statistical Psychology,
38</em>, 87-111.
</p>
<p>Formann, A. K. (1992). Linear logistic latent class analysis for polytomous data.
<em>Journal of the American Statistical Association, 87</em>, 476-486.
</p>
<p>Formann, A. K. (2007). (Almost) Equivalence between conditional and mixture maximum
likelihood estimates for some models of the Rasch type. In M. von Davier &amp; C. H. Carstensen
(Eds.), <em>Multivariate and mixture distribution Rasch models</em> (pp. 177-189).
New York: Springer.
</p>
<p>Formann, A. K., &amp; Kohlmann, T. (1998). Structural latent class models.
<em>Sociological Methods &amp; Research, 26</em>, 530-565.
</p>
<p>Neuhaus, W. (1996). Optimal estimation under
linear constraints. <em>Astin Bulletin, 26</em>, 233-245.
</p>
<p>Sun, J., Chen, Y., Liu, J., Ying, Z., &amp; Xin, T. (2016).
Latent variable selection for multidimensional item response theory models
via <code class="reqn">L_1</code> regularization. <em>Psychometrika, 81</em>(4), 921-939.
</p>
<p>Xu, X., &amp; von Davier, M. (2008). <em>Fitting the structured general diagnostic
model to NAEP data</em>. ETS Research Report ETS RR-08-27. Princeton, ETS.
</p>


<h3>See Also</h3>

<p>For latent trait models with continuous latent variables see the
<span class="pkg">mirt</span> or <b>TAM</b> packages. For a discrete trait distribution see
the <span class="pkg">MultiLCIRT</span> package.
</p>
<p>For latent class models see the <span class="pkg">poLCA</span>, <span class="pkg">covLCA</span> or <span class="pkg">randomLCA</span>
package.
</p>
<p>For mixture Rasch or mixture IRT models see the <span class="pkg">psychomix</span> or
<span class="pkg">mRm</span> package.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#############################################################################
# EXAMPLE 1: data.Students | (Generalized) Partial Credit Model
#############################################################################

data(data.Students, package="CDM")

dat &lt;- data.Students[, c("mj1","mj2","mj3","mj4","sc1", "sc2") ]
# define discretized ability
theta.k &lt;- seq( -6, 6, len=21 )

#*** Model 1: Partial credit model

# define design matrix for lambda
I &lt;- ncol(dat)
maxK &lt;- 4
TP &lt;- length(theta.k)
NXlam &lt;- I*(maxK-1) + 1       # number of estimated parameters
       # last parameter is joint slope parameter
Xdes &lt;- array( 0, dim=c(I, maxK, TP,  NXlam ) )
# Item1Cat1, ..., Item1Cat3, Item2Cat1, ...,
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[3]] &lt;- paste0("Class", 1:TP )
v2 &lt;- unlist( sapply( 1:I, FUN=function(ii){ # ii
    paste0( paste0( colnames(dat)[ii], "_b"  ), "Cat", 1:(maxK-1) )
                }, simplify=FALSE) )
dimnames(Xdes)[[4]] &lt;- c( v2, "a" )
# define theta design and item discriminations
for (ii in 1:I){
    for (hh in 1:(maxK-1) ){
        Xdes[ii, hh + 1,, NXlam ] &lt;- hh * theta.k
    }
}
# item intercepts
for (ii in 1:I){
    for (hh in 1:(maxK-1) ){
        # ii &lt;- 1  # Item    # hh &lt;- 1  # category
        Xdes[ii,hh+1,, ( ii - 1)*(maxK-1) + hh] &lt;- 1
    }
}
#****
# skill space designmatrix
TP &lt;- length(theta.k)
w1 &lt;- stats::dnorm(theta.k)
w1 &lt;- w1 / sum(w1)
delta.designmatrix &lt;- matrix( 1, nrow=TP, ncol=1 )
delta.designmatrix[,1] &lt;- log(w1)

# initial lambda parameters
Xlambda.init &lt;- c( stats::rnorm( dim(Xdes)[[4]] - 1 ), 1 )
# fixed delta parameter
delta.fixed &lt;- cbind( 1, 1,1 )

# estimate model
mod1 &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            Xlambda.init=Xlambda.init, delta.fixed=delta.fixed )
summary(mod1)
plot(mod1, cex.names=.7 )

## Not run: 
#*** Model 2: Partial credit model with some parameter constraints
# fixed lambda parameters
Xlambda.fixed &lt;- cbind( c(1,19), c(3.2,1.52 ) )
# 1st parameter=3.2
# 19th parameter=1.52 (joint item slope)
mod2 &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            delta.init=delta.init, Xlambda.init=Xlambda.init, delta.fixed=delta.fixed,
            Xlambda.fixed=Xlambda.fixed, maxiter=70 )

#*** Model 3: Partial credit model with non-normal distribution
Xlambda.fixed &lt;- cbind(  c(1,19), c(3.2,1) ) # fix item slope to one
delta.designmatrix &lt;- cbind( 1, theta.k, theta.k^2, theta.k^3 )
mod3 &lt;- CDM::slca( dat, Xdes=Xdes,  delta.designmatrix=delta.designmatrix,
            Xlambda.fixed=Xlambda.fixed,  maxiter=200 )
summary(mod3)

# non-normal distribution with convergence regularizing factor oldfac
mod3a &lt;- CDM::slca( dat, Xdes=Xdes,  delta.designmatrix=delta.designmatrix,
            Xlambda.fixed=Xlambda.fixed, maxiter=500, oldfac=.95 )
summary(mod3a)

#*** Model 4: Generalized Partial Credit Model

# estimate generalized partial credit model without restrictions on trait
# distribution and item parameters to ensure better convergence behavior
# Note that two parameters are not identifiable and information criteria
# have to be adapted.

#---
# define design matrix for lambda
I &lt;- ncol(dat)
maxK &lt;- 4
TP &lt;- length(theta.k)
NXlam &lt;- I*(maxK-1) + I       # number of estimated parameters
Xdes &lt;- array( 0, dim=c(I, maxK, TP,  NXlam ) )
# Item1Cat1, ..., Item1Cat3, Item2Cat1, ...,
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[3]] &lt;- paste0("Class", 1:TP )
v2 &lt;- unlist( sapply( 1:I, FUN=function(ii){ # ii
    paste0( paste0( colnames(dat)[ii], "_b"  ), "Cat", 1:(maxK-1) )
                }, simplify=FALSE) )
dimnames(Xdes)[[4]] &lt;- c( v2, paste0( colnames(dat),"_a") )
dimnames(Xdes)
# define theta design and item discriminations
for (ii in 1:I){
    for (hh in 1:(maxK-1) ){
        Xdes[ii, hh + 1,, I*(maxK-1) + ii ] &lt;- hh * theta.k
    }
}
# item intercepts
for (ii in 1:I){
    for (hh in 1:(maxK-1) ){
        Xdes[ii,hh+1,, ( ii - 1)*(maxK-1) + hh] &lt;- 1
    }
}
#****
# skill space designmatrix
delta.designmatrix &lt;- cbind( 1, theta.k,theta.k^2 )
# initial lambda parameters from partial credit model
Xlambda.init &lt;- mod1$Xlambda
Xlambda.init &lt;- c( mod1$Xlambda[ - length(Xlambda.init) ],
         rep( Xlambda.init[ length(Xlambda.init)  ],I) )

# estimate model
mod4 &lt;- CDM::slca( dat, Xdes=Xdes, Xlambda.init=Xlambda.init,
             delta.designmatrix=delta.designmatrix, decrease.increments=TRUE,
             maxiter=300 )

#############################################################################
# EXAMPLE 2: Latent class model with two classes
#############################################################################

set.seed(9876)
I &lt;- 7    # number of items
# simulate response probabilities
a1 &lt;- stats::runif(I, 0, .4 )
a2 &lt;- stats::runif(I, .6, 1 )
N &lt;- 1000    # sample size
# simulate data in two classes of proportions .3 and .7
N1 &lt;- round(.3*N)
dat1 &lt;- 1 * ( matrix(a1,N1,I,byrow=TRUE) &gt; matrix( stats::runif( N1 * I), N1, I ) )
N2 &lt;- round(.7*N)
dat2 &lt;- 1 * ( matrix(a2,N2,I,byrow=TRUE) &gt; matrix( stats::runif( N2 * I), N2, I ) )
dat &lt;- rbind( dat1, dat2 )
colnames(dat) &lt;- paste0("I", 1:I)

# define design matrices
TP &lt;- 2     # two classes
# The idea is that latent classes refer to two different "dimensions".
# Items load on latent class indicators 1 and 2, see below.
Xdes &lt;- array(0, dim=c(I,2,2,2*I) )
items &lt;- colnames(dat)
dimnames(Xdes)[[4]] &lt;- c(paste0( colnames(dat), "Class", 1),
          paste0( colnames(dat), "Class", 2) )
    # items, categories, classes, parameters
# probabilities for correct solution
for (ii in 1:I){
    Xdes[ ii, 2, 1, ii ] &lt;- 1    # probabilities class 1
    Xdes[ ii, 2, 2, ii+I ] &lt;- 1  # probabilities class 2
}
# estimate model
mod1 &lt;- CDM::slca( dat, Xdes=Xdes )
summary(mod1)

#############################################################################
# EXAMPLE 3: Mixed Rasch model with two classes
#############################################################################

set.seed(987)
library(sirt)
# simulate two latent classes of Rasch populations
I &lt;- 15  # 6 items
b1 &lt;- seq( -1.5, 1.5, len=I)      # difficulties latent class 1
b2 &lt;- b1    # difficulties latent class 2
b2[ c(4,7, 9, 11, 12, 13) ] &lt;- c(1, -.5, -.5, .33, .33, -.66 )
N &lt;- 3000    # number of persons
wgt &lt;- .25       # class probability for class 1
# class 1
dat1 &lt;- sirt::sim.raschtype( stats::rnorm( wgt*N ), b1 )
# class 2
dat2 &lt;- sirt::sim.raschtype( stats::rnorm( (1-wgt)*N, mean=1, sd=1.7), b2 )
dat &lt;- rbind( dat1, dat2 )
# theta grid
theta.k &lt;- seq( -5, 5, len=9 )
TP &lt;- length(theta.k)

#*** Model 1: Rasch model with normal distribution
maxK &lt;- 2
NXlam &lt;- I +1
Xdes &lt;- array( 0, dim=c(I, maxK, TP,  NXlam ) )
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[4]] &lt;- c( paste0( "b_", colnames(dat)[1:I] ), "a" )
# define item difficulties
for (ii in 1:I){
    Xdes[ii, 2,, ii ] &lt;- -1
}
# theta design
for (tt in 1:TP){
    Xdes[1:I, 2, tt, I + 1] &lt;- theta.k[tt]
}

# skill space definition
delta.designmatrix &lt;- cbind( 1, theta.k^2 )
delta.fixed &lt;- NULL
Xlambda.init &lt;- c( stats::runif( I, -.8, .8 ), 1 )
Xlambda.fixed &lt;- cbind( I+1, 1 )
# estimate model
mod1 &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            delta.fixed=delta.fixed, Xlambda.fixed=Xlambda.fixed,
            Xlambda.init=Xlambda.init, decrease.increments=TRUE, maxiter=200 )
summary(mod1)

#*** Model 1b: Constraint the sum of item difficulties to zero

# change skill space definition
delta.designmatrix &lt;- cbind( 1, theta.k, theta.k^2 )
delta.fixed &lt;- NULL
# constrain sum of difficulties Xlambda parameters to zero
Xlambda.constr.V &lt;- matrix( 1, nrow=I+1, ncol=1 )
Xlambda.constr.V[I+1,1] &lt;- 0
Xlambda.constr.c &lt;- c(0)
# estimate model
mod1b &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            Xlambda.fixed=Xlambda.fixed, Xlambda.constr.V=Xlambda.constr.V,
            Xlambda.constr.c=Xlambda.constr.c  )
summary(mod1b)

#*** Model 2: Mixed Rasch model with two latent classes
NXlam &lt;- 2*I +2
Xdes &lt;- array( 0, dim=c(I, maxK, 2*TP,  NXlam ) )
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[4]] &lt;- c( paste0( "bClass1_", colnames(dat)[1:I] ),
        paste0( "bClass2_", colnames(dat)[1:I] ), "aClass1", "aClass2" )
# define item difficulties
for (ii in 1:I){
    Xdes[ii, 2, 1:TP, ii ] &lt;- -1  # first class
    Xdes[ii, 2, TP + 1:TP, I+ii ] &lt;- -1  # second class
}
# theta design
for (tt in 1:TP){
    Xdes[1:I, 2, tt, 2*I+1 ] &lt;- theta.k[tt]
    Xdes[1:I, 2, TP+tt, 2*I+2 ] &lt;- theta.k[tt]
}
# skill space definition
delta.designmatrix &lt;- matrix( 0, nrow=2*TP, ncol=4 )
delta.designmatrix[1:TP,1] &lt;- 1
delta.designmatrix[1:TP,2] &lt;- theta.k^2
delta.designmatrix[TP + 1:TP,3] &lt;- 1
delta.designmatrix[TP+ 1:TP,4] &lt;- theta.k^2
b1 &lt;- stats::qnorm( colMeans(dat) )
Xlambda.init &lt;- c( stats::runif( 2*I, -1.8, 1.8 ), 1,1 )
Xlambda.fixed &lt;- cbind( c(2*I+1, 2*I+2), 1 )
# estimate model
mod2 &lt;- CDM::slca( dat, Xdes=Xdes,  delta.designmatrix=delta.designmatrix,
            Xlambda.fixed=Xlambda.fixed, decrease.increments=TRUE,
            Xlambda.init=Xlambda.init, maxiter=1000 )
summary(mod2)
summary(mod1)
# latent class proportions
stats::aggregate( mod2$pi.k, list( rep(1:2, each=TP)), sum )

#*** Model 2b: Different parametrization with sum constraint on item difficulties

# skill space definition
delta.designmatrix &lt;- matrix( 0, nrow=2*TP, ncol=6 )
delta.designmatrix[1:TP,1] &lt;- 1
delta.designmatrix[1:TP,2] &lt;- theta.k
delta.designmatrix[1:TP,3] &lt;- theta.k^2
delta.designmatrix[TP+ 1:TP,4] &lt;- 1
delta.designmatrix[TP+ 1:TP,5] &lt;- theta.k
delta.designmatrix[TP+ 1:TP,6] &lt;- theta.k^2
Xlambda.fixed &lt;- cbind( c(2*I+1,2*I+2), c(1,1) )
b1 &lt;- stats::qnorm( colMeans( dat ) )
Xlambda.init &lt;- c( b1, b1 + stats::runif(I, -1, 1 ), 1, 1 )
# constraints on item difficulties
Xlambda.constr.V &lt;- matrix( 0, nrow=NXlam, ncol=2)
Xlambda.constr.V[1:I, 1 ] &lt;- 1
Xlambda.constr.V[I + 1:I, 2 ] &lt;- 1
Xlambda.constr.c &lt;- c(0,0)
# estimate model
mod2b &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            Xlambda.fixed=Xlambda.fixed,  Xlambda.init=Xlambda.init,
            Xlambda.constr.V=Xlambda.constr.V, Xlambda.constr.c=Xlambda.constr.c,
            decrease.increments=TRUE, maxiter=1000 )
summary(mod2b)
stats::aggregate( mod2b$pi.k, list( rep(1:2, each=TP)), sum )

#*** Model 2c: Estimation with mRm package
library(mRm)
mod2c &lt;- mRm::mrm(data.matrix=dat, cl=2)
plot(mod2c)
print(mod2c)

#*** Model 2d: Estimation with psychomix package
library(psychomix)
mod2d &lt;- psychomix::raschmix(data=dat, k=2, verbose=TRUE )
summary(mod2d)
plot(mod2d)

#############################################################################
# EXAMPLE 4: Located latent class model, Rasch model
#############################################################################

set.seed(487)
library(sirt)
I &lt;- 15  # I items
b1 &lt;- seq( -2, 2, len=I)      # item difficulties
N &lt;- 4000    # number of persons
# simulate 4 theta classes
theta0 &lt;- c( -2.5, -1, 0.3, 1.3 )  # skill classes
probs0 &lt;- c( .1, .4, .2, .3 )
TP &lt;- length(theta0)
theta &lt;- theta0[ rep(1:TP, round(probs0*N)  ) ]
dat &lt;- sirt::sim.raschtype( theta, b1 )

#*** Model 1: Located latent class model with 4 classes
maxK &lt;- 2
NXlam &lt;- I + TP
Xdes &lt;- array( 0, dim=c(I, maxK, TP,  NXlam ) )
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[3]] &lt;- paste0("Class", 1:TP )
dimnames(Xdes)[[4]] &lt;- c( paste0( "b_", colnames(dat)[1:I] ), paste0("theta", 1:TP) )
# define item difficulties
for (ii in 1:I){
    Xdes[ii, 2,, ii ] &lt;- -1
}
# theta design
for (tt in 1:TP){
    Xdes[1:I, 2, tt, I + tt] &lt;- 1
}

# skill space definition
delta.designmatrix &lt;- diag(TP)
Xlambda.init &lt;- c( - stats::qnorm( colMeans(dat) ), seq(-2,1,len=TP)  )
# constraint on item difficulties
Xlambda.constr.V &lt;- matrix( 0, nrow=NXlam, ncol=1)
Xlambda.constr.V[1:I,1] &lt;- 1
Xlambda.constr.c &lt;- c(0)
delta.init &lt;- matrix( c(1,1,1,1), TP, 1 )
# estimate model
mod1 &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            delta.init=delta.init, Xlambda.init=Xlambda.init,
            Xlambda.constr.V=Xlambda.constr.V, Xlambda.constr.c=Xlambda.constr.c,
            decrease.increments=TRUE,  maxiter=400 )
summary(mod1)
# compare estimated and simulated theta class locations
cbind( mod1$Xlambda[ - c(1:I) ], theta0 )
# compare estimated and simulated latent class proportions
cbind( mod1$pi.k, probs0 )

#############################################################################
# EXAMPLE 5: DINA model with two skills
#############################################################################

set.seed(487)
N &lt;- 3000   # number of persons
# define Q-matrix
I &lt;- 9  # 9 items
NS &lt;- 2 # 2 skills
TP &lt;- 4 # number of skill classes
Q &lt;- scan( nlines=3)
  1 0   1 0   1 0
  0 1   0 1   0 1
  1 1   1 1   1 1
Q &lt;- matrix(Q, I, ncol=NS,byrow=TRUE)
# define skill distribution
alpha0 &lt;- matrix( c(0,0,1,0,0,1,1,1), nrow=4,ncol=2,byrow=TRUE)
prob0 &lt;- c( .2, .4, .1, .3 )
alpha &lt;- alpha0[ rep( 1:TP, prob0*N),]
# define guessing and slipping parameters
guess &lt;- round( stats::runif(I, 0, .4 ), 2 )
slip &lt;- round( stats::runif(I, 0, .3 ), 2 )
# simulate data according to the DINA model
dat &lt;- CDM::sim.din( q.matrix=Q, alpha=alpha, slip=slip, guess=guess )$dat

# define Xlambda design matrix
maxK &lt;- 2
NXlam &lt;- 2*I
Xdes &lt;- array( 0, dim=c(I, maxK, TP,  NXlam ) )
dimnames(Xdes)[[1]] &lt;- colnames(dat)
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 1:(maxK) )
dimnames(Xdes)[[3]] &lt;- c("S00","S10","S01","S11")
dimnames(Xdes)[[4]] &lt;- c( paste0("guess",1:I ), paste0( "antislip", 1:I ) )
dimnames(Xdes)
# define item difficulties
for (ii in 1:I){
        # define latent responses
        latresp &lt;- 1*( alpha0 %*% Q[ii,]==sum(Q[ii,]) )[,1]
        # model slipping parameters
        Xdes[ii, 2, latresp==1, I+ii ] &lt;- 1
        # guessing parameters
        Xdes[ii, 2, latresp==0, ii ] &lt;- 1
}
Xdes[1,2,,]
Xdes[7,2,,]
# skill space definition
delta.designmatrix &lt;- diag(TP)
Xlambda.init &lt;- c( rep( stats::qlogis( .2 ), I ), rep( stats::qlogis( .8 ), I ) )

# estimate DINA model with slca function
mod1 &lt;- CDM::slca( dat, Xdes=Xdes, delta.designmatrix=delta.designmatrix,
            Xlambda.init=Xlambda.init, decrease.increments=TRUE, maxiter=400 )
summary(mod1)

# compare estimated and simulated latent class proportions
cbind( mod1$pi.k, probs0 )
# compare estimated and simulated guessing parameters
cbind( mod1$pjk[1,,2], guess )
# compare estimated and simulated slipping parameters
cbind( 1 - mod1$pjk[4,,2], slip )

#############################################################################
# EXAMPLE 6: Investigating differential item functioning in Rasch models
#            with regularization
#############################################################################

#---- simulate data
set.seed(987)
N &lt;- 1000   # number of persons in a group
I &lt;- 20    # number of items
#* population parameters of two groups
mu1 &lt;- 0
mu2 &lt;- .6
sd1 &lt;- 1.4
sd2 &lt;- 1
# item difficulties
b &lt;- seq( -1.1, 1.1, len=I )
# define some DIF effects
dif &lt;- rep(0,I)
dif[ c(3,6,9,12)] &lt;- c( .6, -1, .75, -.35 )
print(dif)
#* simulate datasets
dat1 &lt;- sirt::sim.raschtype( rnorm(N, mean=mu1, sd=sd1), b=b - dif /2 )
colnames(dat1) &lt;- paste0("I", 1:I, "_G1")
dat2 &lt;- sirt::sim.raschtype( rnorm(N, mean=mu2, sd=sd2), b=b + dif /2 )
colnames(dat2) &lt;- paste0("I", 1:I, "_G2")
dat &lt;- CDM::CDM_rbind_fill( dat1, dat2 )
dat &lt;- data.frame( "group"=rep(1:2, each=N), dat )

#-- nodes for distribution
theta.k &lt;- seq(-4, 4, len=11)
# define design matrix for lambda
nitems &lt;- ncol(dat) - 1
maxK &lt;- 2
TP &lt;- length(theta.k)
NXlam &lt;- 2*I + 1
Xdes &lt;- array( 0, dim=c( nitems, maxK, TP,  NXlam  ) )
dimnames(Xdes)[[1]] &lt;- colnames(dat)[-1]
dimnames(Xdes)[[2]] &lt;- paste0("Cat", 0:(maxK-1) )
dimnames(Xdes)[[3]] &lt;- paste0("Theta", 1:TP )
dimnames(Xdes)[[4]] &lt;- c( paste0("b", 1:I ), paste0("dif", 1:I ), "const" )
# define theta design
for (ii in 1:nitems){
    Xdes[ii,2,,NXlam ] &lt;- theta.k
}
# item intercepts and DIF effects
for (ii in 1:I){
    Xdes[c(ii,ii+I),2,, ii ] &lt;- -1
    Xdes[ii,2,,ii+I] &lt;- - 1/2
    Xdes[ii+I,2,,ii+I] &lt;- 1/2
}
#--- skill space designmatrix
TP &lt;- length(theta.k)
w1 &lt;- stats::dnorm(theta.k)
w1 &lt;- w1 / sum(w1)
delta.designmatrix &lt;- matrix( 1, nrow=TP, ncol=2 )
delta.designmatrix[,2] &lt;- log(w1)

# fixed lambda parameters
Xlambda.fixed &lt;- cbind(NXlam, 1 )
# initial Xlambda parameters
dif_sim &lt;- 0*stats::rnorm(I, sd=.2)
Xlambda.init &lt;- c( - stats::qnorm( colMeans(dat1) ), dif_sim, 1 )

# delta.fixed
delta.fixed &lt;- cbind( 1, 1, 0 )
# regularization parameter
regular_lam &lt;- .2
# weighting vector: regularize only DIF effects
regular_w &lt;- c( rep(0,I), rep(1,I), 0 )

#--- estimation model with scad penalty
mod1 &lt;- CDM::slca( dat[,-1], group=dat$group, Xdes=Xdes,
            delta.designmatrix=delta.designmatrix, regular_type="scad",
            Xlambda.init=Xlambda.init, delta.fixed=delta.fixed, Xlambda.fixed=Xlambda.fixed,
            regular_lam=regular_lam, regular_w=regular_w )
# compare true and estimated DIF effects
cbind( "true"=dif, "estimated"=round(coef(mod1)[seq(I+1,2*I)],2) )
summary(mod1)

## End(Not run)
</code></pre>


</div>