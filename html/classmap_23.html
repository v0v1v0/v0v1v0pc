<div class="container">

<table style="width: 100%;"><tr>
<td>vcr.svm.train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Prepare for visualization of a support vector machine classification on training data.
</h2>

<h3>Description</h3>

<p>Produces output for the purpose of constructing graphical displays such as the <code>classmap</code>. The user first needs to run a support vector machine classification on the data by <code>e1071::svm</code>, with the option <code>probability = TRUE</code>. This classification can be with two or more classes. The output of <code>e1071::svm</code> is then an argument to <code>vcr.svm.train</code>. As <code>e1071::svm</code> does not output the data itself, it needs to be given as well, in the arguments <code>X</code> and <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vcr.svm.train(X, y, svfit, ortho = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>matrix of data coordinates, as used in <code>e1071::svm</code>. Missing values are not allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>factor with the given (observed) class labels. It is crucial that X and y are exactly the same as in the call to <code>e1071::svm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>svfit</code></td>
<td>
<p>an object returned by <code>e1071::svm</code>, called with exactly the same <code>X</code> and <code>y</code> as above.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ortho</code></td>
<td>
<p>If <code>TRUE</code>, will compute farness in the orthogonal complement of the vector beta given by <code>e1071::svm</code>. Is only possible for 2 classes, else there would be several beta vectors.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with components: <br></p>
<table>
<tr style="vertical-align: top;">
<td><code>yint</code></td>
<td>
<p>number of the given class of each case. Can contain <code>NA</code>'s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>given class label of each case. Can contain <code>NA</code>'s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>levels</code></td>
<td>
<p>levels of the response <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predint</code></td>
<td>
<p>predicted class number of each case. Always exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predicted label of each case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>altint</code></td>
<td>
<p>number of the alternative class. Among the classes different from the given class, it is the one with the highest posterior probability. Is <code>NA</code> for cases whose <code>y</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>altlab</code></td>
<td>
<p>label of the alternative class. Is <code>NA</code> for cases whose <code>y</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PAC</code></td>
<td>
<p>probability of the alternative class. Is <code>NA</code> for cases whose <code>y</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>figparams</code></td>
<td>
<p>parameters used in <code>fig</code>, can be used for new data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fig</code></td>
<td>
<p>distance of each case <code class="reqn">i</code> from each class <code class="reqn">g</code>. Always exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>farness</code></td>
<td>
<p>farness of each case from its given class. Is <code>NA</code> for cases whose <code>y</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ofarness</code></td>
<td>
<p>for each case <code class="reqn">i</code>, its lowest <code>fig[i,g]</code> to any class <code>g</code>. Always exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>svfit</code></td>
<td>
<p>as it was input, will be useful for new data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the matrix of data coordinates from the arguments. This is useful for classifying new data.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Raymaekers J., Rousseeuw P.J.
</p>


<h3>References</h3>

<p>Raymaekers J., Rousseeuw P.J., Hubert M. (2021). Class maps for visualizing classification results. <em>Technometrics</em>, appeared online. doi: <a href="https://doi.org/10.1080/00401706.2021.1927849">10.1080/00401706.2021.1927849</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code>vcr.knn.newdata</code>, <code>classmap</code>, <code>silplot</code>, <code>stackedplot</code>, <code>e1071::svm</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(e1071)
set.seed(1); X &lt;- matrix(rnorm(200 * 2), ncol = 2)
X[1:100, ] &lt;- X[1:100, ] + 2
X[101:150, ] &lt;- X[101:150, ] - 2
y &lt;- as.factor(c(rep("blue", 150), rep("red", 50)))
cols &lt;- c("deepskyblue3", "red")
plot(X, col = cols[as.numeric(y)], pch = 19)
# We now fit an SVM with radial basis kernel to the data:
set.seed(1) # to make the result of svm() reproducible.
svmfit &lt;- svm(y~., data = data.frame(X = X, y = y),
scale = FALSE, kernel = "radial", cost = 10,
gamma = 1, probability = TRUE)
plot(svmfit$decision.values, col = cols[as.numeric(y)]); abline(h = 0)
# so the decision values separate the classes reasonably well.
plot(svmfit, data = data.frame(X = X, y = y), X.2~X.1, col = cols)
# The boundary is far from linear (but in feature space it is).
vcr.train &lt;- vcr.svm.train(X, y, svfit = svmfit)
confmat.vcr(vcr.train)
stackedplot(vcr.train, classCols = cols)
classmap(vcr.train, "blue", classCols = cols)
classmap(vcr.train, "red", classCols = cols)

# For more examples, we refer to the vignette:
## Not run: 
vignette("Support_vector_machine_examples")

## End(Not run)
</code></pre>


</div>