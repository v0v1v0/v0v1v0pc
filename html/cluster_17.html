<div class="container">

<table style="width: 100%;"><tr>
<td>diana</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>DIvisive ANAlysis Clustering</h2>

<h3>Description</h3>

<p>Computes a divisive hierarchical clustering of the dataset
returning an object of class <code>diana</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">diana(x, diss = inherits(x, "dist"), metric = "euclidean", stand = FALSE,
      stop.at.k = FALSE,
      keep.diss = n &lt; 100, keep.data = !diss, trace.lev = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>data matrix or data frame, or dissimilarity matrix or object,
depending on the value of the <code>diss</code> argument.
</p>
<p>In case of a matrix or data frame, each row corresponds to an observation,
and each column corresponds to a variable.  All variables must be numeric.
Missing values (<code>NA</code>s) <em>are</em> allowed.
</p>
<p>In case of a dissimilarity matrix, <code>x</code> is typically the output
of <code>daisy</code> or <code>dist</code>.  Also a vector of
length n*(n-1)/2 is allowed (where n is the number of observations),
and will be interpreted in the same way as the output of the
above-mentioned functions. Missing values (NAs) are <em>not</em> allowed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diss</code></td>
<td>

<p>logical flag: if TRUE (default for <code>dist</code> or
<code>dissimilarity</code> objects), then <code>x</code> will be considered as a
dissimilarity matrix.  If FALSE, then <code>x</code> will be considered as
a matrix of observations by variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>

<p>character string specifying the metric to be used for calculating
dissimilarities between observations.<br>
The currently available options are "euclidean" and
"manhattan".  Euclidean distances are root sum-of-squares of
differences, and manhattan distances are the sum of absolute
differences.  If <code>x</code> is already a dissimilarity matrix, then
this argument will be ignored.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stand</code></td>
<td>
<p>logical; if true, the measurements in <code>x</code> are
standardized before calculating the dissimilarities.  Measurements
are standardized for each variable (column), by subtracting the
variable's mean value and dividing by the variable's mean absolute
deviation.  If <code>x</code> is already a dissimilarity matrix, then this
argument will be ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stop.at.k</code></td>
<td>
<p>logical or integer, <code>FALSE</code> by default.
Otherwise must be integer, say <code class="reqn">k</code>, in <code class="reqn">\{1,2,..,n\}</code>,
specifying that the <code>diana</code> algorithm should stop early.

Non-default NOT YET IMPLEMENTED.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.diss, keep.data</code></td>
<td>
<p>logicals indicating if the dissimilarities
and/or input data <code>x</code> should be kept in the result.  Setting
these to <code>FALSE</code> can give much smaller results and hence even save
memory allocation <em>time</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace.lev</code></td>
<td>
<p>integer specifying a trace level for printing
diagnostics during the algorithm.  Default <code>0</code> does not print
anything; higher values print increasingly more.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>diana</code> is fully described in chapter 6 of Kaufman and Rousseeuw (1990).
It is probably unique in computing a divisive hierarchy, whereas most
other software for hierarchical clustering is agglomerative.
Moreover, <code>diana</code> provides (a) the divisive coefficient
(see <code>diana.object</code>) which measures the amount of clustering structure
found; and (b) the banner, a novel graphical display
(see <code>plot.diana</code>).
</p>
<p>The <code>diana</code>-algorithm constructs a hierarchy of clusterings,
starting with one large
cluster containing all n observations. Clusters are divided until each cluster
contains only a single observation.<br>
At each stage, the cluster with the largest diameter is selected.
(The diameter of a cluster is the largest dissimilarity between any
two of its observations.)<br>
To divide the selected cluster, the algorithm first looks for its most
disparate observation (i.e., which has the largest average dissimilarity to the
other observations of the selected cluster). This observation initiates the
"splinter group". In subsequent steps, the algorithm reassigns observations
that are closer to the "splinter group" than to the "old party". The result
is a division of the selected cluster into two new clusters.
</p>


<h3>Value</h3>

<p>an object of class <code>"diana"</code> representing the clustering;
this class has methods for the following generic functions:
<code>print</code>, <code>summary</code>, <code>plot</code>.
</p>
<p>Further, the class <code>"diana"</code> inherits from
<code>"twins"</code>.  Therefore, the generic function <code>pltree</code> can be
used on a <code>diana</code> object, and <code>as.hclust</code> and
<code>as.dendrogram</code> methods are available.
</p>
<p>A legitimate <code>diana</code> object is a list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>

<p>a vector giving a permutation of the original observations to allow for
plotting, in the sense that the branches of a clustering tree will
not cross.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order.lab</code></td>
<td>

<p>a vector similar to <code>order</code>, but containing observation labels
instead of observation numbers.  This component is only available if
the original observations were labelled.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>height</code></td>
<td>
<p>a vector with the diameters of the clusters prior to splitting.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dc</code></td>
<td>

<p>the divisive coefficient, measuring the clustering structure of the
dataset.  For each observation i, denote by <code class="reqn">d(i)</code> the diameter of the
last cluster to which it belongs (before being split off as a single
observation), divided by the diameter of the whole dataset.  The
<code>dc</code> is the average of all <code class="reqn">1 - d(i)</code>.  It can also be seen
as the average width (or the percentage filled) of the banner plot.
Because <code>dc</code> grows with the number of observations, this
measure should not be used to compare datasets of very different
sizes.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>merge</code></td>
<td>

<p>an (n-1) by 2 matrix, where n is the number of
observations. Row i of <code>merge</code> describes the split at step n-i of
the clustering. If a number <code class="reqn">j</code> in row r is negative, then the single
observation <code class="reqn">|j|</code> is split off at stage n-r. If j is positive, then the
cluster that will be splitted at stage n-j (described by row j), is
split off at stage n-r.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diss</code></td>
<td>

<p>an object of class <code>"dissimilarity"</code>, representing the total
dissimilarity matrix of the dataset.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>a matrix containing the original or standardized measurements, depending
on the <code>stand</code> option of the function <code>agnes</code>.  If a
dissimilarity matrix was given as input structure, then this component
is not available.
</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>agnes</code> also for background and references;
<code>cutree</code> (and <code>as.hclust</code>) for grouping
extraction; <code>daisy</code>, <code>dist</code>,
<code>plot.diana</code>, <code>twins.object</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(votes.repub)
dv &lt;- diana(votes.repub, metric = "manhattan", stand = TRUE)
print(dv)
plot(dv)

## Cut into 2 groups:
dv2 &lt;- cutree(as.hclust(dv), k = 2)
table(dv2) # 8 and 42 group members
rownames(votes.repub)[dv2 == 1]

## For two groups, does the metric matter ?
dv0 &lt;- diana(votes.repub, stand = TRUE) # default: Euclidean
dv.2 &lt;- cutree(as.hclust(dv0), k = 2)
table(dv2 == dv.2)## identical group assignments

str(as.dendrogram(dv0)) # {via as.dendrogram.twins() method}

data(agriculture)
## Plot similar to Figure 8 in ref
## Not run: plot(diana(agriculture), ask = TRUE)

</code></pre>


</div>