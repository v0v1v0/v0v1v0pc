<div class="container">

<table style="width: 100%;"><tr>
<td>Nonparametric Approach to CA and CC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Computes classification accuracy and consistency using Lathrop and Cheng's (2014) nonparametric approach.
</h2>

<h3>Description</h3>


<p>Computes classification accuracy and consistency with Lathrop &amp; Cheng's (2014) approach. First, the kernel-smoothed estimate of the probability of a correct response, conditional on observed total score, is found with <code>pnr()</code>. Then, the method proceeds similar to <code>class.Lee()</code>. Using the nonparametric approach does not require a parametric IRT model, keeps the problem on the total score scale, and can produce more accurate CA and CC estimates when the IRT model's assumptions are violated (see Lathrop &amp; Cheng, 2014).
</p>


<h3>Usage</h3>

<pre><code class="language-R">Lee.pnr(cutscore, pnr.out)
pnr(resp, bw.g = NULL, alpha = .5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>cutscore</code></td>
<td>


<p>A scalar or vector of cut scores on the total score scale. Should not include 0 or the max total score, as the end points are added internally.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pnr.out</code></td>
<td>

<p>The output from <code>pnr()</code>. It is a list of length 3 where
</p>
<p><code>pnr.out[[1]]</code> is a vector of T evaluation points on the total score scale (integers from 0 to the max total score)
</p>
<p><code>pnr.out[[2]]</code> is a vector of the observed density at each evaluation point
</p>
<p><code>pnr.out[[3]]</code> is a TxMxJ array. Each slice is an item. Within a slice, rows are for evaluation points and columns are for the probability of the score category. This has a similar structure to <code>Pij</code> seen in <code>Lee.poly()</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resp</code></td>
<td>

<p>The response data matrix with rows as subjects and columns as items. Because the method is based on total score, the method is not robust to missing data. Any <code>NA</code> in <code>resp</code> will propogate to the output.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw.g</code></td>
<td>

<p>The global bandwidth parameter. The default of NULL will estimate the global bandwidth with the optimal (in terms of MSE) estimate of the bandwidth for normally distributed variables. The default is generally a good starting point.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>The adaptivity of the bandwidth parameter. A value of 0 means no adaptation and each evaluation point uses the value in <code>bw.g</code>. For, other values (up to and including 1), the bandwidth parameter will shrink if the evaluation point is in an area of high density and grow when the evaluation point is in an area of low density. A value of 0.5 is default and generally recommended.
</p>
</td>
</tr>
</table>
<h3>Value</h3>



<table>
<tr style="vertical-align: top;">
<td><code>Marginal</code></td>
<td>
<p>A matrix with two columns of marginal accuracy and consistency per cut score (and simultaneous if multiple cutscores are given)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Conditional</code></td>
<td>
<p>A list of two matrixes, one for conditional accuracy and  one for conditional consistency. Each matrix has one row per evaluation point.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The function <code>pnr()</code> is modified from Ramsay's (1991) kernel-smoothed response functions, specifically because they occur conditional total score (and not conditional on a latent trait) and the addition of an adaptive bandwidth (which helps performance when the distribution of total scores is not normal.)
</p>
<p>There is no "D" method of marginalization (as there is for <code>class.Rud</code> and <code>class.Lee</code>). But if there is a theoretical distribution of total scores, the <code>pnr.out[[2]]</code> can be adjusted to match this theoretical distribution.
</p>


<h3>Author(s)</h3>

<p>Quinn N. Lathrop</p>


<h3>References</h3>

<p>Lathrop, Q. N., &amp; Cheng, Y. (2014). A Nonparametric Approach to Estimate Classification Accuracy and Consistency. Journal of Educational Measurement, 51(3), 318-334.
</p>
<p>Lee, W. (2010) Classification consistency and accuracy for complex assessments using item response theory. Journal of Educational Measurement, 47, 1-17.
</p>
<p>Ramsay, J. O. (1991). Kernel Smoothing Approaches to Item Characteristic Curve Estimation. Psychometrika, 56(4), 611-630.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#Simulate simple response data

params &lt;- matrix(c(1,1,1,1,-2,1,0,1,0,0,0,0),4,3)
theta &lt;- rnorm(100)
rdm &lt;- sim(params, theta)

pnr.out &lt;- pnr(rdm)

resultsNP &lt;- Lee.pnr(3, pnr.out)
</code></pre>


</div>