<div class="container">

<table style="width: 100%;"><tr>
<td>analyze_training</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Visualize training of Neural Network</h2>

<h3>Description</h3>

<p>After training a model with cito, this function helps to analyze the training process and decide on best performing model.
Creates a 'plotly' figure which allows to zoom in and out on training graph
</p>


<h3>Usage</h3>

<pre><code class="language-R">analyze_training(object)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a model created by <code>dnn</code> or <code>cnn</code></p>
</td>
</tr></table>
<h3>Details</h3>

<p>The baseline loss is the most important reference. If the model was not able to achieve a better (lower) loss than the baseline (which is the loss for a intercept only model), the model probably did not converge. Possible reasons include an improper learning rate, too few epochs, or too much regularization. See the <code>?dnn</code> help or the <code>vignette("B-Training_neural_networks")</code>.
</p>


<h3>Value</h3>

<p>a 'plotly' figure
</p>


<h3>Examples</h3>

<pre><code class="language-R">
if(torch::torch_is_installed()){
library(cito)
set.seed(222)
validation_set&lt;- sample(c(1:nrow(datasets::iris)),25)

# Build and train  Network
nn.fit&lt;- dnn(Sepal.Length~., data = datasets::iris[-validation_set,],validation = 0.1)

# show zoomable plot of training and validation losses
analyze_training(nn.fit)

# Use model on validation set
predictions &lt;- predict(nn.fit, iris[validation_set,])

# Scatterplot
plot(iris[validation_set,]$Sepal.Length,predictions)
}

</code></pre>


</div>