<div class="container">

<table style="width: 100%;"><tr>
<td>cpm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Classification Performance Measures
</h2>

<h3>Description</h3>

<p>Calculates multiple performance measures for binary or multiclass classification. Uses known class labels and evaluates against predicted labels.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cpm(x, y, level = NULL, fbeta = NULL, prior = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Known class labels of class numeric, factor, or integer. If factor, converted to class integer in the order of factor levels with integers beginning at 0 (i.e., for binary classification, factor levels become 0 and 1; for multiclass, levels become 0, 1, 2, etc.). 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Predicted class labels of class numeric, factor, or integer. If factor, converted to class integer in the order of factor levels with integers beginning at 0 (i.e., for binary classification, factor levels become 0 and 1; for multiclass, 0, 1, 2, etc.).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>

<p>Optional argument specifying possible class labels. For cases when <code>x</code> or <code>y</code> do not contain all possible classes. Can be of class numeric, integer, or character. Must contain two elements for binary classification, and contain three or more elements for multiclass classification. If integer, integers should be ordered (e.g., binary with <code>c(0, 1)</code>; or three-class with <code>c(0, 1, 2)</code>). Note: if both <code>x</code> and <code>y</code> jointly contain only a single value (e.g., 1), must specify argument <code>level</code> in order to identify classification as binary or multiclass. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fbeta</code></td>
<td>

<p>Optional numeric argument specifying beta value for F-score. Defaults to <code>fbeta = 1</code>, providing an F1-score (i.e., the balanced harmonic mean between precision and recall). Can be any real number.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>

<p>Optional numeric argument specifying weights for classes. Currently only implemented with multiclass problems. Defaults to <code>prior = c(rep(1/llev, llev))</code>, where <code>llev</code> is the number of classes, providing equal importance across classes.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Selecting one class as a negative class and one class as a positive class, binary classification generates four possible outcomes: (1) negative cases classified as positives, called false positives (FP); (2) negative cases classified as negatives, called true negatives (TN); (3) positive cases classified as negatives, called false negatives (FN); and (4) positive cases classified as positives, called true positives (TP). 
</p>
<p>Multiple evaluation measures are calculated using these four outcomes. Measures include: overall error (ERR), also called fraction incorrect;  overall accuracy (ACC), also called fraction correct; true positive rate (TPR), also called recall, hit rate, or sensitivity; false negative rate (FNR), also called miss rate; false positive rate (FPR), also called fall-out; true negative rate (TNR), also called specificity or selectivity; positive predictive value (PPV), also called precision; false discovery rate (FDR); negative predictive value (NPV); false omission rate (FOR); and F-score (FS).
</p>
<p>In multiclass classification, the four outcomes are possible for each individual class in macro-averaging, and performance measures are averaged over classes. Macro-averaging gives equal importance to all classes. For multiclass classification, calculated measures are currently only macro-averaged. See the listed reference in this help file for additional details on micro-averaging.
</p>
<p>For binary classification, this function assumes a negative class and a positive class (i.e., it contains a reference group) and is ordered. Multiclass classification is currently assumed to be unordered. 
</p>
<p>Computational details:
</p>
<p>ERR = (FP + FN) / (TP + TN + FP + FN).
</p>
<p>ACC = (TP + TN) / (TP + TN + FP + FN), and ACC = 1 - ERR.
</p>
<p>TPR = TP / (TP + FN).
</p>
<p>FNR = FN / (FN + TP), and FNR = 1 - TPR.
</p>
<p>FPR = FP / (FP + TN).
</p>
<p>TNR = TN / (TN + FP), and TNR = 1 - FPR.
</p>
<p>PPV = TP / (TP + FP).
</p>
<p>FDR = FP / (FP + TP), and FDR = 1 - PPV.
</p>
<p>NPV = TN / (TN + FN).
</p>
<p>FOR = FN / (FN + TN), and FOR = 1 - NPV.
</p>
<p>FS = (1 + beta^2) * ((PPV * TPR) / (((beta^2)*PPV) + TPR)).
</p>
<p>All performance measures calculated are between 0 and 1, inclusive. For multiclass classification, macro-averaged values are provided for each performance measure. Note that 'beta' in FS represents the relative weight such that recall (TPR) is beta times more important than precision (PPV). See reference for more details.
</p>


<h3>Value</h3>

<p>Returns list where first element is a full confusion matrix <code>cm</code> and where the second element is a data frame containing performance measures. For multiclass classification, macro-averaged values are provided (i.e., each measure is calculated for each class, then averaged over all classes; the average is weighted by argument <code>prior</code> if provided). The second list element contains the following performance measures:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>cm</code></td>
<td>

<p>A confusion matrix with counts for each of the possible outcomes.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>err</code></td>
<td>

<p>Overall error (ERR). Also called fraction incorrect.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>acc</code></td>
<td>

<p>Overall accuracy (ACC). Also called fraction correct.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tpr</code></td>
<td>

<p>True positive rate (TPR). Also called recall, hit rate, or sensitivity.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fpr</code></td>
<td>

<p>False positive rate (FPR). Also called fall-out.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tnr</code></td>
<td>

<p>True negative rate (TNR). Also called specificity or selectivity.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fnr</code></td>
<td>

<p>False negative rate (FNR). Also called miss rate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ppv</code></td>
<td>

<p>Positive predictive value (PPV). Also called precision.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npv</code></td>
<td>

<p>Negative predicted value (NPV).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fdr</code></td>
<td>

<p>False discovery rate (FDR).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fom</code></td>
<td>

<p>False omission rate (FOR).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fs</code></td>
<td>

<p>F-score. Mean between TPR (recall) and PPV (precision) varying by importance 
given to recall over precision (see Details section and argument <code>fbeta</code>). 
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matthew Snodgress &lt;snodg031@umn.edu&gt;
</p>


<h3>References</h3>

<p>Sokolova, M. and Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. Information Processing and Management, 45(4), 427-437.
</p>


<h3>Examples</h3>

<pre><code class="language-R">########## Parafac example with 3-way array and binary response ##########

# set seed and specify dimensions of a three-way tensor
set.seed(3)
mydim &lt;- c(10, 11, 80)
nf &lt;- 3

# create correlation matrix between response and third mode's weights 
rho.cc &lt;- .35 
rho.cy &lt;- .75 
cormat.values &lt;- c(1, rho.cc, rho.cc, rho.cy, rho.cc, 1, rho.cc, rho.cy, 
                   rho.cc, rho.cc, 1, rho.cy, rho.cy, rho.cy, rho.cy, 1)
cormat &lt;- matrix(cormat.values, nrow = (nf + 1), ncol = (nf + 1))

# sample from a multivariate normal with specified correlation structure
ymean &lt;- Cmean &lt;- 2
mu &lt;- as.matrix(c(Cmean, Cmean, Cmean, ymean))
eidecomp &lt;- eigen(cormat, symmetric = TRUE)
L.sqrt &lt;- diag(eidecomp$values^0.5)
cormat.sqrt &lt;- eidecomp$vectors %*% L.sqrt %*% t(eidecomp$vectors)
Z &lt;- matrix(rnorm(mydim[3]*(nf + 1)), nrow = mydim[3], ncol = (nf + 1))
Xw &lt;- rep(1, mydim[3]) %*% t(mu) + Z %*% cormat.sqrt
Cmat &lt;- Xw[, 1:nf]

# create a random three-way data tensor with C weights related to a response
Amat &lt;- matrix(rnorm(mydim[1]*nf), nrow = mydim[1], ncol = nf)
Bmat &lt;- matrix(runif(mydim[2]*nf), nrow = mydim[2], ncol = nf)
Xmat &lt;- tcrossprod(Amat, krprod(Cmat, Bmat))
Xmat &lt;- array(Xmat, dim = mydim)
Emat &lt;- array(rnorm(prod(mydim)), dim = mydim)
Emat &lt;- nscale(Emat, 0, ssnew = sumsq(Xmat))  
X &lt;- Xmat + Emat

# create a binary response by dichotomizing at the specified response mean
y &lt;- factor(as.numeric(Xw[ , (nf + 1)] &gt; ymean))

# initialize
gamma &lt;- c(0, 0.01)
cost &lt;- c(1, 2)
method &lt;- c("SVM")
family &lt;- "binomial"
parameters &lt;- list(gamma = gamma, cost = cost)
model &lt;- "parafac"
nfolds &lt;- 3
nstart &lt;- 3

# constrain first mode weights to be orthogonal
const &lt;- c("orthog", "uncons", "uncons")

# fit Parafac models and use third mode to tune classification methods
tune.object &lt;- tunecpfa(x = X, y = y, model = model, nfac = nf, 
                        nfolds = nfolds, method = method, family = family, 
                        parameters = parameters, parallel = FALSE, 
                        const = const, nstart = nstart)
                         
# create new data with Parafac structure and C weights related to response
mydim.new &lt;- c(10, 11, 20)
Znew &lt;- matrix(rnorm(mydim.new[3]*(nf + 1)), 
               nrow = mydim.new[3], ncol = (nf + 1))
Xwnew &lt;- rep(1, mydim.new[3]) %*% t(mu) + Znew %*% cormat.sqrt
Cmatnew &lt;- Xwnew[, 1:nf]
Xnew0 &lt;- tcrossprod(Amat, krprod(Cmatnew, Bmat))
Xnew0 &lt;- array(Xnew0, dim = mydim.new)
Ematnew &lt;- array(rnorm(prod(mydim.new)), dim = mydim.new)
Ematnew &lt;- nscale(Ematnew, 0, ssnew = sumsq(Xnew0))  
Xnew &lt;- Xnew0 + Ematnew

# create new random class labels for two levels
newlabel &lt;- as.numeric(Xwnew[, (nf + 1)] &gt; ymean)

# predict class labels
predict.labels &lt;- predict(object = tune.object, newdata = Xnew, 
                          type = "response")
                        
# calculate performance measures for predicted class labels
y.pred &lt;- predict.labels[, 1]
evalmeasure &lt;- cpm(x = newlabel, y = y.pred)

# print performance measures
evalmeasure
</code></pre>


</div>