<div class="container">

<table style="width: 100%;"><tr>
<td>statistics_calibratR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>statistics_calibratR</h2>

<h3>Description</h3>

<p>this method offers a variety of statistical evaluation methods for the output of the <code>calibrate</code> method.
All returned error values represent mean error values over the <code>n_seeds</code> times repeated 10-fold CV.
</p>


<h3>Usage</h3>

<pre><code class="language-R">statistics_calibratR(calibrate_object, t.test_partitions = TRUE,
  significance_models = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>calibrate_object</code></td>
<td>
<p>list that is returned from the <code>calibrate</code> function. The parameter <code>n_seeds</code> is available as a list component of the <code>calibrate_object</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t.test_partitions</code></td>
<td>
<p>Performs a paired two sided t.test over the error values (ECE, CLE1, CLE0, MCE, AUC, sensitivity and specificity) from the
random partition splits comparing a possible significant difference in mean among the calibration models. All models and the original, scaled and transformed values are tested against each other.
The p_value and the effect size of the t.test are returned to the user. Can only be performed, if the <code>calibrate_object</code> contains a <code>summary_CV</code> list object, else, an error is returned.  Default: TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>significance_models</code></td>
<td>
<p>returns important characteristics of the implemented calibration models, Default: TRUE</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>DETAILS
</p>


<h3>Value</h3>

<p>An object of class list, with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mean_calibration</code></td>
<td>
<p>mean of calibration error values (ECE_equal_width, MCE_equal_width, ECE_equal_freq, MCE_equal_freq, RMSE, Class 1 CLE, Class 0 CLE, Brier Score, Class 1 Brier Score, Class 0 Brier Score) over <code>n_seeds</code> times repeated 10-fold CV.
ECE and MCE are computed once using equal-width and once using equal-frequency binning for the construction of the underlying binning scheme.
Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standard_deviation</code></td>
<td>
<p>standard deviation of calibration error values over <code>n_seeds</code> times repeated 10-fold CV. Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_coeff_calibration</code></td>
<td>
<p>variation coefficient of calibration error values over <code>n_seeds</code> times repeated 10-fold CV. Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean_discrimination</code></td>
<td>
<p>mean of discrimination error (sensitivity, specificity, AUC, positive predictive value, negative predictive value, accuracy) values over <code>n_seeds</code> times repeated 10-fold CV. The "cut-off" is
the cut-off value that maximizes sensitivity and specificity. Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd_discrimination</code></td>
<td>
<p>standard deviation of discrimination error values over <code>n_seeds</code> times repeated 10-fold CV. Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_coeff_discrimination</code></td>
<td>
<p>variation coefficient of discrimination error values over <code>n_seeds</code> times repeated 10-fold CV. Only returned, if <code>calibrate_object</code> contains a summary_CV list object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t.test_calibration</code></td>
<td>
<p>=list(p_value=t.test.calibration, effect_size=effect_size_calibration), only returned if t.test=TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t.test_discrimination</code></td>
<td>
<p>=list(p_value=t.test.discrimination, effect_size=effect_size_discrimination), only returned if t.test=TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>significance_models</code></td>
<td>
<p>only returned if significance_models=TRUE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_seeds</code></td>
<td>
<p>number of random data set partitions into training and test set for <code>folds</code>-times CV</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>original_values</code></td>
<td>
<p>list object that consists of the <code>actual</code> and <code>predicted</code> values of the original scores</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Johanna Schwarz
</p>


<h3>See Also</h3>

<p><code>t.test</code>,<code>friedman.test</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"> ## Loading dataset in environment
 data(example)
 calibration_model &lt;- example$calibration_model

 statistics &lt;- statistics_calibratR(calibration_model)
</code></pre>


</div>