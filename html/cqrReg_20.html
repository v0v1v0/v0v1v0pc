<div class="container">

<table style="width: 100%;"><tr>
<td>QR.lasso.cd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Quantile Regression (QR) with Adaptive Lasso Penalty (lasso) use Coordinate Descent (cd)  Algorithms</h2>

<h3>Description</h3>

<p>The adaptive lasso parameter base on the estimated coefficient without penalty function.
The algorithm base on greedy coordinate descent and Edgeworth's for ordinary <code class="reqn">l_1</code>    regression. As explored by Tong Tong Wu and Kenneth Lange.
</p>


<h3>Usage</h3>

<pre><code class="language-R">QR.lasso.cd(X,y,tau,lambda,beta,maxit,toler)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the design matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>quantile level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The constant coefficient of penalty function. (default lambda=1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>initial value of estimate coefficient (default naive guess by least square estimation) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>maxim iteration (default 200)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>toler</code></td>
<td>
<p>the tolerance critical for stop the algorithm (default 1e-3)</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a <code>list</code> structure is with components
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>the vector of estimated coefficient</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>intercept</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>QR.lasso.cd(x,y,tau) work properly only if the least square estimation is good. 
</p>


<h3>References</h3>

<p>Wu, T.T. and Lange, K. (2008). Coordinate Descent Algorithms for Lasso Penalized Regression. <em>Annals of Applied Statistics</em>, <b>2</b>, No 1, 224–244.
</p>
<p>Wu, Yichao and Liu, Yufeng (2009). Variable selection in quantile regression. <em>Statistica Sinica</em>, <b>19</b>, 801–817.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
n=100
p=2
a=2*rnorm(n*2*p, mean = 1, sd =1)
x=matrix(a,n,2*p)
beta=2*rnorm(p,1,1)
beta=rbind(matrix(beta,p,1),matrix(0,p,1))
y=x%*%beta-matrix(rnorm(n,0.1,1),n,1)
# x is 1000*20 matrix, y is 1000*1 vector, beta is 20*1 vector with last ten zero value elements. 
QR.lasso.cd(x,y,0.1)
</code></pre>


</div>