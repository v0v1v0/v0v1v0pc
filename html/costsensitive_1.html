<div class="container">

<table style="width: 100%;"><tr>
<td>cost.proportionate.classifier</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cost-Proportionate Classifier</h2>

<h3>Description</h3>

<p>Fits a classifier with sample weights by reducing the problem to classification
without sample weights through rejection sampling.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cost.proportionate.classifier(X, y, weights, classifier, nsamples = 10,
  extra_rej_const = 0.1, nthreads = 1, seed = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Features/Covariates for each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Class for each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Weights for each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier</code></td>
<td>
<p>Base classifier to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsamples</code></td>
<td>
<p>Number of resamples to take.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extra_rej_const</code></td>
<td>
<p>Extra rejection constant - the higher, the smaller each sample ends up being,
but the smallest the chance that the highest-weighted observations would end up in each sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nthreads</code></td>
<td>
<p>Number of parallel threads to use (not available on Windows systems). Note
that, unlike the Python version, this is not a shared memory model and each additional thread will
require more memory from the system. Not recommended to use when the algorithm is itself parallelized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed to use for the random number generation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to pass to 'classifier'.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Beygelzimer, A., Langford, J., &amp; Zadrozny, B. (2008). Machine learning techniques-reductions between prediction quality metrics.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
### example here requires 'caret' package
library(costsensitive)
data(iris)
set.seed(1)
X &lt;- iris[, c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")]
y &lt;- factor(iris$Species == "setosa", labels = c("class1", "class2"))
weights &lt;- rgamma(100, 1)
classifier &lt;- caret::train
model &lt;- cost.proportionate.classifier(X, y, weights, classifier,
  method = "glm", family = "binomial",
  trControl=caret::trainControl(method="none"), tuneLength=1)
predict(model, X, aggregation = "raw", type = "raw")
predict(model, X, aggregation = "weighted", type = "prob")

## End(Not run)
</code></pre>


</div>