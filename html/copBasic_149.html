<div class="container">

<table style="width: 100%;"><tr>
<td>vuongCOP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The Vuong Procedure for Parametric Copula Comparison</h2>

<h3>Description</h3>

<p>Perform the <em>Vuong Procedure</em> following Joe (2014, pp. 257–258). Consider two copula densities <code class="reqn">f_1 = c_1(u,v; \Theta_1)</code> and <code class="reqn">f_2 = c_2(u,v; \Theta_2)</code> for two different bivariate copulas <code class="reqn">\mathbf{C}_1(\Theta_1)</code> and <code class="reqn">\mathbf{C}_2(\Theta_2)</code> having respective parameters <code class="reqn">\Theta_1</code> and <code class="reqn">\Theta_2</code> that provide the “closest” <em>Kullback–Leibler Divergence</em> from the true copula density <code class="reqn">g(u,v)</code>.
</p>
<p>The difference of the Kullback–Leibler Divergence (<code>kullCOP</code>) of the two copulas from the true copula density can be measured for a sample of size <code class="reqn">n</code> and bivariate sample realizations <code class="reqn">\{u_i, v_i\}</code> by
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}_{12} = n^{-1}\sum_{i=1}^n D_i\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat{D}_{12}</code> is referred to in the <span class="pkg">copBasic</span> package as the “Vuong <code class="reqn">D</code>” and <code class="reqn">D_i</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">D_i = \log\biggl[\frac{f_1(u_i, v_i; \Theta_2)}{f_2(u_i, v_i; \Theta_1)}\biggr]\mbox{.}</code>
</p>

<p>The variance of <code class="reqn">\hat{D}_{12}</code> can be estimated by
</p>
<p style="text-align: center;"><code class="reqn">\hat\sigma^2_{12} = (n-1)^{-1}\sum_{i=1}^n (D_i - \hat{D}_{12})^2\mbox{.}</code>
</p>

<p>The sample estimate and variance are readily turned into the <code class="reqn">100{{\times}}(1 - \alpha)</code> confidence interval by
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}^{(\mathrm{lo})}_{12} &lt; \hat{D}_{12} &lt; \hat{D}^{(\mathrm{hi})}_{12}\mbox{,}</code>
</p>

<p>where, using the quantile (inverse) function of the t-distribution <code class="reqn">\sim</code> <code class="reqn">\mathcal{T}^{(-1)}(F; \mathrm{df}{=}(n-2))</code> for nonexceedance probability <code class="reqn">F</code> and <code class="reqn">n-2</code> degrees of freedom for <code class="reqn">n</code> being the sample size, the confidence interval is
</p>
<p style="text-align: center;"><code class="reqn">\hat{D}_{12}-\mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n} &lt; \hat{D}_{12} &lt; \hat{D}_{12}+\mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{.}</code>
</p>

<p>Joe (2014, p. 258) reports other interval forms based (1) on the Akaike (AIC) correction and (2) on the Schwarz (BIC) correction, which are defined for AIC as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{AIC} = \hat{D}_{12} - (2n)^{-1}\log(n)\biggl[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)\biggr]\pm \mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{,}</code>
</p>

<p>and for BIC as
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{BIC} = \hat{D}_{12} - (2n)^{-1}\log(n)\biggl[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)\biggr]\pm \mathcal{T}^{(-1)}(1-\alpha/2){\times}\hat\sigma_{12}/\sqrt{n}\mbox{.}</code>
</p>

<p>The AIC and BIC corrections incorporate the number of parameters in the copula and for all else being equal the copula with the fewer parameters is preferable. If the two copulas being compared have equal number of parameters than the AIC and BIC equate to <code class="reqn">\hat{D}_{12}</code> and the same confidence interval because the difference <code class="reqn">[\mathrm{dim}(\Theta_2) - \mathrm{dim}(\Theta_1)]</code> is zero.
</p>
<p>Joe (2014, p. 258) reports that these three intervals can be used for <em>diagnostic inference</em> as follows. If an interval contains 0 (zero), then copulas <code class="reqn">\mathbf{C}_1(\Theta_1)</code> and <code class="reqn">\mathbf{C}_2(\Theta_2)</code> are not considered significantly different. If the interval does not contain 0, then copula <code class="reqn">\mathbf{C}_1(\Theta_1)</code> or <code class="reqn">\mathbf{C}_2(\Theta_2)</code> is the better fit depending on whether the interval is completely below 0 (thus <code class="reqn">\mathbf{C}_1(\Theta_1)</code> better fit) or above 0 (thus <code class="reqn">\mathbf{C}_2(\Theta_2)</code> better fit), respectively. Joe (2014) goes on the emphasize that “the procedure compares different [copulas] and assesses whether they provide similar fits to the data. [The procedure] does not assess whether [either copula] is a good enough fit.”
</p>


<h3>Usage</h3>

<pre><code class="language-R">vuongCOP(u, v=NULL, cop1=NULL, cop2=NULL, para1=NULL, para2=NULL,
                    alpha=0.05, method=c("D12", "AIC", "BIC"),
                    the.zero=.Machine$double.eps^0.25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">u</code> in the <code class="reqn">X</code> direction;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>v</code></td>
<td>
<p>Nonexceedance probability <code class="reqn">v</code> in the <code class="reqn">Y</code> direction and if <code>NULL</code> then <code>u</code> is treated as a two column <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> <code>data.frame</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cop1</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">f_1</code> in the Vuong Procedure;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>para1</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">f_1</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cop2</code></td>
<td>
<p>A copula function corresponding to copula <code class="reqn">f_2</code> in the the Vuong Procedure;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>para2</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula <code class="reqn">f_2</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> in the Vuong Procedure, which results in the <code class="reqn">100{\times}(1 - \alpha)</code> confidence interval (two sided);</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The interval to evaluate as to position of the respective statistic form the comparison of the two copulas;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>the.zero</code></td>
<td>
<p>The value for “the zero” of the copula density function. This argument is the argument of the same name for <code>densityCOP</code>. The default here is intended to suggest that a tiny nonzero value for density will trap the numerical zero densities; and</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to pass to the <code>densityCOP</code> function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> <code>list</code> is returned having the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>title</code></td>
<td>
<p>A descriptive title of the procedure;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A textual description of the <code>method</code> setting;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>result.text</code></td>
<td>
<p>A textual description of the result of the Vuong Procedure;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>result</code></td>
<td>
<p>A value 1 if <code class="reqn">\mathbf{C}_1(\Theta_1)</code> is better fit, 2 if copula <code class="reqn">\mathbf{C}_2(\Theta_2)</code> is better fit, and <code>0</code> if neither is better (<code class="reqn">\hat{D}_{12} = 0</code>), and <code>NA</code> including the likely(?) erroneous situation of <code class="reqn">\mathbf{C}_1(\Theta_1) \equiv \mathbf{C}_2(\Theta_2)</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>The two-sided p-values of the Vuong Procedure inclusive of <code class="reqn">\mathrm{AIC}</code> and <code class="reqn">\mathrm{BIC}</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D12</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">D</code> at the respective confidence interval percentage along with <code class="reqn">\hat{D}_{12}</code> and <code class="reqn">\sigma^2_{12}</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AIC</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">\mathrm{AIC}</code> at the respective confidence interval percentage;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BIC</code></td>
<td>
<p>A named vector of the lower and upper bounds of Vuong <code class="reqn">\mathrm{BIC}</code> at the respective confidence interval percentage; and</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameters</code></td>
<td>
<p>A named vector of the alpha, sample size, value for the t-distribution quantile <code>qt(1-alpha/2, df=n)</code>, and <code class="reqn">\hat\sigma_{12}</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The <code>vuongCOP</code> function along with <code>kullCOP</code> and features of function <code>densityCOPplot</code> represent collective milestones towards <em>copula inference</em> and diagnostics post fitting of copulas to the usual measures of association such as the <em>Kendall Tau</em> (<code class="reqn">\tau_K</code>) and <em>Spearman Rho</em> (<code class="reqn">\rho_S</code>) and their copula counterparts <code class="reqn">\tau_\mathbf{C}</code> (<code>tauCOP</code>) and <code class="reqn">\rho_\mathbf{C}</code> (<code>rhoCOP</code>).
</p>
<p>For an example application, imagine a problem of say low springflow risk at “nearby springs” that jointly should converge in the lower tail because drought usually has a strong regional impact. First, it is necessary to form a reflection of the <em>Gumbel–Hougaard copula</em> (<code class="reqn">\mathbf{GH}(u,v; \Theta_{\mathbf{GH}})</code>; <code>GHcop</code>) but parameter estimation using <code class="reqn">\tau_\mathbf{C}</code> is the same because sample <code class="reqn">\hat\tau_K</code> is invariant to reflection.
</p>
<pre>
  "rGHcop" &lt;- function(u,v, ...) { u + v - 1 + GHcop(1-u, 1-v, ...) }
  set.seed(385) # setting so that reported quantities here are reproducible
</pre>
<p>The prior code also sets a seed on the pseudo-random number generator so that reported values here are reproducible. The reflected <code class="reqn">\mathbf{GH}(u,v; \Theta_{\mathbf{GH}})</code> is denoted <code class="reqn">\mathbf{rGH}(u,v; \Theta_{\mathbf{rGH}})</code>.
</p>
<p>Second, the <code class="reqn">\mathbf{PSP}(u,v)</code> copula (<code>PSP</code>) is chosen as the parent distribution, and this copula has no parameter. The <code class="reqn">\mathbf{PSP}</code> has lower-tail dependency, which will be important as discussion unfolds. The following two lines of code establish a sample size to be drawn from the <code class="reqn">\mathbf{PSP}</code> and then simulates a sample from that copula. The color grey is used for the simulated values on the figure produced by <code>simCOP</code>, which forms a background example of the joint structure of the <code class="reqn">\mathbf{PSP}</code> copula.
</p>
<pre>
  n &lt;- 390
  UV &lt;- simCOP(cop=PSP, n=n, col=8, pch=16) # simulate and form the base image
</pre>
<p>By inspection of the so-produced graphic, it is obvious that there is contraction in the lower-left corner of the plot, which is a geometric representation of tail dependency. The lower-tail dependency thus phenomenalogically says that there is joint interconnect during low springflow conditions—both springs are likely to be at low flow simultaneously. The variable <code>UV</code> contains the bivariate data as uniform variables (nonexceedance probabilities <code class="reqn">u</code> and <code class="reqn">v</code>).
</p>
<p>The <em>Plackett copula</em> (<code class="reqn">\mathbf{PL}(u,v; \Theta_{\mathbf{PL}})</code>; <code>PLACKETTcop</code>) and the <code class="reqn">\mathbf{rGH}(u,v; \Theta_{\mathbf{rGH}})</code> copula are chosen as candidate models of the “unknown” parent. Both <code class="reqn">\mathbf{PL}</code> and <code class="reqn">\mathbf{rGH}</code> copulas use different “measures of association” for their parameter estimation. Next, sample estimates of the copula parameters using <em>Schweizer and Wolff Sigma</em> <code class="reqn">\hat\sigma_\mathbf{C}</code>. The sample value computations and parameter estimates also are set as shown in the following code:
</p>
<pre>
  Wolf   &lt;- wolfCOP(para=UV, as.sample=TRUE) # 0.496943
  paraPL &lt;- uniroot(function(p)
                Wolf - wolfCOP(cop=PLACKETTcop, para=p), c(1,30))$root
  paraGH &lt;- uniroot(function(p)
                Wolf - wolfCOP(cop=rGHcop,      para=p), c(1,30))$root
</pre>
<p><em>STEP 1—Compute Kullback–Leibler sample size:</em> The Kullback–Leibler Divergences (<code class="reqn">\mathrm{KL}(f {\mid} g)</code> and <code class="reqn">\mathrm{KL}(g {\mid} f)</code>) are computed (<code>kullCOP</code>) for the evaluation of the sample size as appropriate for distinguishing between the two candidate copulas 95 percent of the time. The Kullback–Leibler sample size (<code class="reqn">n_{f\!g}</code>) also is computed as the following code illustrates and provides additional commentary.
</p>
<pre>
  KL &lt;- replicate(20, kullCOP(cop1=PLcop,  para1=paraPL,       # CPU intensive
                              cop2=rGHcop, para2=paraGH, n=1E5)$KL.sample.size)
  print(round(mean(KL))) #         n_{fg} = 221   sample size
  print(     range(KL))  # 204 &lt;-- n_{fg} --&gt; 252 sample size range
</pre>
<p>Depending on the sample <code class="reqn">\hat\sigma_\mathbf{C}</code> coming from the simulation of the parent <code class="reqn">\mathbf{PSP}</code> copula, the call to <code>kullCOP</code> will likely report different <code class="reqn">n_{f\!g}</code> values because <code class="reqn">n_{f\!g}(\mathbf{C}_1(\Theta_1), \mathbf{C}_1(\Theta_1)</code>. These sample sizes have a range for 20 replications of about <code class="reqn">n_{f\!g}=204{-}252</code>. The result here is <code class="reqn">n_{f\!g}=221</code> and thus <b>the sample size <code class="reqn">n=390</code> should be more than large enough to generally distinguish between the <code class="reqn">\mathbf{PL}</code> and <code class="reqn">\mathbf{rGH}</code> copulas at the respective sample measure of association.</b>
</p>
<p><em>STEP 2—Perform the Vuong Procedure:</em> The Vuong Procedure can now be completed. Now watch the copula and parameter order in the next code for mistakes, the author has purposefully switched order here to draw attention to the need to make sure argument <code>cop1</code> has the correct parameter(s) for copula 1 (the <code class="reqn">\mathbf{PL}</code>). The two calls to <code>simCOP</code> are made to graphically superimpose these simulations on top of the parent <code class="reqn">\mathbf{PSP}</code>.
</p>
<pre>
  VD &lt;- vuongCOP(UV, cop2=rGHcop, para2=paraGH, cop1=PLcop, para1=paraPL)
  print(VD) # "Copula 2 better" or rGHcop (Gumbel-Hougaard is better)
  set.seed(385) # seems harmless enough to reuse the seed to emphasize "fit"
  TMP &lt;-simCOP(cop=PLcop, para=paraPL,n=n,plot=FALSE,col="red",  pch=16,cex=0.5)
  set.seed(385) # seems harmless enough to reuse the seed to emphasize "fit"
  TMP &lt;-simCOP(cop=rGHcop,para=paraGH,n=n,plot=FALSE,col="green",pch=16,cex=0.5)
  rm(TMP) # just cleaning up the workspace.
</pre>
<p>Further discussion of the Vuong Procedure is informative. Simply speaking, the result is that <b>the <code class="reqn">\mathbf{rGH}</code> (copula 2) has better fit than <code class="reqn">\mathbf{PL}</code> (copula 1).</b> The 95-percent confident limits from the procedure for <code class="reqn">\hat{D}_{12} = 0.049</code> with p-value <code class="reqn">0.0012</code>, <code class="reqn">\hat\sigma_{12} = 0.297</code>, and <code class="reqn">n=390</code> are <code class="reqn">0.0194 &lt; \hat{D}_{12} &lt; 0.0786</code>. This interval does not contain zero and is greater than zero and therefore a conclusion may be drawn that copula 2 has the better fit.
</p>
<p><em>STEP 3—Comparison of lower-tail dependency parameters:</em> What does the tail dependency do for inference? This can be checked by computing the lower-tail dependency parameters (<code class="reqn">\lambda^L_\mathbf{C}</code>; <code>taildepCOP</code>) in the code that follows for each of the three copulas and the empirical copula with acknowledgment that true sample estimators do not quite exist. Numeric focus need only be on the lower tail, but the four graphics are informative.
</p>
<pre>
  taildepCOP(cop=PSP,                   plot=TRUE)$lambdaL # = 1/2
  taildepCOP(cop=PLcop,    para=paraPL, plot=TRUE)$lambdaL # = ZERO
  taildepCOP(cop=rGHcop,   para=paraGH, plot=TRUE)$lambdaL # = 0.429
  taildepCOP(cop=EMPIRcop, para=UV,     plot=TRUE)$lambdaL # = 0.328
</pre>
<p>The important aspect of the graphics by <code>taildepCOP</code> is that the <code class="reqn">\mathbf{rGH}</code> has lower-tail dependency whereas the <code class="reqn">\mathbf{PL}</code> does not. So, based on inspection <code class="reqn">\mathbf{rGH}</code> is superior given that we known <code class="reqn">\mathbf{PSP}</code> was the true parent.  The empirical estimate of the <code class="reqn">\hat\lambda^L_\mathbf{C} = 0.328</code> through the <code>EMPIRcop</code> copula indicates that its lower-tail dependency is closer to that of the <code class="reqn">\mathbf{rGH}</code> relative to <code class="reqn">\mathbf{PL}</code> and thus <b>quantitatively by lower-tail dependency the <code class="reqn">\mathbf{rGH}</code> has a superior fit.</b>
</p>
<p>Therefore the <code class="reqn">\mathbf{rGH}</code> has a tail dependency more similar to the true model compared to the <code class="reqn">\mathbf{PL}</code>. Hence for this example, the <code class="reqn">\mathbf{rGH}</code> is clearly a superior fitting model in terms of the <em>Vuong Procedure</em> (fit alone) and the <code class="reqn">\lambda^L_\mathbf{C}</code> then is used as a follow up to shown that the <code class="reqn">\mathbf{rGH}</code> might be “good enough” an approximation to the <code class="reqn">\mathbf{PSP}</code>. The efficacy of reflecting the <code class="reqn">\mathbf{GH}</code> copula into a “new” form as <code class="reqn">\mathbf{rGH}</code> is demonstrated. Users are strongly encouraged to review the so-produced graphic from the <code>simCOP</code> call several listings back for <code class="reqn">n=390</code>, and lastly, this example is one for which absence of the argument <code>snv</code> (standard normal variate [scores]) by <code>simCOP</code> makes the tail dependency issue for the sample size more prominent in the graphic.
</p>
<p><em>STEP 4—Qualitatively compare using copula density plots:</em> Graphical depiction of copula density contours by the <code>densityCOPplot</code> function supports the conclusion that the <code class="reqn">\mathbf{rGH}</code> is the superior model relative to the <code class="reqn">\mathbf{PL}</code>. The so-produced graphic obviously shows that <b>the <code class="reqn">\mathbf{rGH}</code> strongly mimics the shape of the parent <code class="reqn">\mathbf{PSP}</code>.</b>
</p>
<pre>
  densityCOPplot(cop=PSP, contour.col=8) # grey is the parent bivariate density
  densityCOPplot(cop=PLcop,  para=paraPL, contour.col="green", ploton=FALSE)
  densityCOPplot(cop=rGHcop, para=paraGH, contour.col="red",   ploton=FALSE)
</pre>
<p><em>STEP 5—Compute L-comoments of the data via simulation and estimate the sampling distributions:</em> An open research problem is the what if any role that <em>L-comoments</em> might play in either copula estimation or inference. (There being very little literature on the topic?) Because a measure of association was used for parameter estimation, the L-correlation is uniformative, but a comparison is conceptually useful. The <code class="reqn">\hat\sigma_\mathbf{C} = 0.4969</code> and <em>Spearman Rho</em> of the data <code class="reqn">\hat\rho_S</code> and the L-correlations <code class="reqn">\hat\rho_S \approx \tau^{[12]}_{2} \approx \tau^{[21]}_{2} \approx 0.497</code> are all similar as mandated by the mathematics.
</p>
<p>Inference using L-coskew and L-cokurtosis seems possible. The following code listing is CPU intensive. First, the L-correlation, L-coskew, and L-cokurtosis values are computed from the simulated sample by the <code>lcomoms2()</code> function of the <span class="pkg">lmomco</span> package. Second and third, the respective sampling distributions of these L-comoments (<code>lcomCOPpv</code>) for the two copulas are estimated.
</p>
<pre>
  UVlmr &lt;- lmomco::lcomoms2(UV, nmom=4) # The sample L-comoments
  # This execution will result in nonrejection of rGH copula.
  GHlmr &lt;- lcomCOPpv(n, UVlmr, cop=rGHcop,      para=paraGH) # NONREJECTION
  # LcomType      n     Mean  Lscale    Lskew   Lkurt sample.est p.value signif
  #    Tau3[12] 390 -0.06952 0.01819  0.04505 0.12024   -0.11188 0.08795      .
  #    Tau3[21] 390 -0.06739 0.02084  0.04104 0.12917   -0.10673 0.14162      -
  # Tau3[12:21] 390 -0.06845 0.01713  0.04930 0.11696   -0.10931 0.08161      .
  #    Tau4[12] 390  0.04970 0.01682 -0.01635 0.10150    0.04183 0.38996      -
  #    Tau4[21] 390  0.05129 0.01606 -0.06833 0.13798    0.07804 0.17470      -
  # Tau4[12:21] 390  0.05049 0.01329 -0.02045 0.12001    0.05994 0.35069      -

  # This execution will result in rejection of Plackett copula.
  PLlmr &lt;- lcomCOPpv(n, UVlmr, cop=PLACKETTcop, para=paraPL) # REJECT PLACKETT
  #  LcomType     n     Mean  Lscale    Lskew   Lkurt sample.est p.value signif
  #    Tau3[12] 390 -0.00267 0.02133  0.01556 0.09581   -0.11188 0.00129     **
  #    Tau3[21] 390 -0.00112 0.02022 -0.00663 0.13338   -0.10673 0.00189     **
  # Tau3[12:21] 390 -0.00189 0.01757  0.00906 0.10226   -0.10931 0.00019    ***
  #    Tau4[12] 390  0.00153 0.01652 -0.03320 0.12468    0.04183 0.07924      .
  #    Tau4[21] 390  0.00361 0.01851 -0.01869 0.12052    0.07804 0.00929     **
  # Tau4[12:21] 390  0.00257 0.01362 -0.01194 0.10796    0.05994 0.00744     **
</pre>
<p>Because each copula was fit to a measure of association, the p-values for the L-correlations are all nonsignificant (noninformative because of how the copulas were fit), and therefore p-values quite near to the 50th percentile should be produced. So here, the L-correlation is noninformative on fit even though it might have some role because it is asymmetrical unlike that statistics <code class="reqn">\tau_K</code> and <code class="reqn">\rho_S</code>. The results in variable <code>GHlmr</code> show no statistically significant entries (all p-values <code class="reqn">{&gt;}0.05 = (\alpha=0.1)/2)</code>) for L-coskew and L-cokurtosis—<b>the <code class="reqn">\mathbf{rGH}</code> copula is not rejected.</b> The results in <code>PLlmr</code> show many p-values <code class="reqn">{&lt;}0.05 = (\alpha=0.1)/2</code> for both L-coskew and L-cokurtosis—<b>the <code class="reqn">\mathbf{PL}</code> copula is rejected</b>. The experimental L-comoment inference shown is consistent with results with the Vuong Procedure.
</p>
<p>The Vuong Procedure, however, does not address adequacy of fit—it just evaluates which copula fits better. The inspection of the lower tail dependency results previously shown (<code class="reqn">\lambda^L_\mathbf{PSP} = 1/2 \approx \lambda^U_\mathbf{rGH}</code> = 0.429) along with the L-coskew and L-cokurtosis of the sample being well within the sample distribution suggests that the <code class="reqn">\mathbf{rGH}</code> is a adequate mimic of the <code class="reqn">\mathbf{PSP}</code> copula.
</p>
<p>Some open research questions concern the numerical performance of the L-comoments as simulation sample size becomes large and whether or not the L-comoments should be computed on the probabilities <code class="reqn">\{u, v\}</code>. Also should conversion to normal scores be made and if so, should adjustment by the <em>Hazen plotting positions</em> (<code class="reqn">u_i = (r_i - 0.5)/n</code> for rank <code class="reqn">r_i</code>) be made that Joe (2014) repeatedly advocates when standard normal variates (scores) [<code class="reqn">z_i = \Phi^{(-1)}(u_i)</code> for quantile function of standard normal distribution <code class="reqn">\Phi(0,1)</code>]? Collectively, Nelsen (2006) and Salvadori <em>et al.</em> (2007) are both silent on the matter of normal score conversion, and in conclusion Nelsen (2006), Salvadori <em>et al.</em> (2007), and Joe (2014) also are all silent on L-comoment applications with copulas.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Joe, H., 2014, Dependence modeling with copulas: Boca Raton, CRC Press, 462 p.
</p>
<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>
<p>Salvadori, G., De Michele, C., Kottegoda, N.T., and Rosso, R., 2007, Extremes in Nature—An approach using copulas: Springer, 289 p.
</p>


<h3>See Also</h3>

<p><code>densityCOP</code>, <code>kullCOP</code>, <code>simCOP</code>, <code>statTn</code>, <code>mleCOP</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># See extended code listings and discussion in the Note section
# See Examples in mleCOP() (Last example therein might suggest a problem in the
# implied 95th percentile associated with n_fg above.
</code></pre>


</div>