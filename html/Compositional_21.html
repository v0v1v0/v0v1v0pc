<div class="container">

<table style="width: 100%;"><tr>
<td>The k-NN algorithm for compositional data</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
The k-NN algorithm for compositional data
</h2>

<h3>Description</h3>

<p>The k-NN algorithm for compositional data with and without using the
power transformation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">comp.knn(xnew, x, ina, a = 1, k = 5,  apostasi = "ESOV", mesos = TRUE)

alfa.knn(xnew, x, ina, a = 1, k = 5, mesos = TRUE,
apostasi = "euclidean", rann = FALSE)

ait.knn(xnew, x, ina, a = 1, k = 5, mesos = TRUE,
apostasi = "euclidean", rann = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xnew</code></td>
<td>

<p>A matrix with the new compositional data whose group is to be predicted. Zeros
are allowed, but you must be careful to choose strictly positive values
of <code class="reqn">\alpha</code> or not to set apostasi= "Ait".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed, but you
must be careful to choose strictly positive values of <code class="reqn">\alpha</code> or not
to set apostasi= "Ait".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ina</code></td>
<td>

<p>A group indicator variable for the available data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code>. As zero values in the compositional data are allowed,
you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>.
You have the option to put a = NULL. In this case, the xnew and x are
assumed to be the already <code class="reqn">\alpha</code>-transformed data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>apostasi</code></td>
<td>

<p>The type of distance to use. For the compk.knn this can be one of the following:
"ESOV", "taxicab", "Ait", "Hellinger", "angular" or "CS". See the references for
them. For the alfa.knn this can be either "euclidean" or "manhattan".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mesos</code></td>
<td>

<p>This is used in the non standard algorithm. If TRUE, the arithmetic mean of the
distances is calulated, otherwise the harmonic mean is used (see details).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use
kd-trees implemented in the R package "Rnanoflann". In this case you must set this
argument equal to TRUE. Note however, that in this case, the only available
distance is by default "euclidean".
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The k-NN algorithm is applied for the compositional data. There are many metrics
and possibilities to choose from. The algorithm finds the k nearest observations
to a new observation and allocates it to the class which appears most times in
the neighbours. It then computes the arithmetic or the harmonic mean of the
distances. The new point is allocated to the class with the minimum distance.
</p>


<h3>Value</h3>

<p>A vector with the estimated groups.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris, Michail (2014). The k-NN algorithm for compositional data: a revised
approach with and without zero values present. Journal of Data Science, 12(3): 519–534.
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009). The elements of
statistical learning, 2nd edition. Springer, Berlin
</p>
<p>Tsagris Michail, Simon Preston and Andrew T.A. Wood (2016).
Improved classification for compositional data using the
<code class="reqn">\alpha</code>-transformation. Journal of Classification 33(2): 243–261.
</p>
<p>Connie Stewart (2017). An approach to measure distance between compositional
diet estimates containing essential zeros. Journal of Applied Statistics 44(7): 1137–1152.
</p>
<p>Clarotto L., Allard D. and Menafoglio A. (2022). A new class of
<code class="reqn">\alpha</code>-transformations for the spatial analysis of Compositional Data.
Spatial Statistics, 47.
</p>
<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability
distributions. Information Theory, IEEE Transactions on 49, 1858–1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on
probability spaces and its applicability in statistics.
Annals of the Institute of Statistical Mathematics 55, 639–653.
</p>


<h3>See Also</h3>

<p><code>compknn.tune, alfa.rda, comp.nb, alfa.nb, alfa,
esov, mix.compnorm
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- as.matrix( iris[, 1:4] )
x &lt;- x/ rowSums(x)
ina &lt;- iris[, 5]
mod &lt;- comp.knn(x, x, ina, a = 1, k = 5)
table(ina, mod)
mod2 &lt;- alfa.knn(x, x, ina, a = 1, k = 5)
table(ina, mod2)

</code></pre>


</div>