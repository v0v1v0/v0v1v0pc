<div class="container">

<table style="width: 100%;"><tr>
<td>vcr.svm.newdata</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Prepare for visualization of a support vector machine classification on new data.
</h2>

<h3>Description</h3>

<p>Carries out a support vector machine classification of new data using the output of <code>vcr.svm.train</code> on the training data, and computes the quantities needed for its visualization.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vcr.svm.newdata(Xnew, ynew = NULL, vcr.svm.train.out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xnew</code></td>
<td>
<p>data matrix of the new data, with the same number of columns as in the training data. Missing values in <code>Xnew</code> are not allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ynew</code></td>
<td>
<p>factor with class membership of each new case. Can be <code>NA</code> for some or all cases. If <code>NULL</code>, is assumed to be <code>NA</code> everywhere.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vcr.svm.train.out</code></td>
<td>
<p> output of <code>vcr.svm.train</code> on the training data.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with components: <br></p>
<table>
<tr style="vertical-align: top;">
<td><code>yintnew</code></td>
<td>
<p>number of the given class of each case. Can contain <code>NA</code>'s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ynew</code></td>
<td>
<p>given class label of each case. Can contain <code>NA</code>'s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>levels</code></td>
<td>
<p>levels of the response, from <code>vcr.svm.train.out</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predint</code></td>
<td>
<p>predicted class number of each case. Always exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>predicted label of each case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>altint</code></td>
<td>
<p>number of the alternative class. Among the classes different from the given class, it is the one with the highest posterior probability. Is <code>NA</code> for cases whose <code>ynew</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>altlab</code></td>
<td>
<p>alternative label if yintnew was given, else <code>NA</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PAC</code></td>
<td>
<p>probability of the alternative class. Is <code>NA</code> for cases whose <code>ynew</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fig</code></td>
<td>
<p>distance of each case <code class="reqn">i</code> from each class <code class="reqn">g</code>. Always exists.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>farness</code></td>
<td>
<p>farness of each case from its given class. Is <code>NA</code> for cases whose <code>ynew</code> is missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ofarness</code></td>
<td>
<p>for each case <code class="reqn">i</code>, its lowest <code>fig[i,g]</code> to any class <code class="reqn">g</code>. Always exists.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Raymaekers J., Rousseeuw P.J.
</p>


<h3>References</h3>

<p>Raymaekers J., Rousseeuw P.J., Hubert M. (2021). Class maps for visualizing classification results. <em>Technometrics</em>, appeared online. doi: <a href="https://doi.org/10.1080/00401706.2021.1927849">10.1080/00401706.2021.1927849</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code>vcr.svm.train</code>, <code>classmap</code>, <code>silplot</code>, <code>stackedplot</code>, <code>e1071::svm</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(e1071)
set.seed(1); X &lt;- matrix(rnorm(200 * 2), ncol = 2)
X[1:100, ] &lt;- X[1:100, ] + 2
X[101:150, ] &lt;- X[101:150, ] - 2
y &lt;- as.factor(c(rep("blue", 150), rep("red", 50)))
# We now fit an SVM with radial basis kernel to the data:
set.seed(1) # to make the result of svm() reproducible.
svmfit &lt;- svm(y~., data = data.frame(X = X, y = y),
scale = FALSE, kernel = "radial", cost = 10,
gamma = 1, probability = TRUE)
vcr.train &lt;- vcr.svm.train(X, y, svfit = svmfit)
# As "new" data we take a subset of the training data:
inds &lt;- c(1:25, 101:125, 151:175)
vcr.test &lt;- vcr.svm.newdata(X[inds, ], y[inds], vcr.train)
plot(vcr.test$PAC, vcr.train$PAC[inds]); abline(0, 1) # match
plot(vcr.test$farness, vcr.train$farness[inds]); abline(0, 1)
confmat.vcr(vcr.test)
cols &lt;- c("deepskyblue3", "red")
stackedplot(vcr.test, classCols = cols)
classmap(vcr.train, "blue", classCols = cols) # for comparison
classmap(vcr.test, "blue", classCols = cols)
classmap(vcr.train, "red", classCols = cols) # for comparison
classmap(vcr.test, "red", classCols = cols)


# For more examples, we refer to the vignette:
## Not run: 
vignette("Support_vector_machine_examples")

## End(Not run)
</code></pre>


</div>