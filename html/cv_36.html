<div class="container">

<table style="width: 100%;"><tr>
<td>mse</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cost Functions for Fitted Regression Models</h2>

<h3>Description</h3>

<p>Compute cost functions (cross-validation criteria) for fitted
regression models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mse(y, yhat)

rmse(y, yhat)

medAbsErr(y, yhat)

BayesRule(y, yhat)

BayesRule2(y, yhat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yhat</code></td>
<td>
<p>fitted value</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Cost functions (cross-validation criteria) are meant to measure lack-of-fit. Several cost functions are provided:
</p>

<ol>
<li> <p><code>mse()</code> returns the mean-squared error of prediction for
a numeric response variable <code>y</code> and predictions <code>yhat</code>; and
<code>rmse()</code> returns the root-mean-squared error and is just the
square-root of <code>mse()</code>.
</p>
</li>
<li> <p><code>medAbsErr()</code> returns the median absolute error of prediction for a numeric
response <code>y</code> and predictions <code>yhat</code>.
</p>
</li>
<li> <p><code>BayesRule()</code> and <code>BayesRule2()</code> report the proportion
of incorrect predictions for a dichotomous response variable <code>y</code>, assumed
coded (or coercible to) <code>0</code> and <code>1</code>. The <code>yhat</code> values are
predicted probabilities and are rounded to 0 or 1. The distinction
between <code>BayesRule()</code> and <code>BayesRule2()</code> is that the former
checks that the <code>y</code> values are all either <code>0</code> or <code>1</code>
and that the <code>yhat</code> values are all between 0 and 1, while
the latter doesn't and is therefore faster.
</p>
</li>
</ol>
<h3>Value</h3>

<p>In general, cost functions should return a single numeric
value measuring lack-of-fit. <code>mse()</code> returns the mean-squared error;
<code>rmse()</code> returns the root-mean-squared error;
<code>medAbsErr()</code> returns the median absolute error;
and <code>BayesRule()</code> and
<code>BayesRule2()</code> return the proportion of misclassified cases.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>mse()</code>: Mean-square error.
</p>
</li>
<li> <p><code>rmse()</code>: Root-mean-square error.
</p>
</li>
<li> <p><code>medAbsErr()</code>: Median absolute error.
</p>
</li>
<li> <p><code>BayesRule()</code>: Bayes Rule for a binary response.
</p>
</li>
<li> <p><code>BayesRule2()</code>: Bayes rule for a binary response (without bounds checking).
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>cv</code>, <code>cv.merMod</code>,
<code>cv.function</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (requireNamespace("carData", quietly=TRUE)){
withAutoprint({
data("Duncan", package="carData")
m.lm &lt;- lm(prestige ~ income + education, data=Duncan)
mse(Duncan$prestige, fitted(m.lm))

data("Mroz", package="carData")
m.glm &lt;- glm(lfp ~ ., data=Mroz, family=binomial)
BayesRule(Mroz$lfp == "yes", fitted(m.glm))
})
} else {
cat("\n install 'carData' package to run these examples\n")
}
</code></pre>


</div>