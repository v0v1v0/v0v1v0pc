<div class="container">

<table style="width: 100%;"><tr>
<td>visualize_error_boxplot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>visualize_error_boxplot</h2>

<h3>Description</h3>

<p>compares error values among different calibration models. A boxplots is created from the n error values that were obtained during the n-times repeated Cross-Validation procedure.
Different error values are implemented and can be compared:
<br> discrimination error = sensitivity, specificity, accuracy, AUC (when <code>discrimination</code>=TRUE)
<br> calibration error = ece, mce, rmse, class 0 cle, class 1 cle (when <code>discrimination</code>=FALSE)
For the calculation of the errors, see the respective methods listed in the "see also" section
</p>


<h3>Usage</h3>

<pre><code class="language-R">visualize_error_boxplot(list_models, discrimination = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>list_models</code></td>
<td>
<p>list object that contains all error values for all trained calibration models. For the specific format, see the calling function <code>visualize_calibratR</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discrimination</code></td>
<td>
<p>boolean (TRUE or FALSE). If TRUE, discrimination errors are compared between models; if FALSE calibration error is compared, Default: TRUE</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class list, with the following components:
<br> if <code>discrimination</code>=TRUE
</p>
<table>
<tr style="vertical-align: top;">
<td><code>sens</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to sensitivity.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spec</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to specificity</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>acc</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to accuracy</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>auc</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to AUC</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>list_errors</code></td>
<td>
<p>list object that contains all discrimination error values that were used to construct the boxplots</p>
</td>
</tr>
</table>
<p><br> if <code>discrimination</code>=FALSE
</p>
<table>
<tr style="vertical-align: top;">
<td><code>ece</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to expected calibration error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mce</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to maximum expected calibration error (MCE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rmse</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to root mean square error (RMSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cle_0</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to class 0 classification error (CLE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cle_1</code></td>
<td>
<p>ggplot2 boxplot that compares all evaluated calibration models with regard to class 1 classification error (CLE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>list_errors</code></td>
<td>
<p>list object that contains all calibration error values that were used to construct the boxplots</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>ggplot</code>,<code>aes</code>,<code>ggtitle</code>,<code>scale_x_discrete</code>,<code>geom_boxplot</code>,<code>theme</code>,<code>element_text</code>
<code>melt</code>,<code>get_CLE_class</code>,<code>getECE</code>,<code>getMCE</code>,<code>getRMSE</code>, <code>evaluate_discrimination</code>
</p>


</div>