<div class="container">

<table style="width: 100%;"><tr>
<td>outlierplot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot various graphics to analyse outliers.</h2>

<h3>Description</h3>

<p>A collection of plots emphasing different aspects of possible outliers.
</p>


<h3>Usage</h3>

<pre><code class="language-R">outlierplot(X,...)
## S3 method for class 'acomp'
outlierplot(X,colcode=colorsForOutliers1,
  pchcode=pchForOutliers1,
  type=c("scatter","biplot","dendrogram","ecdf","portion","nout","distdist"),
  legend.position,pch=19,...,clusterMethod="ward",
  myCls=classifier(X,alpha=alpha,type=class.type,corrected=corrected),
  classifier=OutlierClassifier1,
  alpha=0.05,
  class.type="best",
  Legend,pow=1,
  main=paste(deparse(substitute(X))),
  corrected=TRUE,robust=TRUE,princomp.robust=FALSE,
                              mahRange=exp(c(-5,5))^pow,
                              flagColor="red",
                              meanColor="blue",
                              grayColor="gray40",
                              goodColor="green",
                              mahalanobisLabel="Mahalanobis Distance"
                              )
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>The dataset as an <code>acomp</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>colcode</code></td>
<td>
<p>A color palette for factor given by the <code>myCls</code>,
or function to create it from the factor. Use <code>colorForOutliers2</code> if
<code>class.method="all"</code> is used. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pchcode</code></td>
<td>
<p>A function to create a plot character palette for the factor
returned by the <code>myCls</code> call</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p> The type of plot to be produced. See details for more
precise definitions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>legend.position</code></td>
<td>
<p>The location of the legend. Must!!! be given to
draw a classical legend.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pch</code></td>
<td>
<p>A default plotting char</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments to the used plotting function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clusterMethod</code></td>
<td>
<p>The clustering method for <code>hclust</code>
based outlier grouping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>myCls</code></td>
<td>
<p>A factor presenting the groups of outliers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier</code></td>
<td>
<p>The routine to create a factor presenting the groups
of outliers heuristically. It is only used in the default argument
to <code>myCls</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The confidence level to be used for outlier
classification tests</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class.type</code></td>
<td>
<p>The type of classification that should be generated
by <code>classifier</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Legend</code></td>
<td>
<p>The content will be substituted and stored as list entry
legend in the result of the function. It can than be evaluated to
actually create a seperate legend on another device (e.g. for
publications).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pow</code></td>
<td>
<p>The power of Mahalanobis distances to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>
<p>The title of the graphic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corrected</code></td>
<td>
<p>Literature typically proposes to compare the
Mahalanobis distances with the distribution of a random Mahalanobis
distance. However it would be needed to correct this for (dependent)
multiple testing, since we always test the whole dataset, which means
comparing against the distribution of the maximum Mahalanobis
distance. This argument switches to this second behavior, giving less
outliers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>robust</code></td>
<td>
<p>A robustness description as define in
<code>robustnessInCompositions</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>princomp.robust</code></td>
<td>
<p>Either a logical determining wether or not the
principal component analysis should be done robustly or a principal
component object for the dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mahRange</code></td>
<td>
<p>The range of Mahalanobis distances displayed. This is
fixed to make views comparable among datasets. However if the preset
default is not enough a warning is issued and a red mark is drawn in
the plot</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>flagColor</code></td>
<td>
<p>The color to draw critical situations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meanColor</code></td>
<td>
<p>The color to draw typical curves.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>goodColor</code></td>
<td>
<p>The color to draw confidence bounds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grayColor</code></td>
<td>
<p>The color to draw less important things.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mahalanobisLabel</code></td>
<td>
<p>The axis label to be used for axes displaying
Mahalanobis distances.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See outliersInCompositions for a comprehensive introduction
into the outlier
treatment in compositions.
</p>

<dl>
<dt><code>type="scatter"</code></dt>
<dd>
<p>Produces an appropriate standard plot such as a tenary diagram with
the outliers marked by there codes according to the given classifier
and colorcoding and pch coding.
<br>
This shows the actual values of the identified outliers.
</p>
</dd>
<dt><code>type="biplot"</code></dt>
<dd>
<p>Creates a biplot based on a nonrobust principal component analysis
showing the outliers classified through outliers in the given color
scheme. We use the nonrobust principal component analyis since it
rotates according to a good visibility of the extreme values.
<br>
This shows the position of the outliers in the usual principal
components analysis. However note that a <code>coloredBiplot</code>
is used rather than the usual one. 
</p>
</dd>
</dl>
<dl>
<dt><code>type="dendrogram"</code></dt>
<dd>
<p>Shows a dendrogram based on robust Mahalanobis distance
based hierachical clustering, where the observations are labeled
with the identified outlier classes. 
<br>
This plot can be used to see how good different categories of
outliers cluster.
</p>
</dd>
<dt><code>type="ecdf"</code></dt>
<dd>
<p>This plot provides a cummulated distribution function of the
Mahalanobis distances along with an expeced curve and a lower
confidence limit. The empirical cdf is plotted in the default
color. The expected cdf is displayed in <code>meanColor</code>. The
<code>alpha</code>-quantile – i.e. a lower prediction bound – for the
cdf is given in goodColor. A line in <code>grayColor</code> show the
minium portion of observations above some limit to be
outliers, based on the portion of observations necessary to move
down to make the empirical distribution function get above its lower
prediction limit under the assumption of normality.
<br>
This plot shows the basic construction for the minimal number of
outlier computation done in <code>type="portion"</code>. 
</p>
</dd>
<dt><code>type="portion"</code></dt>
<dd>
<p>This plot focusses on numbers of outliers. The horizontal axis
give Mahalanobis distances and the vertical axis number of
observations. In <code>meanColor</code> we see a curve of an estimated
number of outliers above some limit, generated by estimating the
portion of outliers with a Mahalanobis distance over the given
limit by max(0,1-ecdf/cdf). The minimum
number of outliers is computed by replacing cdf by its lower
confidence limit and displayed in <code>goodColor</code>. The
Mahalanobis distances of the individual data points are added as a
stacked <code>stripchart</code>, such that the influence of
individual observations can be seen.
<br>
The true problem of outlier detection is to detect "near"
outliers. Near outliers are outliers so near to the dataset that
they could well be extrem observation. These near outliers would
provide no problem unless they are not many showing up in
groups. Graphic allows at least to count them and to show there
probable Mahalanobis distance such, however it still does not
allow to conclude that an individual observation is an
outlier. However still the outlier candidates can be identified
comparing their mahalanobis distance (returned by the plot
as<code>$mahalanobis</code>) with a cutoff inferred from this graphic. 
</p>
</dd>
<dt><code>type="nout"</code></dt>
<dd>
<p>This is a simplification of the previous plot simply providing the
number of outliers over a given limit.
<br></p>
</dd>
<dt><code>type="distdist"</code></dt>
<dd>
<p>Plots a scatterplot of the the classical and robust Mahalanobis
distance with the given classification for colors and plot
symbols. Furthermore it plots a horizontal line giving the 0.95-Quantil
of the distribution of the maximum robust Mahalanobis distance of
normally distributed dataset.
</p>
</dd>
</dl>
<h3>Value</h3>

<p>a list respresenting the criteria computed to create the plots. The
content of the list depends on the plotting type selected.
</p>


<h3>Note</h3>

<p>The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code>OutlierClassifier1</code>, <code>ClusterFinder1</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
data(SimulatedAmounts)
outlierplot(acomp(sa.outliers5))

datas &lt;- list(data1=sa.outliers1,data2=sa.outliers2,data3=sa.outliers3,
                data4=sa.outliers4,data5=sa.outliers5,data6=sa.outliers6)

opar&lt;-par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
outlierplot(x,type="scatter",class.type="grade");
  title(y)
},datas,names(datas))


par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
  myCls2 &lt;- OutlierClassifier1(x,alpha=0.05,type="all",corrected=TRUE)
  outlierplot(x,type="scatter",classifier=OutlierClassifier1,class.type="best",
  Legend=legend(1,1,levels(myCls),xjust=1,col=colcode,pch=pchcode),
  pch=as.numeric(myCls2));
  legend(0,1,legend=levels(myCls2),pch=1:length(levels(myCls2)))
  title(y)
},datas,names(datas))
# To slow
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="ecdf",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="portion",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="nout",main=names(datas)[i])
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="distdist",main=names(datas)[i])
par(opar)


## End(Not run)
</code></pre>


</div>