<div class="container">

<table style="width: 100%;"><tr>
<td>dabipf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Data augmentation-Bayesian IPF algorithm for incomplete categorical
data
</h2>

<h3>Description</h3>

<p>Markov-Chain Monte Carlo method for simulating draws from the
observed-data posterior distribution of underlying cell probabilities
under hierarchical loglinear models. May be used in conjunction with
<code>imp.cat</code> to create proper multiple imputations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dabipf(s, margins, start, steps=1, prior=0.5, showits=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>

<p>summary list of an incomplete categorical dataset created by the
function <code>prelim.cat</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>margins</code></td>
<td>

<p>vector describing the marginal totals to be fitted. A margin
is described by the factors not summed over, and margins are separated
by zeros.  Thus c(1,2,0,2,3,0,1,3) would indicate fitting the (1,2),
(2,3), and (1,3) margins in a three-way table, i.e., the model of no
three-way association.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>

<p>starting value of the parameter. The starting value should lie in the
interior of the parameter space for the given loglinear model. If
structural zeros are present, <code>start</code> should contain zeros in
those positions.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>steps</code></td>
<td>

<p>number of complete cycles of data augmentation-Bayesian IPF to be
performed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>

<p>optional array of hyperparameters specifying a Dirichlet
prior distribution. The default is the Jeffreys prior (all
hyperparameters = .5). If structural zeros are present, a prior
should be supplied with hyperparameters set to <code>NA</code> for those cells.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>showits</code></td>
<td>

<p>if <code>TRUE</code>, reports the iterations so the user can monitor the
progress of the algorithm.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>array of simulated cell probabilities that satisfy the loglinear
model. If the algorithm has converged, this will be a draw from the
actual posterior distribution of the parameters.
</p>


<h3>Note</h3>

<p>The random number generator seed must be set at least once by the
function <code>rngseed</code> before this function can be used.
</p>
<p>The starting value must lie in the interior of the parameter space.
Hence, caution should be used when using a maximum likelihood estimate
(e.g., from <code>ecm.cat</code>) as a starting value. Random zeros in a table
may produce mle's with expected cell counts of zero. This difficulty
can be overcome by using as a starting value a posterior mode
calculated by <code>ecm.cat</code> with prior hyperparameters greater than one.
</p>


<h3>References</h3>

<p>Schafer (1996)  <em>Analysis of Incomplete Multivariate Data.</em>
Chapman &amp; Hall, Chapter 8.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#
#  Example 1   Based on Schafer's p. 329 and ss. This is a toy version,
#              using a much shorter length of chain than required. To 
#              generate results comparable with those in the book, edit
#              the \dontrun{ } line below and comment the previous one.
#
data(belt)
attach(belt.frame)
EB &lt;- ifelse(B1==B2,1,0)
EI &lt;- ifelse(I1==I2,1,0)
belt.frame &lt;- cbind(belt.frame,EB,EI)
colnames(belt.frame)
a &lt;- xtabs(Freq ~ D + S + B2 + I2 + EB + EI,
                data=belt.frame)
m &lt;- list(c(1,2,3,4),c(3,4,5,6),c(1,5),
           c(1,6),c(2,6))
b &lt;- loglin(a,margin=m)                  # fits (DSB2I2)B2I2EBEI)(DEB)(DEI)(SEI)
                                         # in Schafer's p. 304

a &lt;- xtabs(Freq ~ D + S + B2 + I2 + B1 + I1,
                data=belt.frame)
m &lt;- list(c(1,2,5,6),c(1,2,3,4),c(3,4,5,6),
           c(1,3,5),c(1,4,6),c(2,4,6))
b &lt;- loglin(a,margin=m)                  # fits (DSB1I1)(DSB2I2)(B2I2B1I1)(DB1B2)
                                         #  (DI1I2)(SI1I2) in Schafer's p. 329
s &lt;- prelim.cat(x=belt[,-7],counts=belt[,7])
m &lt;- c(1,2,5,6,0,1,2,3,4,0,3,4,5,6,0,1,3,5,0,1,4,6,0,2,4,6)
theta &lt;- ecm.cat(s,margins=m,            # excruciantingly slow; needs 2558
                   maxits=5000)          # iterations.
rngseed(1234)
#
#   Now ten multiple imputations of the missing variables B2, I2 are
#   generated, by running a chain and taking every 2500th observation.
#   Prior hyperparameter is set at 0.5 as in Shchafer's p. 329
#
imputations &lt;- vector("list",10)

for (i in 1:10) {
cat("Doing imputation ",i,"\n")
  theta &lt;- dabipf(s,m,theta,prior=0.5,   # toy chain; for comparison with
                   steps=25)             # results in Schafer's book the next
                                         # statement should be run,
                                         # rather than this one.
  ## Not run: theta &lt;- dabipf(s,m,theta,prior=0.5,steps=2500)			   
  imputations[[i]] &lt;- imp.cat(s,theta)
}
  

		   
detach(belt.frame)
#
#  Example 2   (reproduces analysis performed in Schafer's p. 327.)
#
#  Caveat! I try to reproduce what has been done in that page, but although
#  the general appearance of the boxplots generated below is quite similar to
#  that of  Schafer's Fig. 8.4 (p. 327), the VALUES of the log odds do not
#  quite fall in line with those reported by said author. It doesn't look like
#  the difference can be traced to decimal vs. natural logs. On the other hand,
#  Fig. 8.4 refers to log odds, while the text near the end of page 327 gives
#  1.74 and 1.50 as the means of the *odds* (not log odds). FT, 22.7.2003.
#
#
data(older)                              # reading data
x      &lt;- older[,1:6]                    # preliminary manipulations
counts &lt;- older[,7]
s &lt;- prelim.cat(x,counts)                
colnames(x)                              # names of columns
rngseed(1234)
m &lt;- c(1,2,3,4,5,0,1,2,3,5,6,0,4,3)      # model (ASPMG)(ASPMD)(GD) in
                                         # Schafer's p. 327
                                         # do analysis with different priors
theta   &lt;- ecm.cat(s,m,prior=1.5)        # Strong pull to uniform table
                                         # for initial estimates
prob1   &lt;- dabipf(s,m,theta,steps=100,   # Burn-in period 
                  prior=0.1)
prob2   &lt;- dabipf(s,m,theta,steps=100,   # Id. with second prior
                  prior=1.5)

lodds   &lt;- matrix(0,5000,2)              # Where to store log odds ratios.

oddsr   &lt;- function(x) {                 # Odds ratio of 2 x 2 table.
            o &lt;- (x[1,1]*x[2,2])/
                   (x[1,2]*x[2,1])
            return(o)
            }

for(i in 1:5000) {                       # Now generate 5000 log odds
prob1  &lt;- dabipf(s,m,prob1, prior=0.1)   
t1   &lt;- apply(prob1,c(1,2),sum)          # Marginal GD table
                                         # Log odds ratio
lodds[i,1] &lt;- log(oddsr(t1))
prob2  &lt;- dabipf(s,m,prob2, prior=1.5)   # Id. with second prior
t2   &lt;- apply(prob2,c(1,2),sum)         
lodds[i,2] &lt;- log(oddsr(t2))
}
lodds  &lt;- as.data.frame(lodds)
colnames(lodds) &lt;- c("0.1","1.5")        # Similar to Schafer's Fig. 8.4.
boxplot(lodds,xlab="Prior hyperparameter")
title(main="Log odds ratio generated with DABIPF (5000 draws)")
summary(lodds)

</code></pre>


</div>