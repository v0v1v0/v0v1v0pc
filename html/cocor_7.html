<div class="container">

<table style="width: 100%;"><tr>
<td>cocor.dep.groups.overlap</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compare two overlapping correlations based on dependent groups</h2>

<h3>Description</h3>

<p>Performs a test of significance for the difference between two correlations based on dependent groups (e.g.,
the same group). The two correlations are overlapping, i.e.,
they have one variable in common. The comparison is made between <code>r.jk</code> and <code>r.jh</code>. The function tests whether the correlations between <code>j</code> and <code>k</code> (<code>r.jk</code>) and between <code>j</code> and <code>h</code> (<code>r.jh</code>) differ in magnitude. Because the significance depends on the intercorrelation between <code>k</code> and <code>h</code> (r.kh),
this intercorrelation has to be provided as an additional parameter. The function expects correlation coefficients as input.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cocor.dep.groups.overlap(
  r.jk,
  r.jh,
  r.kh,
  n,
  alternative = "two.sided",
  test = "all",
  alpha = 0.05,
  conf.level = 0.95,
  null.value = 0,
  data.name = NULL,
  var.labels = NULL,
  return.htest = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>r.jk</code></td>
<td>
<p>A number specifying the correlation between <code class="reqn">j</code> and <code class="reqn">k</code> (this correlation is used for comparison)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.jh</code></td>
<td>
<p>A number specifying the correlation between <code class="reqn">j</code> and <code class="reqn">h</code> (this correlation is used for comparison)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.kh</code></td>
<td>
<p>A number specifying the correlation between <code class="reqn">k</code> and <code class="reqn">h</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>An integer defining the size of the group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>A character string specifying whether the alternative hypothesis is two-sided ("<code>two.sided</code>"; default) or one-sided ("<code>greater</code>" or "<code>less</code>",
depending on the direction). Optionally,
the initial letter of the character strings ("<code>t</code>", "<code>g</code>", and "<code>l</code>)" can be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>A vector of character strings specifying the tests to be used (<code>pearson1898</code>,
<code>hotelling1940</code>, <code>hendrickson1970</code>, <code>williams1959</code>, <code>olkin1967</code>,
<code>dunn1969</code>, <code>steiger1980</code>, <code>meng1992</code>, <code>hittner2003</code>,
or <code>zou2007</code>). Use <code>all</code> to apply all tests (default). For further information see the tests section below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>A number defining the alpha level for the hypothesis test. The default value is <code class="reqn">.05</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>
<p>A number defining the level of confidence for the confidence interval (if test <code>meng1992</code> or <code>zou2007</code> is used). The default value is <code class="reqn">.95</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.value</code></td>
<td>
<p>A number defining the hypothesized difference between the two correlations used for testing the null hypothesis. The default value is <code class="reqn">0</code>. If the value is other than <code class="reqn">0</code>,
only the test <code>zou2007</code> that uses a confidence interval is available.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>A character string giving the name of the data/group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.labels</code></td>
<td>
<p>A vector of three character strings specifying the labels for j, k,
and h (in this order).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.htest</code></td>
<td>
<p>A logical indicating whether the result should be returned as a list containing a list of class 'htest' for each test. The default value is <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns an S4 object of class 'cocor.dep.groups.overlap' with the following slots:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>r.jk</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.jh</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r.kh</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.value</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.labels</code></td>
<td>
<p>Input parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diff</code></td>
<td>
<p>Difference between the two correlations, r.jk and r.jh, that were compared</p>
</td>
</tr>
</table>
<p>For each test a slot of the same name exists with a list containing the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic</code></td>
<td>
<p>The value of the test statistic (unless test <code>zou2007</code> is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distribution</code></td>
<td>
<p>The distribution of the test statistic (unless test <code>zou2007</code> is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The degrees of freedom of the distribution of the test statistic (if test <code>hotelling1940</code>,
<code>hendrickson1970</code>, or <code>williams1959</code> is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>The p-value of the test (unless test <code>zou2007</code> is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.int</code></td>
<td>
<p>The confidence interval of the difference between the two correlations (if test <code>meng1992</code> or <code>zou2007</code> is used).</p>
</td>
</tr>
</table>
<h3>Tests</h3>

<p>In the following,
<code class="reqn">r_{jk}</code> and <code class="reqn">r_{jh}</code> are the two correlations that are being compared; <code class="reqn">Z_{jk}</code> and <code class="reqn">Z_{jh}</code> are their <code class="reqn">Z</code> transformed equivalents.
<code class="reqn">r_{kh}</code> is the related correlation that is additionally required.
<code class="reqn">n</code> specifies the size of the group the two correlations are based on.
Some tests make use of Fisher's <code class="reqn">r</code>-to-<code class="reqn">Z</code> transformation (1921, p. 26):
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{1}{2}(ln(1+r) - ln(1-r)).</code>
</p>


<dl>
<dt>pearson1898:</dt>
<dd>
<p><em>Pearson and Filon's (1898) z</em>
</p>
<p>This test was proposed by Pearson and Filon (1898, p. 259, formula xxxvii).
The test statistic <code class="reqn">z</code> is computed as
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{\sqrt{n} (r_{jk} - r_{jh})}{\sqrt{(1 - r_{jk}^2)^2 + (1 - r_{jh}^2)^2 - 2k}}</code>
</p>

<p>(Steiger, 1980, p. 246, formula 4), where
</p>
<p style="text-align: center;"><code class="reqn">k = r_{kh}(1 - r_{jk}^2 - r_{jh}^2) - \frac{1}{2}(r_{jk}r_{jh})(1 - r_{jk}^2 - r_{jh}^2 - r_{kh}^2)</code>
</p>

<p>(Steiger, 1980, p. 245 formula 3).
</p>
</dd>
<dt>hotelling1940:</dt>
<dd>
<p><em>Hotelling's (1940) t</em>
</p>
<p>The test statistic <code class="reqn">t</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">t = \frac{(r_{jk} - r_{jh})\sqrt{(n - 3)(1 + r_{kh})}}{\sqrt{2|R|}}</code>
</p>

<p>(Hotelling, 1940, p. 278, formula 7) with <code class="reqn">df = n - 3</code>, where
</p>
<p style="text-align: center;"><code class="reqn">|R| = 1 + 2 r_{jk} r_{jh} r_{kh} - r_{jk}^2 - r_{jh}^2 - r_{kh}^2</code>
</p>

<p>(Hotelling, 1940, p. 278).
The test statistic is also given in Steiger (1980, p. 246), Glass and Stanley (1984,
p. 311, formula 15.7), and Hittner, May, and Silver (2003, p. 152).
</p>
</dd>
<dt>williams1959:</dt>
<dd>
<p><em>Williams' (1959) t</em>
</p>
<p>This test is a modification of Hotelling's (1940) <code class="reqn">t</code> and was suggested by Williams (1959).
Two mathematically different formulae for Williams' <code class="reqn">t</code> can be found in the literature (Hittner et al.,
2003, p. 152).
This is the version that Hittner et al. (2003,
p. 152) labeled as "standard Williams' <code class="reqn">t</code>":
</p>
<p style="text-align: center;"><code class="reqn">t = (r_{jk} - r_{jh})\sqrt{\frac{(n - 1)(1 + r_{kh})}{2(\frac{n - 1}{n - 3})|R|+\bar r^2(1 - r_{kh})^3}}</code>
</p>

<p>with <code class="reqn">df = n - 3</code>, where
</p>
<p style="text-align: center;"><code class="reqn">\bar r = \frac{r_{jk} + r_{jh}}{2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">|R| = 1 + 2 r_{jk} r_{jh} r_{kh} - r_{jk}^2 - r_{jh}^2 - r_{kh}^2.</code>
</p>

<p>An alternative formula for Williams' <code class="reqn">t</code>—termed as "Williams' modified <code class="reqn">t</code> per Hendrickson,
Stanley, and Hills (1970)" by Hittner et al. (2003,
p. 152)—is implemented in this function as <code>hendrickson1970</code> (see below).
The test statistic of <code>williams1959</code> is also given in Steiger (1980, p. 246,
formula 7) and Neill and Dunn (1975, p. 533).
</p>
<p>Results of <code>williams1959</code> are in accordance with the results of the software DEPCORR by Hittner and May (1998) and DEPCOR by Silver,
Hittner, and May (2006).
However,
we found several typographical errors in formulae that also claim to compute Williams' <code class="reqn">t</code>.
For example, the formula reported by Boyer, Palachek, and Schucany (1983,
p. 76) contains an error because the term <code class="reqn">(1 - r_{rk})</code> is not being cubed.
There are also typographical errors in the formula described by Hittner et al. (2003,
p. 152). For example,
<code class="reqn">r_{jk} - r_{jh}</code> is divided instead of being multiplied by the square root term, and in the denominator of the fraction in the square root term,
there are additional parentheses so that the whole denominator is multiplied by 2.
These same errors can also be found in Wilcox and Tian (2008, p. 107, formula 1).
</p>
</dd>
<dt>olkin1967:</dt>
<dd>
<p><em>Olkin's (1967) z</em>
</p>
<p>In the original article by Olkin (1967, p. 112) and in Hendrickson, Stanley,
and Hills (1970, p. 190, formula 2), the reported formula contains a typographical error.
Hendrickson and Collins (1970, p. 639) provide a corrected version.
In the revised version, however, <code class="reqn">n</code> in the enumerator is decreased by 1.
This function implements the corrected formula without the decrement.
The formula implemented in this function is used by Glass and Stanley (1970, p. 313,
formula 14.19), Hittner et al. (2003, p. 152), and May and Hittner (1997a, p. 259; 1997b,
p. 480):
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{(r_{jk} - r_{jh})\sqrt{n}}{\sqrt{(1 - r_{jk}^2)^2 + (1 - r_{jh}^2)^2 - 2 r_{kh}^3 - (2 r_{kh} - r_{jk} r_{jh}) (1 - r_{kh}^2 - r_{jk}^2 - r_{jh}^2)}}.</code>
</p>

</dd>
<dt>dunn1969:</dt>
<dd>
<p><em>Dunn and Clark's (1969) z</em>
</p>
<p>The test statistic <code class="reqn">z</code> of this test is calculated as
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{(Z_{jk} - Z_{jh})\sqrt{n - 3}}{\sqrt{2 - 2c}}</code>
</p>

<p>(Dunn and Clark, 1969, p. 370, formula 15), where
</p>
<p style="text-align: center;"><code class="reqn">c = \frac{r_{kh}(1 - r_{jk}^2 - r_{jh}^2) - \frac{1}{2} r_{jk} r_{jh} (1 - r_{jk}^2 - r_{jh}^2 - r_{kh}^2)}{(1 - r_{jk}^2)(1 - r_{jh}^2)}</code>
</p>

<p>(Dunn and Clark, 1969, p. 368, formula 8).
</p>
</dd>
<dt>hendrickson1970:</dt>
<dd>
<p><em>Hendrickson, Stanley, and Hills' (1970) modification of Williams' (1959) t</em>
</p>
<p>This test is a modification of Hotelling's (1940) <code class="reqn">t</code> and was suggested by Williams (1959).
Two mathematically different formulae of Williams' (1959) <code class="reqn">t</code> can be found in the literature.
<code>hendrickson1970</code> is the version that Hittner et al. (2003,
p. 152) labeled as "Williams' modified <code class="reqn">t</code> per Hendrickson, Stanley, and Hills (1970)".
An alternative formula termed as "standard Williams' <code class="reqn">t</code>" by Hittner et al. (2003,
p. 152) is implemented as <code>williams1959</code> (see above).
The <code>hendrickson1970</code> formula can be found in Hendrickson, Stanley, and Hills (1970,
p. 193), May and Hittner (1997a, p. 259; 1997b, p. 480), and Hittner et al. (2003,
p. 152):
</p>
<p style="text-align: center;"><code class="reqn">t = \frac{(r_{jk} - r_{jh})\sqrt{(n - 3)(1 + r_{kh})}}{\sqrt{2|R|+\frac{(r_{jk} - r_{jh})^2(1 - r_{kh})^3}{4(n - 1)}}}</code>
</p>

<p>with <code class="reqn">df = n - 3</code>.
A slightly changed version of this formula was provided by Dunn and Clark (1971, p. 905,
formula 1.2), but seems to be erroneous, due to an error in the denominator.
</p>
</dd>
<dt>steiger1980:</dt>
<dd>
<p><em>Steiger's (1980) modification of Dunn and Clark's (1969) z using average correlations</em>
</p>
<p>This test was proposed by Steiger (1980) and is a modification of Dunn and Clark's (1969) <code class="reqn">z</code>.
Instead of <code class="reqn">r_{jk}</code> and <code class="reqn">r_{jh}</code>, the mean of the two is used.
The test statistic <code class="reqn">z</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{(Z_{jk} - Z_{jh})\sqrt{n - 3}}{\sqrt{2 - 2c}}</code>
</p>

<p>(Steiger 1980, p. 247, formula 14), where
</p>
<p style="text-align: center;"><code class="reqn">\bar r = \frac{r_{jk} + r_{jh}}{2}</code>
</p>

<p>(Steiger, 1980, p. 247)
and
</p>
<p style="text-align: center;"><code class="reqn">c = \frac{r_{kh}(1 - 2\bar r^2) - \frac{1}{2}\bar r^2(1 - 2\bar r^2 - r_{kh}^2)}{(1 - \bar r^2)^2}</code>
</p>

<p>(Steiger ,1980, p. 247, formula 10; in the original article,
there are brackets missing around the divisor).
</p>
</dd>
<dt>meng1992:</dt>
<dd>
<p><em>Meng, Rosenthal, and Rubin's (1992) z</em>
</p>
<p>This test is based on the test statistic <code class="reqn">z</code>,
</p>
<p style="text-align: center;"><code class="reqn">z = (Z_{jk} - Z_{jh}) \sqrt{\frac{n - 3}{2(1 - r_{kh})h}},
     </code>
</p>

<p>(Meng et al., 1992, p. 173, formula 1), where
</p>
<p style="text-align: center;"><code class="reqn">h = \frac{1 - f\overline{r^2}}{1 - \overline{r^2}}</code>
</p>

<p>(Meng et al., 1992, p. 173, formula 2),
</p>
<p style="text-align: center;"><code class="reqn">f = \frac{1 - r_{kh}}{2(1 - \overline{r^2})}</code>
</p>

<p>(<code class="reqn">f</code> must be <code class="reqn">\le 1</code>; Meng et al., 1992, p. 173, formula 3), and
</p>
<p style="text-align: center;"><code class="reqn">\overline{r^2} = \frac{r_{jk}^2 + r_{jh}^2}{2}</code>
</p>

<p>(Meng et al., 1992, p. 173).
This test also constructs a confidence interval of the difference between the two correlation coefficients <code class="reqn">r_{jk}</code> and <code class="reqn">r_{jh}</code>:
</p>
<p style="text-align: center;"><code class="reqn">L,
      U = Z_{jk} - Z_{jk} \pm z_{\frac{\alpha}{2}} \sqrt{\frac{2(1 - r_{kh})h}{n - 3}}</code>
</p>

<p>(Meng et al., 1992, p. 173, formula 4).
<code class="reqn">\alpha</code> denotes the desired alpha level of the confidence interval.
If the confidence interval includes zero,
the null hypothesis that the two correlations are equal must be retained.
If zero is outside the confidence interval, the null hypothesis can be rejected.
</p>
</dd>
<dt>hittner2003:</dt>
<dd>
<p><em>Hittner, May,
and Silver's (2003) modification of Dunn and Clark's (1969) z using a backtransformed average Fisher's (1921) Z procedure</em>
</p>
<p>The approach to backtransform averaged Fisher's (1921) <code class="reqn">Z</code>s was first proposed by Silver and Dunlap (1987) and was applied to the comparison of overlapping correlations by Hittner et al. (2003).
The test is based on Steiger's (1980) approach.
The test statistic <code class="reqn">z</code> is calculated as
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{(Z_{jk} - Z_{jh})\sqrt{n - 3}}{\sqrt{2 - 2c}}</code>
</p>

<p>(Hittner et al., 2003, p. 153), where
</p>
<p style="text-align: center;"><code class="reqn">c = \frac{r_{kh}(1 - 2\bar r_z^2) - \frac{1}{2}\bar r_z^2(1 - 2\bar r_z^2 - r_{kh}^2)}{(1 - \bar r_z^2)^2}</code>
</p>

<p>(Hittner et al., 2003, p. 153),
</p>
<p style="text-align: center;"><code class="reqn">\bar r_z = \frac{exp(2\bar Z - 1)}{exp(2\bar Z + 1)}</code>
</p>

<p>(Silver and Dunlap, 1987, p. 146, formula 4), and
</p>
<p style="text-align: center;"><code class="reqn">\bar Z = \frac{Z_{jk} + Z_{jh}}{2}</code>
</p>

<p>(Silver and Dunlap, 1987, p. 146).
</p>
</dd>
<dt>zou2007:</dt>
<dd>
<p><em>Zou's (2007) confidence interval</em>
</p>
<p>This test calculates the confidence interval of the difference between the two correlation coefficients <code class="reqn">r_{jk}</code> and <code class="reqn">r_{jh}</code>.
If the confidence interval includes zero,
the null hypothesis that the two correlations are equal must be retained.
If the confidence interval does not include zero, the null hypothesis has to be rejected.
A lower and upper bound for the interval (<code class="reqn">L</code> and <code class="reqn">U</code>, respectively) is given by
</p>
<p style="text-align: center;"><code class="reqn">L = r_{jk} - r_{jh} - \sqrt{(r_{jk} - l_1)^2 + (u_2 - r_{jh})^2 - 2c(r_{jk} - l_1)(u_2 - r_{jh})}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">U = r_{jk} - r_{jh} + \sqrt{(u_1 - r_{jk})^2 + (r_{jh} - l_2)^2 - 2c(u_1 - r_{jk})(r_{jh} - l_2)}</code>
</p>

<p>(Zou, 2007, p. 409), where
</p>
<p style="text-align: center;"><code class="reqn">l = \frac{exp(2l') - 1}{exp(2l') + 1},</code>
</p>

<p style="text-align: center;"><code class="reqn">u = \frac{exp(2u') - 1}{exp(2u') + 1}</code>
</p>

<p>(Zou, 2007, p. 406),
</p>
<p style="text-align: center;"><code class="reqn">c = \frac{(r_{kh} - \frac{1}{2} r_{jk} r_{jh})(1 - r_{jk}^2- r_{jh}^2- r_{kh}^2) + r_{kh}^3}{(1 - r_{jk}^2)(1 - r_{jh}^2)}</code>
</p>

<p>(Zou, 2007, p. 409), and
</p>
<p style="text-align: center;"><code class="reqn">l',u' = Z \pm z_{\frac{\alpha}{2}} \sqrt{\frac{1}{n - 3}}</code>
</p>

<p>(Zou, 2007, p. 406).
<code class="reqn">\alpha</code> denotes the desired alpha level of the confidence interval.
</p>
</dd>
</dl>
<h3>References</h3>

<p>Boyer, I. E., Palachek, A. D.,
&amp; Schucany. W. R. (1983). An empirical study of related correlation coefficients.  <em>Journal of Educational Statistics</em>,  <em>8</em>,
75-86. doi:10.2307/1164871
</p>
<p>Dunn, O. J. &amp; Clark,
V. A. (1969). Correlation coefficients measured on the same individuals. <em>Journal of the American Statistical Association</em>, <em>64</em>,
366-377. doi:10.2307/2283746
</p>
<p>Dunn, O. J. &amp; Clark,
V. A. (1971). Comparison of tests of the equality of dependent correlation coefficients. <em>Journal of the American Statistical Association</em>, <em>66</em>,
904-908. doi:10.2307/2284252
</p>
<p>Fisher,
R. A. (1921). On the probable error of a coefficient of correlation deduced from a small sample. <em>Metron</em>, <em>1</em>, 1-32.
</p>
<p>Glass, G. V., &amp; Stanley,
J. C. (1970). <em>Statistical methods in eduction and psychology</em>. Englewood Cliffs, NJ: Prentice-Hall.
</p>
<p>Glass, G. V., &amp; Stanley,
J. C. (1984). <em>Statistical methods in eduction and psychology (2nd ed.)</em>. Englewood Cliffs, NJ: Prentice-Hall.
</p>
<p>Hendrickson, G. F., Stanley J. C., &amp; Hills,
J. R. (1970). Olkin's new formula for significance of r13 vs. r23 compared with Hotelling's method. <em>American Educational Research Journal</em>,
<em>7</em>, 189-195. doi:10.2307/1162159
</p>
<p>Hendrickson, G. F., &amp; Collins,
J. R. (1970). Note correcting the results in "Olkin's new formula for the significance of r13 vs. r23 compared with Hotelling's method". <em>American Educational Research Journal</em>,
<em>7</em>, 639-641. doi:10.2307/1161847
</p>
<p>Hittner, J. B., &amp; May,
K. (1998). DEPCORR: A SAS program for comparing dependent correlations. Applied Psychological Measurement, 22, 93-94. doi:10.1177/01466216980221010
</p>
<p>Hittner, J. B., May, K., &amp; Silver,
N. C. (2003). A Monte Carlo evaluation of tests for comparing dependent correlations. <em>The Journal of General Psychology</em>, <em>130</em>,
149-168. doi:10.1080/00221300309601282
</p>
<p>Hotelling, H. (1940). The selection of variates for use in prediction,
with some comments on the general problem of nuisance parameters. <em>Annals of Mathematical Statistics</em>,
<em>11</em>, 271-283. doi:10.1214/aoms/1177731867
</p>
<p>May, K., &amp; Hittner, J. B.,
(1997a) - A note on statistics for comparing dependent correlations. <em>Psychological Reports</em>, <em>80</em>, 475-480. doi:10.2466/pr0.1997.80.2.475
</p>
<p>May, K., &amp; Hittner,
J. B. (1997b). Tests for comparing dependent correlations revisited: A Monte Carlo study. <em>The Journal of Experimental Education</em>, <em>65</em>,
257-269. doi:10.1080/00220973.1997.9943458
</p>
<p>Meng, X. L., Rosenthal, R., &amp; Rubin,
D. B. (1992). Comparing correlated correlation coefficients. <em>Psychological Bulletin</em>, <em>111</em>,
172-175. doi:10.1037//0033-2909.111.1.172
</p>
<p>Neill, J. J., &amp; Dunn,
O. J. (1975). Equality of dependent correlation coefficients. <em>Biometrics</em>, <em>31</em>, 531-543. doi:10.2307/2529435
</p>
<p>Olkin, I. (1967). Correlations revisited. In J. C. Stanley (Ed.),
<em>Improving experimental design and statistical analysis</em> (pp. 102-128). Chicago, IL: Rand McNally.
</p>
<p>Pearson, K., &amp; Filon,
L. N. G. (1898). Mathematical contributions to theory of evolution: IV. On the probable errors of frequency constants and on the influence of random selection and correlation. <em>Philosophical Transactions of the Royal Society of London,
Series A</em>, <em>191</em>, 229-311. doi:10.1098/rsta.1898.0007
</p>
<p>Silver, N. C , &amp; Dunlap,
W. P. (1987). Averaging correlation coefficients: Should Fisher's Z transformation be used? <em>Journal of Applied Psychology</em>, <em>72</em>,
146-148. doi:10.1037//0021-9010.72.1.146
</p>
<p>Silver, N. C., Hittner, J. B., &amp; May,
K. (2004). Testing dependent correlations with nonoverlapping variables: A Monte Carlo simulation. <em>Journal of Experimental Education</em>,
<em>73</em>, 53-69. doi:10.3200/JEXE.71.1.53-70
</p>
<p>Silver, N. C., Hittner, J. B., &amp; May,
K. (2006). A FORTRAN 77 program for comparing dependent correlations. <em>Applied Psychological Measurement</em>, <em>30</em>,
152-153. doi:10.1177/0146621605277132
</p>
<p>Steiger,
J. H. (1980). Tests for comparing elements of a correlation matrix. <em>Psychological Bulletin</em>, <em>87</em>, 245-251. doi:10.1037//0033-2909.87.2.245
</p>
<p>Wilcox, R. R., &amp; Tian,
T. (2008). Comparing dependent correlations. <em>The Journal of General Psychology</em>, <em>135</em>, 105-112. doi:10.3200/GENP.135.1.105-112
</p>
<p>Williams,
E. J. (1959). The comparison of regression variables. <em>Journal of the Royal Statistical Society, Series B</em>, <em>21</em>,
396-399. Retrieved from http://www.jstor.org/stable/2983809
</p>
<p>Zou,
G. Y. (2007). Toward using confidence intervals to compare correlations. <em>Psychological Methods</em>, <em>12</em>, 399-413. doi:10.1037/1082-989X.12.4.399
</p>


<h3>See Also</h3>

<p>cocor, cocor.indep.groups, cocor.dep.groups.nonoverlap,
as.htest
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Compare the difference between the correlations (age, intelligence) and
# (age, shoe size) measured in the same group (all values are fictional):
r.jk &lt;- .2  # Correlation (age, intelligence)
r.jh &lt;- .5  # Correlation (age, shoe size)
r.kh &lt;- .1  # Correlation (intelligence, shoe size)
n &lt;- 315  # Size of the group

cocor.dep.groups.overlap(r.jk, r.jh, r.kh, n, var.labels=c("age", "intelligence",
      "shoe size"))

</code></pre>


</div>