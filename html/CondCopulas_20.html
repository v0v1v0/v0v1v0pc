<div class="container">

<table style="width: 100%;"><tr>
<td>CKT.fit.randomForest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit a Random Forest that can be used for the estimation of conditional Kendall's tau.</h2>

<h3>Description</h3>

<p>Let <code class="reqn">X_1</code> and <code class="reqn">X_2</code> be two random variables.
The goal of this function is to estimate the conditional Kendall's tau
(a dependence measure) between <code class="reqn">X_1</code> and <code class="reqn">X_2</code> given <code class="reqn">Z=z</code>
for a conditioning variable <code class="reqn">Z</code>.
Conditional Kendall's tau between <code class="reqn">X_1</code> and <code class="reqn">X_2</code> given <code class="reqn">Z=z</code>
is defined as:
</p>
<p style="text-align: center;"><code class="reqn">P( (X_{1,1} - X_{2,1})(X_{1,2} - X_{2,2}) &gt; 0 | Z_1 = Z_2 = z)</code>
</p>

<p style="text-align: center;"><code class="reqn">- P( (X_{1,1} - X_{2,1})(X_{1,2} - X_{2,2}) &lt; 0 | Z_1 = Z_2 = z),</code>
</p>

<p>where <code class="reqn">(X_{1,1}, X_{1,2}, Z_1)</code> and <code class="reqn">(X_{2,1}, X_{2,2}, Z_2)</code>
are two independent and identically distributed copies of <code class="reqn">(X_1, X_2, Z)</code>.
In other words, conditional Kendall's tau is the difference
between the probabilities of observing concordant and discordant pairs
from the conditional law of </p>
<p style="text-align: center;"><code class="reqn">(X_1, X_2) | Z=z.</code>
</p>

<p>These functions estimate and predict conditional Kendall's tau using a
<strong>random forest</strong>. This is possible by the relationship between
estimation of conditional Kendall's tau and classification problems
(see Derumigny and Fermanian (2019)): estimation of conditional Kendall's tau
is equivalent to the prediction of concordance in the space of pairs
of observations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">CKT.fit.randomForest(
  datasetPairs,
  designMatrix = data.frame(x = datasetPairs[, 2:(ncol(datasetPairs) - 3)]),
  n,
  nTree = 10,
  mindev = 0.008,
  mincut = 0,
  nObs_per_Tree = ceiling(0.8 * n),
  nVar_per_Tree = ceiling(0.8 * (ncol(datasetPairs) - 4)),
  verbose = FALSE,
  nMaxDepthAllowed = 10
)

CKT.predict.randomForest(fit, newZ)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>datasetPairs</code></td>
<td>
<p>the matrix of pairs and corresponding values of the kernel
as provided by <code>datasetPairs</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>designMatrix</code></td>
<td>
<p>the matrix of predictor to be used for the fitting of the tree</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>the original sample size of the dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTree</code></td>
<td>
<p>number of trees of the Random Forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mindev</code></td>
<td>
<p>a factor giving the minimum deviation for a node to be splitted.
See <code>tree::tree.control()</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mincut</code></td>
<td>
<p>the minimum number of observations (of pairs) in a node
See <code>tree::tree.control()</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nObs_per_Tree</code></td>
<td>
<p>number of observations kept in each tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nVar_per_Tree</code></td>
<td>
<p>number of variables kept in each tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>if <code>TRUE</code>, a message is printed after fitting each tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nMaxDepthAllowed</code></td>
<td>
<p>the maximum number of errors of type
"the tree cannot be fitted" or "is too deep" before stopping the procedure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>result of a call to <code>CKT.fit.randomForest</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newZ</code></td>
<td>
<p>new matrix of observations, with the same number of variables.
and same names as the <code>designMatrix</code> that was used to fit the Random Forest.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list with two components
</p>

<ul>
<li> <p><code>list_tree</code> a list of size <code>nTree</code>
composed of all the fitted trees.
</p>
</li>
<li> <p><code>list_variables</code> a list of size <code>nTree</code>
composed of the (predictor) variables for each tree.
</p>
</li>
</ul>
<p><code>CKT.predict.randomForest</code> returns
a vector of (predicted) conditional Kendall's taus of the same size
as the number of rows of the newZ.
</p>


<h3>References</h3>

<p>Derumigny, A., &amp; Fermanian, J. D. (2019).
A classification point-of-view about conditional Kendallâ€™s tau.
Computational Statistics &amp; Data Analysis, 135, 70-94.
(Algorithm 4)
<a href="https://doi.org/10.1016/j.csda.2019.01.013">doi:10.1016/j.csda.2019.01.013</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># We simulate from a conditional copula
set.seed(1)
N = 800
Z = rnorm(n = N, mean = 5, sd = 2)
conditionalTau = -0.9 + 1.8 * pnorm(Z, mean = 5, sd = 2)
simCopula = VineCopula::BiCopSim(N=N , family = 1,
    par = VineCopula::BiCopTau2Par(1 , conditionalTau ))
X1 = qnorm(simCopula[,1])
X2 = qnorm(simCopula[,2])

datasetP = datasetPairs(X1 = X1, X2 = X2, Z = Z, h = 0.07, cut = 0.9)
est_RF = CKT.fit.randomForest(datasetPairs = datasetP, n = N,
  mindev = 0.008)

newZ = seq(1,10,by = 0.1)
prediction = CKT.predict.randomForest(fit = est_RF,
   newZ = data.frame(x=newZ))
# Comparison between true Kendall's tau (in red)
# and estimated Kendall's tau (in black)
plot(newZ, prediction, type = "l", ylim = c(-1,1))
lines(newZ, -0.9 + 1.8 * pnorm(newZ, mean = 5, sd = 2), col="red")

</code></pre>


</div>