<div class="container">

<table style="width: 100%;"><tr>
<td>caretEnsemble</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Combine several predictive models via weights</h2>

<h3>Description</h3>

<p>Find a greedy, positive only linear combination of several <code>train</code> objects
</p>
<p>Functions for creating ensembles of caret models: caretList and caretStack
</p>


<h3>Usage</h3>

<pre><code class="language-R">caretEnsemble(all.models, excluded_class_id = 0L, tuneLength = 1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>all.models</code></td>
<td>
<p>an object of class caretList</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>excluded_class_id</code></td>
<td>
<p>The integer level to exclude from binary classification or multiclass problems.
By default no classes are excluded, as the greedy optimizer requires all classes because it cannot
use negative coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuneLength</code></td>
<td>
<p>The size of the grid to search for tuning the model. Defaults to 1, as
the only parameter to optimize is the number of iterations, and the default of 100 works well.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to pass caret::train</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>greedyMSE works well when you want an ensemble that will never be worse than any
single model in the dataset. In the worst case scenario, it will select the single
best model, if none of them can be ensembled to improve the overall score. It will
also never assign any model a negative coefficient, which can help avoid
unintuitive cases at prediction time (e.g. if the correlations between
predictors breaks down on new data, negative coefficients can lead to bad results).
</p>


<h3>Value</h3>

<p>a <code>caretEnsemble</code> object
</p>


<h3>Note</h3>

<p>Every model in the "library" must be a separate <code>train</code> object. For
example, if you wish to combine a random forests with several different
values of mtry, you must build a model for each value of mtry. If you
use several values of mtry in one train model, (e.g. tuneGrid =
expand.grid(.mtry=2:5)), caret will select the best value of mtry
before we get a chance to include it in the ensemble. By default,
RMSE is used to ensemble regression models, and AUC is used to ensemble
Classification models. This function does not currently support multi-class
problems
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Zachary A. Deane-Mayer <a href="mailto:zach.mayer@gmail.com">zach.mayer@gmail.com</a> [copyright holder]
</p>
<p>Other contributors:
</p>

<ul>
<li>
<p> Jared E. Knowles <a href="mailto:jknowles@gmail.com">jknowles@gmail.com</a> [contributor]
</p>
</li>
<li>
<p> Antón López <a href="mailto:anton.gomez.lopez@rai.usc.es">anton.gomez.lopez@rai.usc.es</a> [contributor]
</p>
</li>
</ul>
<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="http://zachmayer.github.io/caretEnsemble/">http://zachmayer.github.io/caretEnsemble/</a>
</p>
</li>
<li> <p><a href="https://github.com/zachmayer/caretEnsemble">https://github.com/zachmayer/caretEnsemble</a>
</p>
</li>
<li>
<p> Report bugs at <a href="https://github.com/zachmayer/caretEnsemble/issues">https://github.com/zachmayer/caretEnsemble/issues</a>
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">set.seed(42)
models &lt;- caretList(iris[1:50, 1:2], iris[1:50, 3], methodList = c("rpart", "rf"))
ens &lt;- caretEnsemble(models)
summary(ens)
</code></pre>


</div>