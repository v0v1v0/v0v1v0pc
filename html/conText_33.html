<div class="container">

<table style="width: 100%;"><tr>
<td>get_nns_ratio</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Given a corpus and a binary grouping variable, computes the ratio of cosine similarities
over the union of their respective N nearest neighbors.</h2>

<h3>Description</h3>

<p>This is a wrapper function for <code>nns_ratio()</code> that allows users to go from a
tokenized corpus to results with the option to: (1) bootstrap cosine similarity ratios
and get the corresponding std. errors. (2) use a permutation test to get empirical
p-values for inference.
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_nns_ratio(
  x,
  N = 10,
  groups,
  numerator = NULL,
  candidates = character(0),
  pre_trained,
  transform = TRUE,
  transform_matrix,
  bootstrap = TRUE,
  num_bootstraps = 100,
  confidence_level = 0.95,
  permute = TRUE,
  num_permutations = 100,
  stem = FALSE,
  language = "porter",
  verbose = TRUE,
  show_language = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a (quanteda) tokens object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>(numeric) number of nearest neighbors to return. Nearest neighbors
consist of the union of the top N nearest neighbors of the embeddings in <code>x</code>.
If these overlap, then resulting N will be smaller than 2*N.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>a character or factor variable equal in length to the number of documents</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numerator</code></td>
<td>
<p>(character) defines which group is the nuemerator in the ratio.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>candidates</code></td>
<td>
<p>(character) vector of features to consider as candidates to be nearest neighbor
You may for example want to only consider features that meet a certian count threshold
or exclude stop words etc. To do so you can simply identify the set of features you
want to consider and supply these as a character vector in the <code>candidates</code> argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pre_trained</code></td>
<td>
<p>(numeric) a F x D matrix corresponding to pretrained embeddings.
F = number of features and D = embedding dimensions.
rownames(pre_trained) = set of features for which there is a pre-trained embedding.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transform</code></td>
<td>
<p>(logical) if TRUE (default) apply the 'a la carte' transformation,
if FALSE ouput untransformed averaged embeddings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transform_matrix</code></td>
<td>
<p>(numeric) a D x D 'a la carte' transformation matrix.
D = dimensions of pretrained embeddings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bootstrap</code></td>
<td>
<p>(logical) if TRUE, use bootstrapping â€“ sample from texts with replacement and
re-estimate cosine similarity ratios for each sample. Required to get std. errors.
If <code>groups</code> defined, sampling is automatically stratified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_bootstraps</code></td>
<td>
<p>(integer) number of bootstraps to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>confidence_level</code></td>
<td>
<p>(numeric in (0,1)) confidence level e.g. 0.95</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>permute</code></td>
<td>
<p>(logical) if TRUE, compute empirical p-values using permutation test</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_permutations</code></td>
<td>
<p>(numeric) number of permutations to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stem</code></td>
<td>
<p>(logical) - whether to stem candidates when evaluating nns. Default is FALSE.
If TRUE, candidate stems are ranked by their average cosine similarity to the target.
We recommend you remove misspelled words from candidate set <code>candidates</code> as these can
significantly influence the average.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>language</code></td>
<td>
<p>the name of a recognized language, as returned by
<code>getStemLanguages</code>, or a two- or three-letter ISO-639
code corresponding to one of these languages (see references for
the list of codes).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>provide information on which group is the numerator</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show_language</code></td>
<td>
<p>(logical) if TRUE print out message with language used for stemming.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a <code>data.frame</code> with following columns:
</p>

<dl>
<dt><code>feature</code></dt>
<dd>
<p>(character) features in <code>candidates</code>
(or all features if <code>candidates</code> not defined), one instance for each embedding in <code>x</code>.</p>
</dd>
<dt><code>value</code></dt>
<dd>
<p>(numeric) cosine similarity ratio between <code>x</code>
and feature. Average over bootstrapped samples if bootstrap = TRUE.</p>
</dd>
<dt><code>std.error</code></dt>
<dd>
<p>(numeric) std. error of the similarity value.
Column is dropped if bootstrap = FALSE.</p>
</dd>
<dt><code>lower.ci</code></dt>
<dd>
<p>(numeric) (if bootstrap = TRUE) lower bound of the confidence interval.</p>
</dd>
<dt><code>upper.ci</code></dt>
<dd>
<p>(numeric) (if bootstrap = TRUE) upper bound of the confidence interval.</p>
</dd>
<dt><code>p.value</code></dt>
<dd>
<p>(numeric) empirical p-value of bootstrapped ratio
of cosine similarities if permute = TRUE, if FALSE, column is dropped.</p>
</dd>
<dt><code>group</code></dt>
<dd>
<p>(character) group in <code>groups</code> for which feature belongs
to the top N nearest neighbors. If "shared", the feature appeared as
top nearest neighbor for both groups.</p>
</dd>
</dl>
<h3>Examples</h3>

<pre><code class="language-R">
library(quanteda)

# tokenize corpus
toks &lt;- tokens(cr_sample_corpus)

# build a tokenized corpus of contexts sorrounding a target term
immig_toks &lt;- tokens_context(x = toks, pattern = "immigration", window = 6L)

# sample 100 instances of the target term, stratifying by party (only for example purposes)
set.seed(2022L)
immig_toks &lt;- tokens_sample(immig_toks, size = 100, by = docvars(immig_toks, 'party'))

# we limit candidates to features in our corpus
feats &lt;- featnames(dfm(immig_toks))

# compute ratio
set.seed(2021L)
immig_nns_ratio &lt;- get_nns_ratio(x = immig_toks,
                                 N = 10,
                                 groups = docvars(immig_toks, 'party'),
                                 numerator = "R",
                                 candidates = feats,
                                 pre_trained = cr_glove_subset,
                                 transform = TRUE,
                                 transform_matrix = cr_transform,
                                 bootstrap = FALSE,
                                 num_bootstraps = 100,
                                 permute = FALSE,
                                 num_permutations = 5,
                                 verbose = FALSE)

head(immig_nns_ratio)
</code></pre>


</div>