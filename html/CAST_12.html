<div class="container">

<table style="width: 100%;"><tr>
<td>global_validation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Evaluate 'global' cross-validation</h2>

<h3>Description</h3>

<p>Calculate validation metric using all held back predictions at once
</p>


<h3>Usage</h3>

<pre><code class="language-R">global_validation(model)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>an object of class <code>train</code></p>
</td>
</tr></table>
<h3>Details</h3>

<p>Relevant when folds are not representative for the entire area of interest.
In this case, metrics like R2 are not meaningful since it doesn't reflect the general ability of
the model to explain the entire gradient of the response.
Comparable to LOOCV, predictions from all held back folds are used here together to calculate validation statistics.
</p>


<h3>Value</h3>

<p>regression (<code>postResample</code>) or classification  (<code>confusionMatrix</code>) statistics
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>See Also</h3>

<p><code>CreateSpacetimeFolds</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(caret)
data(cookfarm)
dat &lt;- cookfarm[sample(1:nrow(cookfarm),500),]
indices &lt;- CreateSpacetimeFolds(dat,"SOURCEID","Date")
ctrl &lt;- caret::trainControl(method="cv",index = indices$index,savePredictions="final")
model &lt;- caret::train(dat[,c("DEM","TWI","BLD")],dat$VW, method="rf", trControl=ctrl, ntree=10)
global_validation(model)

## End(Not run)
</code></pre>


</div>