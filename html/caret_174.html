<div class="container">

<table style="width: 100%;"><tr>
<td>negPredValue</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate sensitivity, specificity and predictive values</h2>

<h3>Description</h3>

<p>These functions calculate the sensitivity, specificity or predictive values
of a measurement system compared to a reference results (the truth or a gold
standard). The measurement and "truth" data must have the same two possible
outcomes and one of the outcomes must be thought of as a "positive" results.
</p>


<h3>Usage</h3>

<pre><code class="language-R">negPredValue(data, ...)

## Default S3 method:
negPredValue(
  data,
  reference,
  negative = levels(reference)[2],
  prevalence = NULL,
  ...
)

## S3 method for class 'table'
negPredValue(data, negative = rownames(data)[-1], prevalence = NULL, ...)

## S3 method for class 'matrix'
negPredValue(data, negative = rownames(data)[-1], prevalence = NULL, ...)

posPredValue(data, ...)

## Default S3 method:
posPredValue(
  data,
  reference,
  positive = levels(reference)[1],
  prevalence = NULL,
  ...
)

## S3 method for class 'table'
posPredValue(data, positive = rownames(data)[1], prevalence = NULL, ...)

## S3 method for class 'matrix'
posPredValue(data, positive = rownames(data)[1], prevalence = NULL, ...)

sensitivity(data, ...)

## Default S3 method:
sensitivity(
  data,
  reference,
  positive = levels(reference)[1],
  na.rm = TRUE,
  ...
)

## S3 method for class 'table'
sensitivity(data, positive = rownames(data)[1], ...)

## S3 method for class 'matrix'
sensitivity(data, positive = rownames(data)[1], ...)

specificity(data, ...)

## Default S3 method:
specificity(
  data,
  reference,
  negative = levels(reference)[-1],
  na.rm = TRUE,
  ...
)

## S3 method for class 'table'
specificity(data, negative = rownames(data)[-1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>for the default functions, a factor containing the discrete
measurements. For the <code>table</code> or <code>matrix</code> functions, a table or
matric object, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>not currently used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reference</code></td>
<td>
<p>a factor containing the reference values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>negative</code></td>
<td>
<p>a character string that defines the factor level
corresponding to the "negative" results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prevalence</code></td>
<td>
<p>a numeric value for the rate of the "positive" class of
the data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positive</code></td>
<td>
<p>a character string that defines the factor level
corresponding to the "positive" results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be
stripped before the computation proceeds</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The sensitivity is defined as the proportion of positive results out of the
number of samples which were actually positive. When there are no positive
results, sensitivity is not defined and a value of <code>NA</code> is returned.
Similarly, when there are no negative results, specificity is not defined
and a value of <code>NA</code> is returned. Similar statements are true for
predictive values.
</p>
<p>The positive predictive value is defined as the percent of predicted
positives that are actually positive while the negative predictive value is
defined as the percent of negative positives that are actually negative.
</p>
<p>Suppose a 2x2 table with notation
</p>

<table>
<tr>
<td style="text-align: right;"> </td>
<td style="text-align: center;"> Reference </td>
<td style="text-align: center;"> </td>
</tr>
<tr>
<td style="text-align: right;"> Predicted </td>
<td style="text-align: center;"> Event </td>
<td style="text-align: center;"> No Event
</td>
</tr>
<tr>
<td style="text-align: right;"> Event </td>
<td style="text-align: center;"> A </td>
<td style="text-align: center;"> B </td>
</tr>
<tr>
<td style="text-align: right;"> No Event </td>
<td style="text-align: center;"> C </td>
<td style="text-align: center;"> D </td>
</tr>
<tr>
<td style="text-align: right;"> </td>
</tr>
</table>
<p>The formulas used here are: </p>
<p style="text-align: center;"><code class="reqn">Sensitivity = A/(A+C)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Specificity =
D/(B+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">Prevalence = (A+C)/(A+B+C+D)</code>
</p>
 <p style="text-align: center;"><code class="reqn">PPV = (sensitivity *
Prevalence)/((sensitivity*Prevalence) + ((1-specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">NPV = (specificity * (1-Prevalence))/(((1-sensitivity)*Prevalence) +
((specificity)*(1-Prevalence)))</code>
</p>

<p>See the references for discussions of the statistics.
</p>


<h3>Value</h3>

<p>A number between 0 and 1 (or NA).
</p>


<h3>Author(s)</h3>

<p>Max Kuhn
</p>


<h3>References</h3>

<p>Kuhn, M. (2008), “Building predictive models in R using the
caret package, ” <em>Journal of Statistical Software</em>,
(<a href="https://doi.org/10.18637/jss.v028.i05">doi:10.18637/jss.v028.i05</a>).
</p>
<p>Altman, D.G., Bland, J.M. (1994) “Diagnostic tests 1: sensitivity and
specificity,” <em>British Medical Journal</em>, vol 308, 1552.
</p>
<p>Altman, D.G., Bland, J.M. (1994) “Diagnostic tests 2: predictive values,”
<em>British Medical Journal</em>, vol 309, 102.
</p>


<h3>See Also</h3>

<p><code>confusionMatrix</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
###################
## 2 class example

lvs &lt;- c("normal", "abnormal")
truth &lt;- factor(rep(lvs, times = c(86, 258)),
                levels = rev(lvs))
pred &lt;- factor(
               c(
                 rep(lvs, times = c(54, 32)),
                 rep(lvs, times = c(27, 231))),
               levels = rev(lvs))

xtab &lt;- table(pred, truth)

sensitivity(pred, truth)
sensitivity(xtab)
posPredValue(pred, truth)
posPredValue(pred, truth, prevalence = 0.25)

specificity(pred, truth)
negPredValue(pred, truth)
negPredValue(xtab)
negPredValue(pred, truth, prevalence = 0.25)


prev &lt;- seq(0.001, .99, length = 20)
npvVals &lt;- ppvVals &lt;- prev  * NA
for(i in seq(along = prev))
  {
    ppvVals[i] &lt;- posPredValue(pred, truth, prevalence = prev[i])
    npvVals[i] &lt;- negPredValue(pred, truth, prevalence = prev[i])
  }

plot(prev, ppvVals,
     ylim = c(0, 1),
     type = "l",
     ylab = "",
     xlab = "Prevalence (i.e. prior)")
points(prev, npvVals, type = "l", col = "red")
abline(h=sensitivity(pred, truth), lty = 2)
abline(h=specificity(pred, truth), lty = 2, col = "red")
legend(.5, .5,
       c("ppv", "npv", "sens", "spec"),
       col = c("black", "red", "black", "red"),
       lty = c(1, 1, 2, 2))

###################
## 3 class example

library(MASS)

fit &lt;- lda(Species ~ ., data = iris)
model &lt;- predict(fit)$class

irisTabs &lt;- table(model, iris$Species)

## When passing factors, an error occurs with more
## than two levels
sensitivity(model, iris$Species)

## When passing a table, more than two levels can
## be used
sensitivity(irisTabs, "versicolor")
specificity(irisTabs, c("setosa", "virginica"))

## End(Not run)

</code></pre>


</div>