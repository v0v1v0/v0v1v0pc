<div class="container">

<table style="width: 100%;"><tr>
<td>Partial correlation between two variables</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Partial correlation between two variables
</h2>

<h3>Description</h3>

<p>Partial correlation between two variables.
</p>


<h3>Usage</h3>

<pre><code class="language-R">partialcor2(y, x, z, type = "pearson", rho = 0, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A numerical vector.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A numerical vector.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>

<p>A numerical vector or a numerical matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>

<p>The type of partial correlation coefficient to compute, "pearson" or "spearman".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>

<p>The hypothesized value of the true partial correlation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>The significance level.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Suppose you want to calculate the correlation coefficient between two variables controlling for the effect of (or conditioning on) one or more other variables. So you cant to calculate <code class="reqn">\hat{\rho}\left(X,Y|{\bf Z}\right)</code>, where <code class="reqn">\bf Z</code> is a matrix, since it does not have to be just one variable. This idea was captures by Ronald Fisher some years ago. To calculate it, one can use linear regression as follows.
</p>
<p>1. Calculate the residuals <code class="reqn">\hat{e}_x</code> from the linear regression <code class="reqn">X=a+bZ</code>.
</p>
<p>2. Calculate the residuals <code class="reqn">\hat{e}_y</code> from the linear regression <code class="reqn">Y=c+dZ</code>.
</p>
<p>3. Calculate the correlation between <code class="reqn">\hat{e}_x</code> and <code class="reqn">\hat{e}_y</code>. This is the partial correlation coefficient between <code class="reqn">X</code> and <code class="reqn">Y</code> controlling for <code class="reqn">\bf Z</code>.
</p>
<p>The standard error of the Fisher's transformation of the sample partial correlation is Anderson (2003):
<code class="reqn">\text{SE}\left(\frac{1}{2}\log{\frac{1+\hat{\rho}\left(X,Y|{\bf Z}\right)}{1-\hat{\rho}\left(X,Y|{\bf Z}\right)}}\right)=\frac{1}{n-d-3}</code>, where <code class="reqn">n</code> is the sample size and <code class="reqn">d</code> is the number of variables upon which we control. The standard error is very similar to the one of the classical correlation coefficient. In fact, the latter one is a special case of the first when <code class="reqn">d=0</code> and thus there is no variable whose effect is to be controlled.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>result</code></td>
<td>

<p>The partial correlation coefficient and the p-value for the test of zero partial correlation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>The asymptotic <code class="reqn">(1-\alpha)\%</code> confidence interval for the true partial correlation coefficient.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code> partialcor, pcormat
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- iris[, 1:4]
partialcor2(x[, 1], x[, 2], x[, 3:4])
</code></pre>


</div>