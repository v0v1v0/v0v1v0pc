<div class="container">

<table style="width: 100%;"><tr>
<td>justClusters</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get the List of Classes From A Clustering Algorithm </h2>

<h3>Description</h3>

<p>Unsupervised clustering algorithms, such as partitioning around medoids
(<code>pam</code>), K-means (<code>kmeans</code>), or
hierarchical clustering (<code>hclust</code>) after cutting the tree,
produce a list of class assignments along with other structure. To
simplify the interface for the <code>BootstrapClusterTest</code>  and
<code>PerturbationClusterTest</code>, we have written these routines
that simply extract these cluster assignments.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cutHclust(data, k, method = "average", metric = "pearson")
cutPam(data, k)
cutKmeans(data, k)
cutRepeatedKmeans(data, k, nTimes)

repeatedKmeans(data, k, nTimes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A numerical data matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>The number of classes desired from the algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Any valid linkage method that can be passed to the
<code>hclust</code> function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>Any valid distance metric that can be passed to the
<code>distanceMatrix</code> function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTimes</code></td>
<td>
<p>An integer; the number of times to repeat the K-means
algorithm with a different random starting point</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Each of the clustering routines used here has a different
structure for storing cluster assignments. The <code>kmeans</code>
function stores the assignments in a ‘cluster’ attribute.  The
<code>pam</code> function uses a ‘clustering’ attribute.  For
<code>hclust</code>, the assignments are produced by a call to the
<code>cutree</code> function.
</p>
<p>It has been observed that the K-means algorithm can converge to
different solutions depending on the starting values of the group
centers. We also include a routine (<code>repeatedKmeans</code>) that runs
the K-means algorithm repeatedly, using different randomly generated
staring points each time, saving the best results.
</p>


<h3>Value</h3>

<p>Each of the <code>cut...</code> functions returns a vector of integer values
representing the cluster assignments found by the algorithm.
</p>
<p>The <code>repeatedKmeans</code> function returns a list <code>x</code> with three
components.  The component <code>x$kmeans</code> is the result of the call
to the <code>kmeans</code> function that produced the best fit to the
data. The component <code>x$centers</code> is a matrix containing the list
of group centers that were used in the best call to <code>kmeans</code>.
The component <code>x$withinss</code> contains the sum of the within-group
sums of squares, which is used as the measure of fitness.
</p>


<h3>Author(s)</h3>

<p>Kevin R. Coombes <a href="mailto:krc@silicovore.com">krc@silicovore.com</a>
</p>


<h3>See Also</h3>

<p><code>cutree</code>,
<code>hclust</code>,
<code>kmeans</code>,
<code>pam</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># simulate data from three different groups
d1 &lt;- matrix(rnorm(100*10, rnorm(100, 0.5)), nrow=100, ncol=10, byrow=FALSE)
d2 &lt;- matrix(rnorm(100*10, rnorm(100, 0.5)), nrow=100, ncol=10, byrow=FALSE)
d3 &lt;- matrix(rnorm(100*10, rnorm(100, 0.5)), nrow=100, ncol=10, byrow=FALSE)
dd &lt;- cbind(d1, d2, d3)

cutKmeans(dd, k=3)
cutKmeans(dd, k=4)

cutHclust(dd, k=3)
cutHclust(dd, k=4)

cutPam(dd, k=3)
cutPam(dd, k=4)

cutRepeatedKmeans(dd, k=3, nTimes=10)
cutRepeatedKmeans(dd, k=4, nTimes=10)

# cleanup
rm(d1, d2, d3, dd)
</code></pre>


</div>