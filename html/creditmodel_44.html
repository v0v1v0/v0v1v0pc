<div class="container">

<table style="width: 100%;"><tr>
<td>entropy_weight</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Entropy Weight Method</h2>

<h3>Description</h3>

<p><code>entropy_weight</code> is for calculating Entropy Weight.
</p>


<h3>Usage</h3>

<pre><code class="language-R">entropy_weight(dat, pos_vars, neg_vars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>A data.frame with independent variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_vars</code></td>
<td>
<p>Names or index of positive direction variables, the bigger the better.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neg_vars</code></td>
<td>
<p>Names or index of negative direction variables, the smaller the better.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Step1 Raw data normalization
Step2 Find out the total amount of contributions of all samples to the index Xj
Step3 Each element of the step generated matrix is transformed into the product of each element and the LN (element),
and the information entropy is calculated.
Step4 Calculate redundancy.
Step5 Calculate the weight of each index.
</p>


<h3>Value</h3>

<p>A data.frame with weights of each variable.
</p>


<h3>Examples</h3>

<pre><code class="language-R">entropy_weight(dat = ewm_data,
              pos_vars = c(6,8,9,10),
              neg_vars = c(7,11))
</code></pre>


</div>