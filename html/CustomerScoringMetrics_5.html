<div class="container">

<table style="width: 100%;"><tr>
<td>cutoffSensitivityPlot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot a sensitivity plot for cutoff values</h2>

<h3>Description</h3>

<p>Visualize the sensitivity of a chosen metric to the choice of the threshold (cutoff) value
used to transform continuous predictions into class predictions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cutoffSensitivityPlot(predTest, depTest, metric = c("accuracy",
  "expMisclassCost", "misclassCost"), costType = c("costRatio", "costMatrix",
  "costVector"), costs = NULL, resolution = 1/50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>predTest</code></td>
<td>
<p>Vector with predictions (real-valued or discrete)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>depTest</code></td>
<td>
<p>Vector with true class labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>Which metric to assess. Should be one of the following values:
<code>"accuracy"</code>, <code>"misclassCost"</code> or <code>"expMisclassCost"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>costType</code></td>
<td>
<p>An argument that specifies how the cost information is provided.
This should be either <code>"costRatio"</code> or <code>"costMatrix"</code> when <code>metric</code>
equals <code>"expMisclassCost"</code>; or <code>"costRatio"</code>, <code>"costVector"</code> or
<code>"costMatrix"</code> when <code>metric</code> equals <code>"MisclassCost"</code>. In the former
case, a single value is provided which reflects the cost ratio (the ratio of the cost
associated with a false negative to the cost associated with a false positive). In the
latter case, a full (4x4) misclassification cost matrix should be provided in the form
<code>rbind(c(0,3),c(15,0))</code> where in this example 3 is the cost for a false positive,
and 15 the cost for a false negative case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>costs</code></td>
<td>
<p>see <code>costType</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resolution</code></td>
<td>
<p>Value for the determination of percentile intervals. Default 1/10 (10%).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Koen W. De Bock, <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>
</p>


<h3>See Also</h3>

<p><code>dynAccuracy</code>, <code>misclassCost</code>, <code>expMisclassCost</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Load response modeling predictions
data("response")
## Apply cutoffSensitivityPlot function to visualize how the cutoff value influences
## accuracy.
cutoffSensitivityPlot(response$test[,2],response$test[,1],metric="accuracy")
## Same exercise, but in function of misclassification costs
costs &lt;- runif(nrow(response$test), 1, 50)
cutoffSensitivityPlot(response$test[,2],response$test[,1],metric="misclassCost",
costType="costVector",costs=costs, resolution=1/10)

</code></pre>


</div>