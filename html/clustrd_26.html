<div class="container">

<table style="width: 100%;"><tr>
<td>cluspca</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Joint  dimension  reduction  and  clustering  of  continuous  data.
</h2>

<h3>Description</h3>

<p>This function implements Factorial K-means (Vichi and Kiers, 2001) and Reduced K-means (De Soete and Carroll, 1994), as well as a compromise version of these two methods. The methods combine Principal Component Analysis for dimension reduction with K-means for clustering.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cluspca(data, nclus, ndim, alpha = NULL, method = c("RKM","FKM"), 
center = TRUE, scale = TRUE, rotation = "none", nstart = 100, 
smartStart = NULL, seed = NULL)

## S3 method for class 'cluspca'
print(x, ...)

## S3 method for class 'cluspca'
summary(object, ...)

## S3 method for class 'cluspca'
fitted(object, mth = c("centers", "classes"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Dataset with metric variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nclus</code></td>
<td>
<p>Number of clusters (nclus = 1 returns the PCA solution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ndim</code></td>
<td>
<p>Dimensionality of the solution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Specifies the method. Options are RKM for reduced K-means and FKM for factorial K-means (default = <code>"RKM"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Adjusts for the relative importance of RKM and FKM in the objective function; <code>alpha</code> = 0.5 leads to reduced K-means, <code>alpha</code> = 0 to factorial K-means, and <code>alpha</code> = 1 reduces to the tandem approach (PCA followed by K-means)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>A logical value indicating whether the variables should be shifted to be zero centered (default = <code>TRUE)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>A logical value indicating whether the variables should be scaled to have unit variance before the analysis takes place (default = <code>TRUE)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rotation</code></td>
<td>
<p>Specifies the method used to rotate the factors. Options are <code>none</code> for no rotation, <code>varimax</code> for varimax rotation with Kaiser normalization and <code>promax</code> for promax rotation (default = <code>"none"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nstart</code></td>
<td>
<p>Number of starts (default = 100)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smartStart</code></td>
<td>
<p>If <code>NULL</code> then a random cluster membership vector is generated. Alternatively, a cluster membership vector can be provided as a starting solution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>An integer that is used as argument by <code>set.seed()</code> for offsetting the random number generator when smartStart = NULL. The default value is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>For the <code>print</code> method, a class of <code>clusmca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>For the <code>summary</code> method, a class of <code>clusmca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mth</code></td>
<td>
<p>For the <code>fitted</code> method, a character string that specifies the type of fitted value to return: <code>"centers"</code> for the observations center vector, or <code>"class"</code> for the observations cluster membership value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Not used</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For the K-means part, the algorithm of Hartigan-Wong is used by default.
</p>
<p>The hidden <code>print</code> and <code>summary</code> methods print out some key components of an object of class <code>cluspca</code>. 
</p>
<p>The hidden <code>fitted</code> method returns cluster fitted values. If method is <code>"classes"</code>, this is a vector of cluster membership (the cluster component of the "cluspca" object). If method is <code>"centers"</code>, this is a matrix where each row is the cluster center for the observation. The rownames of the matrix are the cluster membership values.
</p>
<p>When <code>nclus</code> = 1 the function returns the PCA solution and <code>plot(object)</code> shows the corresponding biplot.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obscoord</code></td>
<td>
<p>Object scores</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>attcoord</code></td>
<td>
<p>Variable scores</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centroid</code></td>
<td>
<p>Cluster centroids</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>Cluster membership</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>Optimal value of the objective function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>The number of objects in each cluster</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>A copy of <code>scale</code> in the return object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>A copy of <code>center</code> in the return object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nstart</code></td>
<td>
<p>A copy of <code>nstart</code> in the return object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>odata</code></td>
<td>
<p>A copy of <code>data</code> in the return object</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>De Soete, G., and Carroll, J. D. (1994). K-means clustering in a low-dimensional Euclidean space. In Diday E. et al. (Eds.), <em>New Approaches in Classification and Data Analysis</em>, Heidelberg: Springer, 212-219.
</p>
<p>Vichi, M., and Kiers, H.A.L. (2001). Factorial K-means analysis for two-way data. <em>Computational Statistics and Data Analysis</em>, 37, 49-64.
</p>


<h3>See Also</h3>

<p><code>clusmca</code>, <code>cluspcamix</code>, <code>tuneclus</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">#Reduced K-means with 3 clusters in 2 dimensions after 10 random starts
data(macro)
outRKM = cluspca(macro, 3, 2, method = "RKM", rotation = "varimax", scale = FALSE, nstart = 10)
summary(outRKM)
#Scatterplot (dimensions 1 and 2) and cluster description plot
plot(outRKM, cludesc = TRUE)

#Factorial K-means with 3 clusters in 2 dimensions 
#with a Reduced K-means starting solution
data(macro)
outFKM = cluspca(macro, 3, 2, method = "FKM", rotation = "varimax", 
scale = FALSE, smartStart = outRKM$cluster)
outFKM
#Scatterplot (dimensions 1 and 2) and cluster description plot
plot(outFKM, cludesc = TRUE)

#To get the Tandem approach (PCA(SVD) + K-means)
outTandem = cluspca(macro, 3, 2, alpha = 1, seed = 1234)
plot(outTandem)

#nclus = 1 just gives the PCA solution 
#outPCA = cluspca(macro, 1, 2)
#outPCA
#Scatterplot (dimensions 1 and 2) 
#plot(outPCA)
</code></pre>


</div>