<div class="container">

<table style="width: 100%;"><tr>
<td>jointCOP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute Equal Marginal Probabilities Given a Single Joint AND or OR Probability for a Copula</h2>

<h3>Description</h3>

<p>Given a single <em>joint probability</em> denoted as <code class="reqn">t</code> for a copula <code class="reqn">\mathbf{C}(u,v)</code> numerically solve for bivariate marginal probabilities <code class="reqn">U</code> and <code class="reqn">V</code> such that they are also equal to each other (<code class="reqn">u = v = w</code>). For the case of a <b>joint and</b> probability, the primary diagonal of the copula (Nelsen, 2006, pp. 12 and 16) is solved for by a simple dispatch to the <code>diagCOPatf</code> function instead. Symbolically the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v,\ V \le v] = t = \mathbf{C}(w,w)\mbox{.}</code>
</p>

<p>For the case of a <b>joint or</b> probability, the <em>dual of a copula (function)</em> or <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> from a copula (Nelsen, 2006, pp. 33–34; <code>duCOP</code>) is used where symbolicaly the solution is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = \tilde{\mathbf{C}}(u,v) = u + v - \mathbf{C}(u,v)\mbox{,}</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{Pr}[U \le v \mathrm{\ or\ } V \le v] = t = 2w - \mathbf{C}(w,w)\mbox{.}</code>
</p>

<p>The function for <code>type="or"</code> tests <code class="reqn">\tilde{\mathbf{C}}(0,0)</code> and if it returns <code>NA</code> or <code>NaN</code> then the lower limit for the rooting is treated as <code>.Machine$double.eps</code> instead of 0 (zero).
</p>


<h3>Usage</h3>

<pre><code class="language-R">jointCOP(t, cop=NULL, para=NULL, type=c("and", "or"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>t</code></td>
<td>
<p>The joint probability level <code class="reqn">t</code>;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cop</code></td>
<td>
<p>A copula function;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>para</code></td>
<td>
<p>Vector of parameters or other data structure, if needed, to pass to the copula;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of joint probability is to be computed; and</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to pass to the <code>duCOP</code> function of <span class="pkg">copBasic</span> or <code>uniroot()</code> function.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A vector of the equal <code class="reqn">u</code> and <code class="reqn">v</code> probabilties for the given <code>type</code> at the joint probability level of <code class="reqn">t</code>. The vector includes the <code class="reqn">t</code> as the third element.
</p>


<h3>Note</h3>

<p><em>ENSEMBLE 1—Counting and Copula Probabilities from a Massive Sample Size:</em> Simulations can be used to check/verify select copula concepts. We begin with a <em>Gumbel–Hougaard</em> copula <code class="reqn">\mathbf{GH}(u,v) = \mathbf{C}_{\Theta}(u,v)</code> having parameter <code class="reqn">\Theta = 1.5</code>, which corresponds to a <em>Kendall Tau</em> <code class="reqn">\tau_\mathbf{C} = 1/3</code> (<code>GHcop</code>). Next, simulate and count the number of either <code class="reqn">U</code> or <code class="reqn">V</code> exceeding the 99th percentile “event.” The event can occur either from the random variable <code class="reqn">U</code> or from <code class="reqn">V</code> with equal “loss.” If the event occurs in both <code class="reqn">U</code> and <code class="reqn">V</code>, the loss is just the same as if <code class="reqn">U</code> or <code class="reqn">V</code> occurred. So, if a design were at the 100-year level and thus a 0.01 chance of loss each year, then 500 losses in 50,000 years would be expected.
</p>
<pre>
  set.seed(89); n &lt;- 50000
  UV &lt;- simCOP(n, cop=GHcop, para=1.5, graphics=FALSE)
  length(UV$U[UV$U &gt; 0.99    | UV$V &gt; 0.99])     # 799 times (losses)
  length(UV$U[UV$U &gt; 0.99356 | UV$V &gt; 0.99356])  # 500 times (losses)
</pre>
<p>Letting <code>JP</code> equal 0.99356, which forces the required acceptance of 500 losses for the design has conditions of <code>UV$U &gt; JP</code> <b>or</b> <code>UV$V &gt; JP</code> as well as condition of <code>UV$U &gt; JP</code> <b>and</b> <code>UV$V &gt; JP</code>. These three conditions are captured using the structure of the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> code listed. Up until now, manual searching resulted in a value for <code>JP</code> equaling 0.99356, which produces the 500 count losses (acceptable losses). Thus, <code>JP</code> is a marginal bivariate probability (in this case equality between <code class="reqn">U_{\mathrm{crit.}} = V_{\mathrm{crit.}}</code> declared) necessary to attain a 99th percentile joint protection from loss. The magnitude for either <code class="reqn">U</code> or <code class="reqn">V</code> thus must exceed the 99th percentile, and this is what the code shows with 799 losses.
</p>
<p>It is important to consider that unless <code class="reqn">U</code> and <code class="reqn">V</code> are in perfect positive correlation (<em>e.g.</em> <code class="reqn">\mathbf{M}(u,v)</code>, <code>M</code>, <em>Fréchet–Hoeffding upper-bound copula</em>), that protection from loss needs to be higher than 0.99 if the marginal risk is set at that level. Continuing, if the 99th percentile is the 100-year event, then design criteria should be about 155 years instead [<code>lmomco::prob2T(0.99356)</code>]. The user can readily see this with the switch to perfect independence with the <code class="reqn">\mathbf{GH}(u,v)</code> copula with <code class="reqn">\Theta = 1</code> and produce quite different results or extreme correlation with say <code class="reqn">\Theta &gt; 20</code>.
</p>
<p>To provide the protection for 500 exceedances in <code class="reqn">n =</code> 50,000 trials and for purposes of demonstration, balance the protection between <code class="reqn">U</code> and <code class="reqn">V</code> by setting their probabilities equal, then the theoretical joint probability is
</p>
<pre>
  diagCOPatf(0.99, 0.99, cop=GHcop, para=1.5)             # 0.9936887
  jointCOP(  0.99,       cop=GHcop, para=1.5, type="and") # 0.9936887
</pre>
<p>and these two probabilities, which in reality are actually based on same computation (<code>diagCOPatf</code>), and nearly are the same as <code>JP</code> <code class="reqn">=</code> 0.99356 that was determined by the manual searching on the simulated data.
</p>
<p>A <b>mutually inclusive and</b> condition can be arranged as follows, and it is implicit in the definition that both loss events occur at the same time:
</p>
<pre>
  length(UV$U[UV$U &gt; 0.99 &amp; UV$V &gt; 0.99])            # 208 losses ( simulated )
  surCOP(  1-0.99, 1-0.99, cop=GHcop, para=1.5) * n  # 209 losses (theoretical)
  surfuncCOP(0.99,   0.99, cop=GHcop, para=1.5) * n  # 209 losses (theoretical)
</pre>
<p>What are the expected number of exceedances if designs for <code class="reqn">U</code> and <code class="reqn">V</code> are built at <code class="reqn">U =</code> <code class="reqn">V = 0.99</code> marginal probabilities for protection?
</p>
<pre>
   coCOP(1-0.99, 1-0.99, cop=GHcop, para=1.5)  * n  # 791 losses (theoretical)
  # by the co-copula which from the copula as nonexceedances is
  (1-COP(  0.99,   0.99, cop=GHcop, para=1.5)) * n  # 791 losses (theoretical)
</pre>
<p>Note, the 791 losses is nearly equal to 799, but obviously not 500 as one might incorrectly have imagined strictly in a univariate world.
</p>
<p>Now a couple of questions can be asked about the <b>joint and</b> and <b>joint or</b> probabilities using the definition of a copula <code>COP</code> and then the <em>dual of a copula (function)</em> (<code class="reqn">\tilde{\mathbf{C}}(u,v)</code>, <code>duCOP</code>), respectively:
</p>
<pre>
  # The AND nonexceedances:
  length(UV$U[UV$U &lt;= 0.99 &amp; UV$V &lt;= 0.99]) / n    # 0.98402   ( simulated )
    COP(0.99, 0.99, cop=GHcop, para=1.5)           # 0.9841727 (theoretical)

  # The OR nonexceedances:
  length(UV$U[UV$U &lt;= 0.99 | UV$V &lt;= 0.99]) / n    # 0.99584   ( simulated )
  duCOP(0.99, 0.99, cop=GHcop, para=1.5)           # 0.9958273 (theoretical)
</pre>
<p>How about inversion of <code class="reqn">\tilde{\mathbf{C}}(u,v)</code> by <code>jointCOP</code> and check against the simulation?
</p>
<pre>
  jointCOP(0.99, cop=GHcop, para=1.5, type="or")[1]      # 0.9763951 ( theor. )
  length(UV$U[UV$U &lt;= 0.9763951 | UV$V &lt;= 0.9763951])/n  # 0.98982 ( simulated)
</pre>
<p>The second probability is a value quite near to 0.99. So, if one wants mutual loss protection, compute the inversion of the dual of a copula using <code>jointCOP(..., type="or")</code>. Let us say that 0.80 mutual loss protection is wanted
</p>
<pre>
  jointCOP(0.80, cop=GHcop, para=1.5, type="or")[1]      # 0.6561286
  n - length(UV$U[UV$U &lt;= 0.6561286 | UV$V &lt;= 0.6561286])# 10049 losses ( sim.)
  n - (1-0.8)*n                                    # 10000 losses (theoretical)
</pre>
<p>The example here shows numerical congruence of 10,049 <code class="reqn">\approx</code> 10,000. An opposing question is also useful. How about a <b>mutually exclusive or</b> condition as nonexceedances?
</p>
<pre>
  # The mutually exclusive OR as nonexceedances:
  length((UV$U[  (UV$U &lt;= 0.99 | UV$V &lt;= 0.99) &amp;
               ! (UV$U &lt;= 0.99 &amp; UV$V &lt;= 0.99)]))        # 591 losses ( simulated )
  # The mutually exclusive OR as exceedances:
  length(UV$U[   (UV$U &gt;  0.99 | UV$V &gt;  0.99) &amp;
               ! (UV$U &gt;  0.99 &amp; UV$V &gt;  0.99)])         # 591 losses ( simulated )
</pre>
<p>It is clear that 208 <code class="reqn">+</code> 591 <code class="reqn">=</code> 799 as shown earlier. Readers are asked to notice how there are two ways to get at the 591 count. There are 208 mutual loss events and 591 occassions where either <code class="reqn">U</code> or <code class="reqn">V</code> is the causation of loss. For comparison, how many observed events by random variable?
</p>
<pre>
  length(UV$U[  (UV$U &gt; 0.99)]) # 519 ( simulated )
  length(UV$U[  (UV$V &gt; 0.99)]) # 491 ( simulated )
</pre>
<p>which if they were perfectly uncorrelated (<code class="reqn">\mathbf{P}(u,v)</code>, <code>P</code>, <em>independence copula</em>) would be 519 <code class="reqn">+</code> 491 <code class="reqn">=</code> 1,007 losses. But for the simulations here, 799 losses occurred, so 1,007 <code class="reqn">-</code> 799 <code class="reqn">=</code> 208 losses were at the same time caused by <code class="reqn">U</code> and <code class="reqn">V</code>.
</p>
<p>Both of the following lengths <code>A</code> and <code>B</code> are 799 and both represent a  <b>joint or</b> condition—the operations do not represent a <b>mutually exclusive or</b> condition.
</p>
<pre>
  A &lt;- length(UV$U[UV$U &gt; 0.99]) + length(UV$U[UV$V &gt; 0.99]) -
       length(UV$U[UV$U &gt; 0.99 &amp; UV$V &gt; 0.99])
  B &lt;- length(UV$U[UV$U &gt; 0.99 | UV$V &gt; 0.99]) # A == B == 799
</pre>
<p><em>ENSEMBLE 2—Simulation Study using a Real-World Sample Size:</em> Now with identities of sorts shown and described above, let us test a theoretically consistent version of a sample of size 150 repeated 1,000 times at the 98th percentile against loss by one or the other random variables or both for slightly correlated <code class="reqn">U</code> or <code class="reqn">V</code> again following the Gumbel–Hougaard copula. The losses incurred by mutual event occurrence is the same as if one or the other variables produced an event causing loss.
</p>
<pre>
  n &lt;- 250; nsim &lt;- 1000; EitherEvent &lt;- 0.98; MutualEvent &lt;- 0.99; Theta&lt;- 1.5
  PT &lt;- jointCOP(EitherEvent, cop=GHcop, para=Theta, type="and")[1] # 0.9873537
  DU &lt;- jointCOP(MutualEvent, cop=GHcop, para=Theta, type="or" )[1] # 0.9763951
</pre>
<p>This next code listing is a redundant example to the one that follows but it is shown anyway because a slight possibility of confusion in
the vectorized conditional evaluations in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>. This first example concretely changes the loss events into binary states and adds them up prior to the condition.
</p>
<pre>
  set.seed(894234)
  EX1a &lt;- sapply(1:nsim, function(i) {
                 uv &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
          length(uv$U[ as.numeric(uv$U &gt; PT) + as.numeric(uv$V &gt; PT) &gt;= 1 ]) })
  t.test(EX1a, mu=(1-EitherEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX1a</code><code class="reqn">] =</code> 5 and the simulation run yielded 5.058. The <code>t.test()</code> function in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> results in a statistically insignificant difference. The following two example use a similar there. For sake of both code brevity and clarity, the examples here all restart the simulations at the expense of computation time.
</p>
<pre>
  set.seed(894234)
  EX1b &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; PT | uv$V &gt; PT])  })
  t.test(EX1b, mu=(1-EitherEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX1b</code><code class="reqn">] =</code> 5—the same results are shown as in the first example listing.
</p>
<p>Next, let us demonstrate the dual of a copula for mutually occurring events.
</p>
<pre>
  set.seed(894234)
  EX2 &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; DU &amp; uv$V &gt; DU]) })
  t.test(EX2, mu=(1-MutualEvent) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX2</code><code class="reqn">] =</code> 2.5 and the simulation run yielded 2.49. The <code>t.test()</code> again results in a statistically insignificant difference.
</p>
<p>Now the <code class="reqn">U = V = 0.9873537</code> for the “and” and <code class="reqn">U = V = 0.9763951</code> for the “or” are not equal marginal probabilities. Taking the larger of the two marginal probabilities, the actual joint protection from mutual event occurrance can be computed:
</p>
<pre>
  duCOP(0.9873537, 0.9873537, cop=GHcop, para=Theta) # 0.9947075
  (1-0.9947075)*n  # which is about 1.32 events per 250 trials.
</pre>
<p>So, the larger protection in terms of joint probabilities provided by <code>EitherEvent</code> at 0.98 instead of <code>MutualEvent</code> at 0.99 with respective protection at the 0.9873537 provides a <code>MutualEvent</code> protection of 0.9947075.
</p>
<pre>
  set.seed(894234)
  EX3 &lt;- sapply(1:nsim, function(i) {
                uv  &lt;- simCOP(n, cop=GHcop, para=Theta, graphics=FALSE)
                length(uv$U[uv$U &gt; 0.9873537 &amp; uv$V &gt; 0.9873537]) })
  t.test(EX3, mu=(1-0.9947075) * n)
</pre>
<p>The expected count <code class="reqn">E[</code><code>EX3</code><code class="reqn">] =</code> 1.32 and the simulation run yielded 1.31. The <code>t.test()</code> again results in a statistically insignificant difference, and thus the result indistinguishable from the expectation.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nelsen, R.B., 2006, An introduction to copulas: New York, Springer, 269 p.
</p>


<h3>See Also</h3>

<p><code>diagCOPatf</code>, <code>duCOP</code>, <code>joint.curvesCOP</code>, <code>level.curvesCOP</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">jointCOP(0.50, cop=GHcop, para=1.5, type="and") # 0.6461941  0.6461941  0.5000000
jointCOP(2/3,  cop=GHcop, para=1.5, type="or" ) # 0.4994036  0.4994036  0.6666667

# See extended code listings and discussion in the Note section
</code></pre>


</div>