<div class="container">

<table style="width: 100%;"><tr>
<td>dinvgauss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The Inverse Gaussian Distribution</h2>

<h3>Description</h3>

<p>Density, distribution function, quantile function,
and random generation for the inverse Gaussian distribution.
The corresponding code for these functions as well as the
manual information included here is attributed to
Christophe Pouzat's STAR Package (archived 2022-05-23).
</p>


<h3>Usage</h3>

<pre><code class="language-R">dinvgauss(x, mu = 1, sigma2 = 1, boundary = NULL, log = FALSE)
pinvgauss(q, mu = 1, sigma2 = 1, boundary = NULL, lower.tail = TRUE, log.p = FALSE)
qinvgauss(p, mu = 1, sigma2 = 1, boundary = NULL)
rinvgauss(n = 1, mu = 1, sigma2 = 1, boundary = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x, q</code></td>
<td>
<p>vector of quantiles.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>vector of probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length is taken to be
the number required.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>mean value of the distribution in the default
parameterization, <code>mean value / boundary</code> otherwise. Can also
be viewed as the inverse of the drift of the latent Brownian motion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma2</code></td>
<td>
<p>variance of the latent Brownian motion. When this
parameterization is used (the default) the distance between the "starting" point
and the boundary ("absorbing barrier") is set to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boundary</code></td>
<td>
<p>distance between the starting point and the "absorbing
barrier" of the latent Brownian motion. When this parameterization is
used, the Brownian motion variance is set to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are
<code>P[X &lt;= x]</code>, otherwise, <code>P[X &gt; x]</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log, log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities p are given as log(p).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>With the default, <code>"sigma2"</code>, parameterization (<code>mu = m,
    sigma2 = s^2</code>) the inverse
Gaussian distribution has density:
</p>
<p style="text-align: center;"><code class="reqn">%
    f(x)=\frac{1}{\sqrt{2 \, \pi \, \sigma^2 \, x^3}} \, \exp%
    (-\frac{1}{2}\frac{(x-\mu)^2}{x \, \sigma^2 \, \mu^2})
  </code>
</p>

<p>with <code class="reqn">\sigma^2 &gt; 0</code>.
The theoretical mean is: <code class="reqn">\mu</code> and the theoretical variance is:
<code class="reqn">\mu^3 \sigma^2</code>.
With the default, <code>"boundary"</code>, parameterization (<code>mu = m,
   boundary = b</code>), the inverse
Gaussian distribution has density:
</p>
<p style="text-align: center;"><code class="reqn">%
    f(x)=\frac{b}{\sqrt{2 \, \pi \, x^3}} \, \exp%
    (-\frac{1}{2}\frac{(x-b \, \mu)^2}{x \, \mu^2})
  </code>
</p>

<p>with <code class="reqn">\sigma^2 &gt; 0</code>.
The theoretical mean is: <code class="reqn">\mu \, b</code> and the theoretical variance is:
<code class="reqn">\mu^3 \sigma^2</code>.
The latent Brownian motion is described in Lindsey (2004) pp 209-213,
Whitemore and Seshadri (1987), Aalen and Gjessing (2001) and Gerstein
and Mandelbrot (1964).
</p>
<p>The expression for the distribution function is given in Eq. 4 of
Whitemore and Seshadri (1987).
</p>
<p>Initial guesses for the inversion of the distribution function used
in <code>qinvgauss</code> are obtained with the transformation of Whitemore
and Yalovsky (1978).
</p>
<p>Random variates are obtained with the method of Michael et al (1976)
which is also described by Devroye (1986, p 148) and Gentle (2003, p 193).
</p>


<h3>Value</h3>

<p><code>dinvgauss</code> gives the density, <code>pinvgauss</code> gives the
distribution function, <code>qinvgauss</code> gives the quantile function
and <code>rinvgauss</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Christophe Pouzat  <a href="mailto:christophe.pouzat@gmail.com">christophe.pouzat@gmail.com</a> </p>


<h3>References</h3>

<p>Gerstein, George L. and Mandelbrot, Benoit (1964) Random Walk Models
for the Spike Activity of a Single Neuron. <em>Biophys J.</em> <b>4</b>:
41–68.
</p>
<p>Whitmore, G. A. and Yalovsky, M. (1978) A normalizing logarithmic
transformation for inverse Gaussian random
variables. <em>Technometrics</em> <b>20</b>: 207–208.
</p>
<p>Whitmore, G. A. and Seshadri, V. (1987) A Heuristic
Derivation of the Inverse Gaussian Distribution. <em>The American
Statistician</em> <b>41</b>: 280–281.
</p>
<p>Aalen, Odd O. and Gjessing, Hakon K. (2001) Understanding the Shape of
the Hazard Rate: A Process Point of View. <em>Statistical Science</em>
<b>16</b>: 1–14.
</p>
<p>Lindsey, J.K. (2004) <em>Introduction to Applied Statistics: A
Modelling Approach</em>. OUP.
</p>
<p>Michael, J. R., Schucany, W. R. and Haas, R. W. (1976) Generating
random variates using transformations with multiple roots. <em>The
American Statistician</em> <b>30</b>: 88–90.
</p>
<p>Devroye, L. (1986) <em>Non-Uniform Random Variate
Generation</em>. Springer-Verlag.
</p>
<p>Gentle, J. E. (2003) <em>Random Number Generation and Monte Carlo
Methods</em>. Springer.
</p>


<h3>See Also</h3>

<p><code>invgaussMLE</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## Start with the inverse Gauss
## Define standard mu and sigma
mu.true &lt;- 0.075 ## a mean ISI of 75 ms
sigma2.true &lt;- 3
## Define a sequence of points on the time axis
X &lt;- seq(0.001, 0.3, 0.001)
## look at the density
plot(X, dinvgauss(X, mu.true, sigma2.true), type="l", xlab = "ISI (s)",ylab = "Density")

## Generate a sample of 100 ISI from this distribution
sampleSize &lt;- 100
sampIG &lt;- rinvgauss(sampleSize, mu = mu.true, sigma2 = sigma2.true)
## check out the empirical survival function (obtained with the Kaplan-Meier
## estimator) against the true one
library(survival)
sampIG.KMfit &lt;- survfit(Surv(sampIG, 1 + numeric(length(sampIG))) ~1)
plot(sampIG.KMfit, log = TRUE)
lines(X, pinvgauss(X, mu.true, sigma2.true, lower.tail = FALSE), col = 2)

## Get a ML fit
sampIGmleIG &lt;- invgaussMLE(sampIG)
## compare true and estimated parameters
rbind(est = sampIGmleIG$estimate, se = sampIGmleIG$se, true = c(mu.true, sigma2.true))
## plot contours of the log relative likelihood function
Mu &lt;- seq(sampIGmleIG$estimate[1] - 3 * sampIGmleIG$se[1],
          sampIGmleIG$estimate[1] + 3 * sampIGmleIG$se[1],
          sampIGmleIG$se[1] / 10)
Sigma2 &lt;- seq(sampIGmleIG$estimate[2] - 7 * sampIGmleIG$se[2],
              sampIGmleIG$estimate[2] + 7 * sampIGmleIG$se[2],
              sampIGmleIG$se[2] / 10)
sampIGmleIGcontour &lt;- sapply(Mu, function(mu) sapply(Sigma2,
                            function(s2) sampIGmleIG$r(mu, s2)))
contour(Mu, Sigma2, t(sampIGmleIGcontour),
        levels=c(log(c(0.5, 0.1)), -0.5 * qchisq(c(0.95, 0.99), df = 2)),
        labels=c("log(0.5)",
          "log(0.1)",
          "-1/2 * P(Chi2 = 0.95)",
          "-1/2 * P(Chi2 = 0.99)"),
        xlab = expression(mu), ylab = expression(sigma^2))
points(mu.true, sigma2.true, pch = 16,col = 2)
## We can see that the contours are more parabola like on a log scale
contour(log(Mu),log(Sigma2),t(sampIGmleIGcontour),
        levels = c(log(c(0.5, 0.1)), -0.5 * qchisq(c(0.95, 0.99), df = 2)),
        labels = c("log(0.5)",
          "log(0.1)",
          "-1/2 * P(Chi2 = 0.95)",
          "-1/2 * P(Chi2 = 0.99)"),
        xlab = expression(log(mu)), ylab = expression(log(sigma^2)))
points(log(mu.true), log(sigma2.true), pch = 16, col = 2)
## make a deviance test for the true parameters
pchisq(-2 * sampIGmleIG$r(mu.true, sigma2.true), df = 2)
## check fit with a QQ plot
qqDuration(sampIGmleIG, log = "xy")

## Generate a censored sample using an exponential distribution
sampEXP &lt;- rexp(sampleSize, 1/(2 * mu.true))
sampIGtime &lt;- pmin(sampIG,sampEXP)
sampIGstatus &lt;- as.numeric(sampIG &lt;= sampEXP)
## fit the censored sample
sampIG2mleIG &lt;- invgaussMLE(sampIGtime, sampIGstatus)
## look at the results
rbind(est = sampIG2mleIG$estimate,
      se = sampIG2mleIG$se,
      true = c(mu.true,sigma2.true))
pchisq(-2 * sampIG2mleIG$r(mu.true, sigma2.true), df = 2)
## repeat the survival function estimation
sampIG2.KMfit &lt;- survfit(Surv(sampIGtime, sampIGstatus) ~1)
plot(sampIG2.KMfit, log = TRUE)
lines(X, pinvgauss(X, sampIG2mleIG$estimate[1], sampIG2mleIG$estimate[2],
                  lower.tail = FALSE), col = 2)

## End(Not run)
</code></pre>


</div>