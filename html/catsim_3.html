<div class="container">

<table style="width: 100%;"><tr>
<td>rand</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Similarity Indices</h2>

<h3>Description</h3>

<p>The Rand index, rand_index, computes the agreement
between two different clusterings or partitions of the same  set of objects.
The inputs to the function should be binary or categorical and of the same
length.
</p>
<p>The adjusted Rand index,  <code>adj_rand</code>,
computes a corrected version
of the Rand index, adjusting for the probability
of chance agreement of clusterings. A small constant is added to the
numerator and denominator of the adjusted Rand index to ensure stability
when there is a small or 0 denominator, as it is possible to have a zero
denominator.
</p>
<p>Cohen's kappa, <code>cohen_kappa</code>,
is an inter-rater agreement metric for two raters which
corrects for the probability of chance agreement. Note
there is a difference here
between this measure and the Rand indices and mutual information:
those consider the similarities of the groupings of points,
while this considers how often the
raters agreed on individual points.
</p>
<p>Like the Rand index, the mutual information
computes the agreement between two different clusterings or
partitions of the same set of objects. If <code class="reqn">H(X)</code> is the
entropy of some probability distribution <code class="reqn">X</code>, then
the mutual information of two distributions is
<code class="reqn">I(X;Y) = -H(X,Y) +H(X) + H(Y)</code>.
The normalized mutual information, <code>normalized_mi</code>, is defined here as:
<code class="reqn">2I(X;Y)/(H(X)+H(Y)),</code> but is set to be 0 if both H(X) and H(Y) are 0.
</p>
<p>The adjusted mutual information, <code>adjusted_mi</code>,
is a correction of the mutual information to account
for the probability of chance agreement in a manner similar to the
adjusted Rand index
or Cohen's kappa.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rand_index(x, y, na.rm = FALSE)

adj_rand(x, y, na.rm = FALSE)

cohen_kappa(x, y, na.rm = FALSE)

normalized_mi(x, y, na.rm = FALSE)

adjusted_mi(x, y, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x, y</code></td>
<td>
<p>a numeric or factor vector or array</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>whether to remove <code>NA</code> values. By default, <code>FALSE</code>.
If <code>TRUE</code>, will perform pair-wise deletion.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>the similarity index, which is between 0 and 1 for most of the
options. The adjusted Rand and Cohen's kappa can be negative, but are
bounded above by 1.
</p>


<h3>References</h3>

<p>W. M. Rand (1971). "Objective criteria for the evaluation of clustering
methods". Journal of the American Statistical Association.
American Statistical Association. 66 (336): 846–850.
<a href="https://doi.org/10.2307/2284239">doi:10.2307/2284239</a>
</p>
<p>Lawrence Hubert and Phipps Arabie (1985).
"Comparing partitions". Journal of Classification. 2 (1): 193–218.
<a href="https://doi.org/10.1007/BF01908075">doi:10.1007/BF01908075</a>
</p>
<p>Cohen, Jacob (1960). "A coefficient of agreement for nominal scales".
Educational and Psychological Measurement. 20 (1): 37–46.
<a href="https://doi.org/10.1177/001316446002000104">doi:10.1177/001316446002000104</a>
</p>
<p>Jaccard, Paul (1912). "The distribution of the flora in the alpine zone,”
New Phytologist, vol. 11, no. 2, pp. 37–50.
<a href="https://doi.org/10.1111/j.1469-8137.1912.tb05611.x">doi:10.1111/j.1469-8137.1912.tb05611.x</a>
</p>
<p>Nguyen Xuan Vinh, Julien Epps, and James Bailey (2010).
Information Theoretic Measures for Clusterings Comparison:
Variants, Properties, Normalization and Correction for Chance.
J. Mach. Learn. Res. 11 (December 2010), 2837–2854.
<a href="https://jmlr.org/papers/v11/vinh10a.html">https://jmlr.org/papers/v11/vinh10a.html</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- rep(0:5, 5)
y &lt;- c(rep(0:5, 4), rep(0, 6))
# Simple Matching, or Accuracy
mean(x == y)
# Hamming distance
sum(x != y)
rand_index(x, y)
adj_rand(x, y)
cohen_kappa(x, y)
normalized_mi(x, y)
adjusted_mi(x, y)
</code></pre>


</div>