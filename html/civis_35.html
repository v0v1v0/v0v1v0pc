<div class="container">

<table style="width: 100%;"><tr>
<td>civis_ml_sparse_logistic</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>CivisML Sparse Logistic</h2>

<h3>Description</h3>

<p>CivisML Sparse Logistic
</p>


<h3>Usage</h3>

<pre><code class="language-R">civis_ml_sparse_logistic(
  x,
  dependent_variable,
  primary_key = NULL,
  excluded_columns = NULL,
  penalty = c("l2", "l1"),
  dual = FALSE,
  tol = 1e-08,
  C = 499999950,
  fit_intercept = TRUE,
  intercept_scaling = 1,
  class_weight = NULL,
  random_state = 42,
  solver = c("liblinear", "newton-cg", "lbfgs", "sag"),
  max_iter = 100,
  multi_class = c("ovr", "multinomial"),
  fit_params = NULL,
  cross_validation_parameters = NULL,
  calibration = NULL,
  oos_scores_table = NULL,
  oos_scores_db = NULL,
  oos_scores_if_exists = c("fail", "append", "drop", "truncate"),
  model_name = NULL,
  cpu_requested = NULL,
  memory_requested = NULL,
  disk_requested = NULL,
  notifications = NULL,
  polling_interval = NULL,
  verbose = FALSE,
  civisml_version = "prod"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>See the Data Sources section below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dependent_variable</code></td>
<td>
<p>The dependent variable of the training dataset.
For a multi-target problem, this should be a vector of column names of
dependent variables. Nulls in a single dependent variable will
automatically be dropped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>primary_key</code></td>
<td>
<p>Optional, the unique ID (primary key) of the training
dataset. This will be used to index the out-of-sample scores. In
<code>predict.civis_ml</code>, the primary_key of the training task is used by
default <code>primary_key = NA</code>. Use <code>primary_key = NULL</code> to
explicitly indicate the data have no primary_key.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>excluded_columns</code></td>
<td>
<p>Optional, a vector of columns which will be
considered ineligible to be independent variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>Used to specify the norm used in the penalization. The
<code>newton-cg</code>, <code>sag</code>, and <code>lbfgs</code> solvers support only l2
penalties.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dual</code></td>
<td>
<p>Dual or primal formulation. Dual formulation is only implemented
for <code>l2</code> penalty with the <code>liblinear</code> solver. <code>dual = FALSE</code>
should be preferred when n_samples &gt; n_features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Tolerance for stopping criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>Inverse of regularization strength, must be a positive float.
Smaller values specify stronger regularization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit_intercept</code></td>
<td>
<p>Should a constant or intercept term be included in the
model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept_scaling</code></td>
<td>
<p>Useful only when the <code>solver = "liblinear"</code>
and <code>fit_intercept = TRUE</code>. In this case, a constant term with the
value <code>intercept_scaling</code> is added to the design matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_weight</code></td>
<td>
<p>A <code>list</code> with <code>class_label = value</code> pairs, or
<code>balanced</code>. When <code>class_weight = "balanced"</code>, the class weights
will be inversely proportional to the class frequencies in the input data
as:
</p>
<p style="text-align: center;"><code class="reqn"> \frac{n_samples}{n_classes * table(y)} </code>
</p>

<p>Note, the class weights are multiplied with <code>sample_weight</code>
(passed via <code>fit_params</code>) if <code>sample_weight</code> is specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random_state</code></td>
<td>
<p>The seed of the random number generator to use when
shuffling the data. Used only in <code>solver = "sag"</code> and
<code>solver = "liblinear"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>solver</code></td>
<td>
<p>Algorithm to use in the optimization problem. For small data
<code>liblinear</code> is a good choice. <code>sag</code> is faster for larger
problems. For multiclass problems, only <code>newton-cg</code>, <code>sag</code>, and
<code>lbfgs</code> handle multinomial loss. <code>liblinear</code> is limited to
one-versus-rest schemes. <code>newton-cg</code>, <code>lbfgs</code>, and <code>sag</code>
only handle the <code>l2</code> penalty.
</p>
<p>Note that <code>sag</code> fast convergence is only guaranteed on features with
approximately the same scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>The maximum number of iterations taken for the solvers to
converge. Useful for the <code>newton-cg</code>, <code>sag</code>, and <code>lbfgs</code>
solvers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multi_class</code></td>
<td>
<p>The scheme for multi-class problems. When <code>ovr</code>, then
a binary problem is fit for each label. When <code>multinomial</code>, a single
model is fit minimizing the multinomial loss. Note, <code>multinomial</code> only
works with the <code>newton-cg</code>, <code>sag</code>, and <code>lbfgs</code> solvers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit_params</code></td>
<td>
<p>Optional, a mapping from parameter names in the model's
<code>fit</code> method to the column names which hold the data, e.g.
<code>list(sample_weight = 'survey_weight_column')</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cross_validation_parameters</code></td>
<td>
<p>Optional, parameter grid for learner
parameters, e.g. <code>list(n_estimators = c(100, 200, 500),
learning_rate = c(0.01, 0.1), max_depth = c(2, 3))</code>
or <code>"hyperband"</code> for supported models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calibration</code></td>
<td>
<p>Optional, if not <code>NULL</code>, calibrate output
probabilities with the selected method, <code>sigmoid</code>, or <code>isotonic</code>.
Valid only with classification models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>oos_scores_table</code></td>
<td>
<p>Optional, if provided, store out-of-sample
predictions on training set data to this Redshift "schema.tablename".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>oos_scores_db</code></td>
<td>
<p>Optional, the name of the database where the
<code>oos_scores_table</code> will be created. If not provided, this will default
to <code>database_name</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>oos_scores_if_exists</code></td>
<td>
<p>Optional, action to take if
<code>oos_scores_table</code> already exists. One of <code>"fail"</code>, <code>"append"</code>, <code>"drop"</code>, or <code>"truncate"</code>.
The default is <code>"fail"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_name</code></td>
<td>
<p>Optional, the prefix of the Platform modeling jobs.
It will have <code>" Train"</code> or <code>" Predict"</code> added to become the Script title.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cpu_requested</code></td>
<td>
<p>Optional, the number of CPU shares requested in the
Civis Platform for training jobs or prediction child jobs.
1024 shares = 1 CPU.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>memory_requested</code></td>
<td>
<p>Optional, the memory requested from Civis Platform
for training jobs or prediction child jobs, in MiB.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>disk_requested</code></td>
<td>
<p>Optional, the disk space requested on Civis Platform
for training jobs or prediction child jobs, in GB.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>notifications</code></td>
<td>
<p>Optional, model status notifications. See
<code>scripts_post_custom</code> for further documentation about email
and URL notification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>polling_interval</code></td>
<td>
<p>Check for job completion every this number of seconds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Optional, If <code>TRUE</code>, supply debug outputs in Platform
logs and make prediction child jobs visible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>civisml_version</code></td>
<td>
<p>Optional, a one-length character vector of the
CivisML version. The default is "prod", the latest version in production</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>civis_ml</code> object, a list containing the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>job</code></td>
<td>
<p>job metadata from <code>scripts_get_custom</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>run</code></td>
<td>
<p>run metadata from <code>scripts_get_custom_runs</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outputs</code></td>
<td>
<p>CivisML metadata from <code>scripts_list_custom_runs_outputs</code> containing the locations of
files produced by CivisML e.g. files, projects, metrics, model_info, logs, predictions, and estimators.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metrics</code></td>
<td>
<p>Parsed CivisML output from <code>metrics.json</code> containing metadata from validation.
A list containing the following elements:
</p>

<ul>
<li>
<p> run list, metadata about the run.
</p>
</li>
<li>
<p> data list, metadata about the training data.
</p>
</li>
<li>
<p> model list, the fitted scikit-learn model with CV results.
</p>
</li>
<li>
<p> metrics list, validation metrics (accuracy, confusion, ROC, AUC, etc).
</p>
</li>
<li>
<p> warnings list.
</p>
</li>
<li>
<p> data_platform list, training data location.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_info</code></td>
<td>
<p>Parsed CivisML output from <code>model_info.json</code> containing metadata from training.
A list containing the following elements:
</p>

<ul>
<li>
<p> run list, metadata about the run.
</p>
</li>
<li>
<p> data list, metadata about the training data.
</p>
</li>
<li>
<p> model list, the fitted scikit-learn model.
</p>
</li>
<li>
<p> metrics empty list.
</p>
</li>
<li>
<p> warnings list.
</p>
</li>
<li>
<p> data_platform list, training data location.
</p>
</li>
</ul>
</td>
</tr>
</table>
<h3>Data Sources</h3>

<p>For building models with <code>civis_ml</code>, the training data can reside in
four different places, a file in the Civis Platform, a CSV or feather-format file
on the local disk, a <code>data.frame</code> resident in local the R environment, and finally,
a table in the Civis Platform. Use the following helpers to specify the
data source when calling <code>civis_ml</code>:
</p>

<dl>
<dt><code>data.frame</code></dt>
<dd>
<p><code>civis_ml(x = df, ...)</code></p>
</dd>
<dt>local csv file</dt>
<dd>
<p><code>civis_ml(x = "path/to/data.csv", ...)</code></p>
</dd>
<dt>file in Civis Platform</dt>
<dd>
<p><code>civis_ml(x = civis_file(1234))</code></p>
</dd>
<dt>table in Civis Platform</dt>
<dd>
<p><code>civis_ml(x = civis_table(table_name = "schema.table", database_name = "database"))</code></p>
</dd>
</dl>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

df &lt;- iris
names(df) &lt;- gsub("\\.", "_", names(df))

m &lt;- civis_ml_sparse_logistic(df, "Species")
yhat &lt;- fetch_oos_scores(m)

# Grid Search
cv_params &lt;- list(C = c(.01, 1, 10, 100, 1000))

m &lt;- civis_ml_sparse_logistic(df, "Species",
  cross_validation_parameters = cv_params)

# make a prediction job, storing in a redshift table
pred_info &lt;- predict(m, newdata = civis_table("schema.table", "my_database"),
   output_table = "schema.scores_table")


## End(Not run)
</code></pre>


</div>