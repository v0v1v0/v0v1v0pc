<div class="container">

<table style="width: 100%;"><tr>
<td>defaultSummary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculates performance across resamples</h2>

<h3>Description</h3>

<p>Given two numeric vectors of data, the mean squared error and
R-squared are calculated. For two factors, the overall agreement
rate and Kappa are determined.
</p>


<h3>Usage</h3>

<pre><code class="language-R">defaultSummary(data, lev = NULL, model = NULL)

postResample(pred, obs)

twoClassSummary(data, lev = NULL, model = NULL)

mnLogLoss(data, lev = NULL, model = NULL)

multiClassSummary(data, lev = NULL, model = NULL)

prSummary(data, lev = NULL, model = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data frame with columns <code>obs</code> and
<code>pred</code> for the observed and predicted outcomes. For metrics
that rely on class probabilities, such as
<code>twoClassSummary</code>, columns should also include predicted
probabilities for each class. See the <code>classProbs</code> argument
to <code>trainControl</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lev</code></td>
<td>
<p>a character vector of factors levels for the
response. In regression cases, this would be <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a character string for the model name (as taken
from the <code>method</code> argument of <code>train</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>A vector of numeric data (could be a factor)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>A vector of numeric data (could be a factor)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>postResample</code> is meant to be used with <code>apply</code>
across a matrix. For numeric data the code checks to see if the
standard deviation of either vector is zero. If so, the
correlation between those samples is assigned a value of zero.
<code>NA</code> values are ignored everywhere.
</p>
<p>Note that many models have more predictors (or parameters) than
data points, so the typical mean squared error denominator (n -
p) does not apply. Root mean squared error is calculated using
<code>sqrt(mean((pred - obs)^2</code>. Also, <code class="reqn">R^2</code> is calculated
wither using as the square of the correlation between the
observed and predicted outcomes when <code>form = "corr"</code>. when
<code>form = "traditional"</code>, </p>
<p style="text-align: center;"><code class="reqn"> R^2 = 1-\frac{\sum (y_i -
 \hat{y}_i)^2}{\sum (y_i - \bar{y})^2} </code>
</p>
<p>. Mean absolute error
is calculated using <code>mean(abs(pred-obs))</code>.
</p>
<p><code>defaultSummary</code> is the default function to compute
performance metrics in <code>train</code>. It is a wrapper
around <code>postResample</code>. The first argument is <code>data</code>,
which is <code>data.frame</code> with columns named <code>obs</code> and
<code>pred</code> for the observed and predicted outcome values
(either numeric data for regression or character values for
classification). The second argument is <code>lev</code>, a character
string that has the outcome factor levels or NULL for a
regression model. The third parameter is <code>model</code>, which can
be used if a summary metric is specific to a model function. If
other columns from the data are required to compute the summary
statistics, but should not be used in the model, the
<code>recipe</code> method for <code>train</code> can be used.
</p>
<p><code>twoClassSummary</code> computes sensitivity, specificity and
the area under the ROC curve. <code>mnLogLoss</code> computes the
minus log-likelihood of the multinomial distribution (without
the constant term): </p>
<p style="text-align: center;"><code class="reqn"> -logLoss = \frac{-1}{n}\sum_{i=1}^n
 \sum_{j=1}^C y_{ij} \log(p_{ij}) </code>
</p>
<p> where the <code>y</code> values are
binary indicators for the classes and <code>p</code> are the predicted
class probabilities.
</p>
<p><code>prSummary</code> (for precision and recall) computes values for
the default 0.50 probability cutoff as well as the area under
the precision-recall curve across all cutoffs and is labelled as
<code>"AUC"</code> in the output. If assumes that the first level of
the factor variables corresponds to a relevant result but the
<code>lev</code> argument can be used to change this.
</p>
<p><code>multiClassSummary</code> computes some overall measures of for
performance (e.g. overall accuracy and the Kappa statistic) and
several averages of statistics calculated from "one-versus-all"
configurations. For example, if there are three classes, three
sets of sensitivity values are determined and the average is
reported with the name ("Mean_Sensitivity"). The same is true
for a number of statistics generated by
<code>confusionMatrix</code>. With two classes, the basic
sensitivity is reported with the name "Sensitivity".
</p>
<p>To use <code>twoClassSummary</code> and/or <code>mnLogLoss</code>, the
<code>classProbs</code> argument of <code>trainControl</code> should
be <code>TRUE</code>. <code>multiClassSummary</code> can be used without
class probabilities but some statistics (e.g. overall log loss
and the average of per-class area under the ROC curves) will not
be in the result set.
</p>
<p>Other functions can be used via the <code>summaryFunction</code>
argument of <code>trainControl</code>. Custom functions must
have the same arguments as<code>defaultSummary</code>.
</p>
<p>The function <code>getTrainPerf</code> returns a one row data frame
with the resampling results for the chosen model. The statistics
will have the prefix "<code>Train</code>" (i.e. "<code>TrainROC</code>").
There is also a column called "<code>method</code>" that echoes the
argument of the call to <code>trainControl</code> of the same
name.
</p>


<h3>Value</h3>

<p>A vector of performance estimates.
</p>


<h3>Author(s)</h3>

<p>Max Kuhn, Zachary Mayer
</p>


<h3>References</h3>

<p>Kvalseth. Cautionary note about <code class="reqn">R^2</code>. American Statistician
(1985) vol. 39 (4) pp. 279-285
</p>


<h3>See Also</h3>

<p><code>trainControl</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
predicted &lt;-  matrix(rnorm(50), ncol = 5)
observed &lt;- rnorm(10)
apply(predicted, 2, postResample, obs = observed)

classes &lt;- c("class1", "class2")
set.seed(1)
dat &lt;- data.frame(obs =  factor(sample(classes, 50, replace = TRUE)),
                  pred = factor(sample(classes, 50, replace = TRUE)),
                  class1 = runif(50))
dat$class2 &lt;- 1 - dat$class1

defaultSummary(dat, lev = classes)
twoClassSummary(dat, lev = classes)
prSummary(dat, lev = classes)
mnLogLoss(dat, lev = classes)

</code></pre>


</div>