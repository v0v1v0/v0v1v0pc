<div class="container">

<table style="width: 100%;"><tr>
<td>clustIndex</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cluster Indexes</h2>

<h3>Description</h3>

<p><code>y</code> is the result of a clustering algorithm of class such
as <code>"cclust"</code>.
This function is calculating the values of several clustering
indexes. The values of the indexes can be independently used in order
to determine the number of clusters existing in a data set.
</p>


<h3>Usage</h3>

<pre><code class="language-R"> clustIndex ( y, x, index = "all" ) </code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Object of class <code>"cclust"</code> returned by a clustering algorithm such as <code>kmeans</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Data matrix where columns correspond to variables and rows to observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>The indexes that are calculated <code>"calinski"</code>,
<code>"cindex"</code>, <code>"db"</code>, <code>"hartigan"</code>, <code>"ratkowsky"</code>,
<code>"scott"</code>, <code>"marriot"</code>, <code>"ball"</code>, <code>"trcovw"</code>,
<code>"tracew"</code>, <code>"friedman"</code>, <code>"rubin"</code>, <code>"ssi"</code>,
<code>"likelihood"</code>, and <code>"all"</code> for all the
indexes. Abbreviations of these names are also accepted.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The description of the indexes is categorized into 3 groups, based
on the statistics mainly used to compute them.
</p>
<p>The first group is based on the sum of squares within (<code class="reqn">SSW</code>)
and between (<code class="reqn">SSB</code>) the clusters. These statistics measure the
dispersion of the data points in a cluster and between the clusters
respectively. These indexes are:
</p>

<dl>
<dt>
<b>calinski</b>:</dt>
<dd>
<p><code class="reqn">(SSB/(k-1))/(SSW/(n-k))</code>, where <code class="reqn">n</code> is the number of
data points and <code class="reqn">k</code> is the number of clusters.
</p>
</dd>
<dt>
<b>hartigan</b>:</dt>
<dd>
<p>then <code class="reqn">\log(SSB/SSW)</code>.</p>
</dd>
<dt>
<b>ratkowsky</b>:</dt>
<dd>
<p><code class="reqn">mean(\sqrt{(varSSB/varSST)})</code>, where <code class="reqn">varSSB</code> stands
for the <code class="reqn">SSB</code> for every variable and <code class="reqn">varSST</code> for the
total sum of squares for every variable.
</p>
</dd>
<dt>
<b>ball</b>:</dt>
<dd>
<p><code class="reqn">SSW/k</code>, where <code class="reqn">k</code> is the number of clusters.
</p>
</dd>
</dl>
<p>The second group is based on the statistics of <code class="reqn">T</code>, i.e., the
scatter matrix of the data points, and <code class="reqn">W</code>, which is the sum of the
scatter matrices in every group. These indexes are:
</p>

<dl>
<dt>
<b>scott</b>:</dt>
<dd>
<p><code class="reqn">n\log(|T|/|W|)</code>, where <code class="reqn">n</code> is the number of data points
and <code class="reqn">|\cdot|</code> stands for the determinant of a matrix.</p>
</dd>
<dt>
<b>marriot</b>:</dt>
<dd>
<p><code class="reqn">k^2 |W|</code>, where <code class="reqn">k</code> is the number of clusters.</p>
</dd>
<dt>
<b>trcovw</b>:</dt>
<dd>
<p><code class="reqn">Trace Cov W</code>.</p>
</dd>
<dt>
<b>tracew</b>:</dt>
<dd>
<p><code class="reqn">Trace W</code>.</p>
</dd>
<dt>
<b>friedman</b>:</dt>
<dd>
<p><code class="reqn">Trace W^{(-1)} B</code>, where <code class="reqn">B</code> is the scatter matrix of
the cluster centers.</p>
</dd>
<dt>
<b>rubin</b>:</dt>
<dd>
<p><code class="reqn">|T|/|W|</code>.</p>
</dd>
</dl>
<p>The third group consists of four algorithms not belonging to the
previous ones and not having anything in common.
</p>

<dl>
<dt>
<b>cindex</b>:</dt>
<dd>
<p>if the data set is binary, then while the C-Index is a cluster
similarity measure, is expressed as:<br><code class="reqn">[d_{(w)}-\min(d_{(w)})]/[\max(d_{(w)})-\min(d_{(w)})]</code>,
where <code class="reqn">d_{(w)}</code> is the sum of all <code class="reqn">n_{(d)}</code> within
cluster distances, <code class="reqn">\min(d_{(w)})</code> is the sum of the
<code class="reqn">n_{(d)}</code> smallest pairwise distances in the data set, and
<code class="reqn">\max (d_{(w)})</code> is the sum of the <code class="reqn">n_{(d)}</code> biggest
pairwise distances.  In order to compute the C-Index all
pairwise distances in the data set have to be computed and
stored.  In the case of binary data, the storage of the
distances is creating no problems since there are only a few
possible distances.  However, the computation of all distances
can make this index prohibitive for large data sets.</p>
</dd>
<dt>
<b>db</b>:</dt>
<dd>
<p><code class="reqn">R=(1/n)*sum(R_{(i)})</code>
where <code class="reqn">R_{(i)}</code> stands for the maximum value of
<code class="reqn">R_{(ij)}</code> for <code class="reqn">i\neq j</code>, and <code class="reqn">R_{(ij)}</code> for
<code class="reqn">R_{(ij)}=(SSW_{(i)}+SSW_{(j)})/DC_{(ij)}</code>, where
<code class="reqn">DC_{(ij)}</code> is the 
distance between the centers of two clusters <code class="reqn">i, j</code>.</p>
</dd>
<dt>
<b>likelihood</b>:</dt>
<dd>
<p>under the assumption of
independence of the variables within a cluster, a cluster solution
can be regarded as a mixture model for the data, where the cluster
centers give the probabilities for each variable to be
<code class="reqn">1</code>. Therefore, the negative Log-likelihood can be computed and
used as a quantity measure for a cluster solution. Note that the
assumptions for applying special penalty terms, like in AIC or BIC,
are not fulfilled in this model, and also they show no effect for
these data sets.</p>
</dd>
<dt>
<b>ssi</b>:</dt>
<dd>
<p>this “Simple Structure Index”
combines three elements which influence the interpretability of a
solution, i.e., the maximum difference of each variable between the
clusters, the sizes of the most contrasting clusters and the
deviation of a variable in the cluster centers compared to its
overall mean. These three elements are multiplicatively combined and
normalized to give a value between <code class="reqn">0</code> and <code class="reqn">1</code>.</p>
</dd>
</dl>
<h3>Value</h3>

<p>Returns an vector with the indexes values.
</p>


<h3>Author(s)</h3>

<p>Evgenia Dimitriadou and Andreas Weingessel
</p>


<h3>References</h3>

<p>Andreas Weingessel, Evgenia Dimitriadou and Sara Dolnicar,
An Examination Of Indexes For Determining The Number
Of Clusters In Binary Data Sets,<br><a href="https://epub.wu.ac.at/1542/">https://epub.wu.ac.at/1542/</a><br>
and the references therein.
</p>


<h3>See Also</h3>

<p><code>cclust</code>, <code>kmeans</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># a 2-dimensional example
x&lt;-rbind(matrix(rnorm(100,sd=0.3),ncol=2),
         matrix(rnorm(100,mean=1,sd=0.3),ncol=2))
cl&lt;-cclust(x,2,20,verbose=TRUE,method="kmeans")
resultindexes &lt;- clustIndex(cl,x, index="all")
resultindexes   
</code></pre>


</div>