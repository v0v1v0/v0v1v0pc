<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.rfcat</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Impute categorical variables using Random Forest within MICE
</h2>

<h3>Description</h3>

<p>This method can be used to impute logical or factor variables
(binary or &gt;2 levels) in MICE by specifying
method = 'rfcat'. It was developed independently from the
<code>mice.impute.rf</code> algorithm of Doove et al.,
and differs from it in some respects.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.rfcat(y, ry, x, ntree_cat = NULL,
    nodesize_cat = NULL, maxnodes_cat = NULL, ntree = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a logical or factor vector of observed values and missing values of the variable to be imputed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>

<p>a logical vector stating whether y is observed or not.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a matrix of predictors to impute y.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree_cat</code></td>
<td>

<p>number of trees, default = 10.
</p>
<p>A global option can be set thus: <code>setRFoptions(ntree_cat=10)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nodesize_cat</code></td>
<td>

<p>minimum size of nodes, default = 1.
</p>
<p>A global option can be set thus: <code>setRFoptions(nodesize_cat=1)</code>.
Smaller values of nodesize create finer, more precise trees but increase the computation time.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxnodes_cat</code></td>
<td>

<p>maximum number of nodes, default NULL. If NULL the number of nodes is determined by number of observations and nodesize_cat.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree</code></td>
<td>

<p>an alternative argument for specifying the number of trees, over-ridden by <code>ntree_cat</code>. This is for consistency with the <code>mice.impute.rf</code> function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>other arguments to pass to randomForest.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This Random Forest imputation algorithm has been developed as an alternative to logistic or
polytomous regression, and can accommodate non-linear relations and interactions among the
predictor variables without requiring them to be specified in the model. The algorithm takes
a bootstrap sample of the data to simulate sampling variability, fits a set of classification
trees, and chooses each imputed value as the prediction of a randomly chosen tree.
</p>


<h3>Value</h3>

<p>A vector of imputed values of y.
</p>


<h3>Note</h3>

<p>This algorithm has been tested on simulated data and in survival analysis of real data
with artificially introduced missingness completely at random. There was slight bias in
hazard ratios compared to polytomous regression, but coverage of confidence intervals was
correct.
</p>


<h3>Author(s)</h3>

<p>Anoop Shah
</p>


<h3>References</h3>

<p>Shah AD, Bartlett JW, Carpenter J, Nicholas O, Hemingway H.
Comparison of Random Forest and parametric imputation models for imputing missing
data using MICE: a CALIBER study. American Journal of Epidemiology 2014; 179(6): 764â€“774. doi:10.1093/aje/kwt312
<a href="https://academic.oup.com/aje/article/179/6/764/107562">https://academic.oup.com/aje/article/179/6/764/107562</a>
</p>


<h3>See Also</h3>

<p><code>setRFoptions</code>,
<code>mice.impute.rfcont</code>,
<code>mice</code>,
<code>mice.impute.rf</code>,
<code>mice.impute.cart</code>,
<code>randomForest</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)

# A small sample dataset 
mydata &lt;- data.frame(
    x1 = as.factor(c('this', 'this', NA, 'that', 'this')),
    x2 = 1:5,
    x3 = c(TRUE, FALSE, TRUE, NA, FALSE))
mice(mydata, method = c('logreg', 'norm', 'logreg'), m = 2, maxit = 2)
mice(mydata[, 1:2], method = c('rfcat', 'rfcont'), m = 2, maxit = 2)
mice(mydata, method = c('rfcat', 'rfcont', 'rfcat'), m = 2, maxit = 2)

# A larger simulated dataset
mydata &lt;- simdata(100, x2binary = TRUE)
mymardata &lt;- makemar(mydata)

cat('\nNumber of missing values:\n')
print(sapply(mymardata, function(x){sum(is.na(x))}))

# Test imputation of a single column in a two-column dataset
cat('\nTest imputation of a simple dataset')
print(mice(mymardata[, c('y', 'x2')], method = 'rfcat', m = 2, maxit = 2))

# Analyse data
cat('\nFull data analysis:\n')
print(summary(lm(y ~ x1 + x2 + x3, data = mydata)))

cat('\nMICE normal and logistic:\n')
print(summary(pool(with(mice(mymardata,
    method = c('', 'norm', 'logreg', '', ''), m = 2, maxit = 2),
    lm(y ~ x1 + x2 + x3)))))

# Set options for Random Forest
setRFoptions(ntree_cat = 10)

cat('\nMICE using Random Forest:\n')
print(summary(pool(with(mice(mymardata,
    method = c('', 'rfcont', 'rfcat', '', ''), m = 2, maxit = 2),
    lm(y ~ x1 + x2 + x3)))))

cat('\nDataset with unobserved levels of a factor\n')
data3 &lt;- data.frame(x1 = 1:100, x2 = factor(c(rep('A', 25),
    rep('B', 25), rep('C', 25), rep('D', 25))))
data3$x2[data3$x2 == 'D'] &lt;- NA
mice(data3, method = c('', 'rfcat'), m = 2, maxit = 2)
</code></pre>


</div>