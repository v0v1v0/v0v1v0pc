<div class="container">

<table style="width: 100%;"><tr>
<td>calibrate</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Calibration of  probabilities according to the given prior.</h2>

<h3>Description</h3>

<p>Given probability scores <code>predictedProb</code> as provided for example by a call to <code>predict.CoreModel</code> 
and using one of available methods given by <code>methods</code> the function calibrates predicted probabilities  so that they 
match the actual probabilities of a binary class 1 provided by <code>correctClass</code>. 
The computed calibration can be applied to the scores returned by that model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
calibrate(correctClass, predictedProb, class1=1, 
          method = c("isoReg","binIsoReg","binning","mdlMerge"), 
          weight=NULL, noBins=10, assumeProbabilities=FALSE)
          
applyCalibration(predictedProb, calibration)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>correctClass</code></td>
<td>
<p> A vector of correct class labels for a binary classification problem. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictedProb</code></td>
<td>
<p> A vector of predicted class 1 (probability) scores. In <code>calibrate</code> method it should be of the same length as <code>correctClass</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class1</code></td>
<td>
<p>A class value (factor) or an index of the class value to be taken as a class to be calibrated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p> One of <code>isoReg</code>, <code>binIsoReg</code>, <code>binning</code>, or <code>mdlMerge</code>. See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>
<p> If specified, should be of the same length as <code>correctClass</code> and gives the weights for all the instances, 
otherwise a default weight of 1 for each instance is assumed. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noBins</code></td>
<td>
<p>The value of parameter depends on the parameter <code>method</code> and specifies desired or initial number of bins. See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>assumeProbabilities</code></td>
<td>
<p> If <code>assumeProbabilities=TRUE</code> the values in <code>predictedProb</code> are expected to be in [0,1] range i.e., probability estimates. 
<code>assumeProbabilities=FALSE</code> the algorithm can be used as ordinary (isotonic) regression    </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calibration</code></td>
<td>
<p>The list resulting from a call to <code>calibration</code> and subsequently applied to probability scores returned by the same model.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Depending on the specified <code>method</code> one of the following calibration methods is executed.
</p>

<ul>
<li> <p><code>"isoReg"</code> isotonic regression calibration based on pair-adjacent violators (PAV) algorithm.
</p>
</li>
<li> <p><code>"binning"</code> calibration into a pre-specified number of bands given by <code>noBins</code> parameter, trying to make bins of equal weight.
</p>
</li>
<li> <p><code>"binIsoReg"</code> first binning method is executed, following by a isotonic regression calibration.
</p>
</li>
<li> <p><code>"mdlMerge"</code> first intervals are merged by a MDL gain criterion into a prespecified number of intervals, following by the isotonic regression calibration.
</p>
</li>
</ul>
<p>If <code>model="binning"</code> the parameter <code>noBins</code> specifies the desired number of bins i.e., calibration bands;
if <code>model="binIsoReg"</code> the parameter <code>noBins</code> specifies the number of initial bins that are formed by binning before isotonic regression is applied;
if <code>model="mdlMerge"</code>  the parameter <code>noBins</code> specifies the number of bins formed after first applying isotonic regression. The most similar bins are merged using MDL criterion.
</p>


<h3>Value</h3>

<p>A function returns a list with two vector components of the same length:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>interval</code></td>
<td>
<p>The boundaries of the intervals. Lower boundary 0 is not explicitly included but should be taken into account.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>calProb</code></td>
<td>
<p>The calibrated probabilities for each corresponding interval.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>References</h3>

 
<p>I. Kononenko, M. Kukar: <em>Machine Learning and Data Mining: Introduction to Principles and Algorithms. </em> Horwood, 2007
</p>
<p>A. Niculescu-Mizil, R. Caruana: Predicting Good Probabilities With Supervised Learning. <em>Proceedings of the 22nd International Conference on Machine Learning (ICML'05)</em>, 2005
</p>


<h3>See Also</h3>

<p><code>reliabilityPlot</code>,
<code>CORElearn</code>,
<code>predict.CoreModel</code>
.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate data set separately for training the model, 
#   calibration of probabilities and testing
train &lt;-classDataGen(noInst=200)
cal &lt;-classDataGen(noInst=200)
test &lt;- classDataGen(noInst=200)

# build random forests model with default parameters
modelRF &lt;- CoreModel(class~., train, model="rf", maxThreads=1)

# prediction 
predCal &lt;- predict(modelRF, cal, rfPredictClass=FALSE)
predTest &lt;- predict(modelRF, test, rfPredictClass=FALSE)
destroyModels(modelRF) # clean up, model not needed anymore

# calibrate for a chosen class1 and method
class1&lt;-1
calibration &lt;- calibrate(cal$class, predCal$prob[,class1], class1=class1, 
                         method="isoReg",assumeProbabilities=TRUE)

# apply the calibration to the testing set
calibratedProbs &lt;- applyCalibration(predTest$prob[,class1], calibration)
# the calibration of probabilities can be visualized with 
# reliabilityPlot function

</code></pre>


</div>