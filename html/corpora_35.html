<div class="container">

<table style="width: 100%;"><tr>
<td>simulated.wikipedia</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Simulated type and token counts for Wikipedia articles (corpora)</h2>

<h3>Description</h3>

<p>This function generates type and token counts, token-type ratios (TTR) and
average word length for simulated articles from the English Wikipedia.
Simulation paramters are based on data from the Wackypedia corpus.
</p>
<p>The generated data set is usually named <code>WackypediaStats</code> (see code examples below)
and is used for various exercises and illustrations in the SIGIL course.
</p>


<h3>Usage</h3>

<pre><code class="language-R">
simulated.wikipedia(N=1429649, length=c(100,1000), seed.rng=42)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>population size, i.e. total number of Wikipedia articles</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>length</code></td>
<td>
<p>a numeric vector of length 2, specifying the typical range of Wikipedia article lengths</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed.rng</code></td>
<td>
<p>seed for the random number generator, so data sets with the same parameters (<code>N</code> and <code>lenght</code>) are reproducible</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The default population size corresponds to the subset of the Wackypedia corpus from which
the simulation parameters were obtained.  This excludes all articles with extreme type-token
statistics (very short, very long, extremely long words, etc.).
</p>
<p>Article lengths are sampled from a lognormal distribution which is scaled so that the
central 95% of the values fall into the range specified by the <code>length</code> argument.
</p>
<p>The simulated data are surprising close to the original Wackypedia statistics.
</p>


<h3>Value</h3>

<p>A data frame with <code>N</code> rows corresponding to Wikipedia articles and the following columns:
</p>

<dl>
<dt>
<code>tokens</code>:</dt>
<dd>
<p>number of word tokens in the article</p>
</dd>
<dt>
<code>types</code>:</dt>
<dd>
<p>number of distinct word types in the article</p>
</dd>
<dt>
<code>ttr</code>:</dt>
<dd>
<p>token-type ratio (TTR) for the article</p>
</dd>
<dt>
<code>avglen</code>:</dt>
<dd>
<p>average word length in characters (averaged across tokens)</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Stephanie Evert (<a href="https://purl.org/stephanie.evert">https://purl.org/stephanie.evert</a>)</p>


<h3>References</h3>

<p>The Wackypedia corpus can be obtained from <a href="https://wacky.sslmit.unibo.it/doku.php?id=corpora">https://wacky.sslmit.unibo.it/doku.php?id=corpora</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
WackypediaStats &lt;- simulated.wikipedia()
summary(WackypediaStats)



</code></pre>


</div>